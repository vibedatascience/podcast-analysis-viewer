================================================================================
YOUTUBE VIDEO EXTRACTION
================================================================================
VIDEO_ID: ixY2PvQJ0To
URL: https://www.youtube.com/watch?v=ixY2PvQJ0To
TITLE: Inside ChatGPT: The fastest growing product in history  | Nick Turley (OpenAI)
CHANNEL: Lenny's Podcast
PUBLISHED: 2025-08-09
DURATION: 1h 35m 38s
VIEWS: 52,404
LIKES: 486
COMMENTS: 28

DESCRIPTION:
----------------------------------------
Nick Turley is Head of ChatGPT, the fastest-growing product in history, with 700 million weekly active users (10% of the world’s population). He was part of the original hackathon team that shipped ChatGPT in just 10 days, helped it grow from zero to billions in revenue, and leads product for what may be the most consequential product of our time. We recorded this the day before GPT-5 launched.

*We discuss:*
1. The 10-day sprint from deciding to ship ChatGPT to Sam Altman’s tweet (and why it was originally called “Chat with GPT-3.5”)
2. How they ran a willingness-to-pay Van Westendorp survey in their Discord to decide on the $20/month price point that everyone copied
3. The “Is it maximally accelerated?” philosophy that drives OpenAI’s insane shipping velocity
4. Why ChatGPT’s retention curve “smiles”—users leave, then come back months later using it more
5. The accidental decisions that changed history, including not having a waitlist
6. The impact ChatGPT will have on SEO and produc
... [truncated]

SUBTITLE AVAILABILITY:
----------------------------------------
Total languages: 158
English available: True (manual)

EXTRACTED CAPTIONS:
----------------------------------------
Method: yt-dlp
Language: en
Word count: 8,702

TRANSCRIPT:
----------------------------------------
You were a product leader at Dropbox,&nbsp; then Instacart. Now, you're the PM of&nbsp;&nbsp; the most consequential product in history. I didn't know what I would do here because it&nbsp;&nbsp; was a research lab. My first task was I&nbsp; fix the blinds, or something like that. &nbsp; When someone offers you a rocket&nbsp; ship, don't ask which seat. &nbsp; We set out to build a super assistant. It&nbsp; was supposed to be a hackathon code base. &nbsp; What was it called before? It was going to be Chat with&nbsp;&nbsp; GPT-3.5 because we really didn't think it&nbsp; was going to be a successful product. &nbsp; And then Sam Altman is just like, "Hey,&nbsp;&nbsp; let me tweet about it." This is a pattern with AI,&nbsp;&nbsp; you won't know what to polish until after&nbsp; you ship. My dream is that we ship daily. &nbsp; By the time people hear this, they're&nbsp; going to have their hands on GPT-5. &nbsp; About 10% of the world population uses every&nbsp; week. With scale comes responsibility. It just&nbsp;&nbsp; feels a little bit more alive, a bit&nbsp; more human. This model has taste. &nbsp; Kevin Weil, your CPO, said to ask you about this&nbsp; principle of, "Is it maximally accelerated?" &nbsp; I just really want to jump to the punchline,&nbsp; "Why can't we do this now?" I always felt&nbsp;&nbsp; like part of my role here is to just set&nbsp; the pace and the resting heartbeat. &nbsp; Everyone is always wondering, "Is Chat&nbsp; the future of all of this stuff?" &nbsp; Chat was the simplest way to ship at that time.&nbsp; I'm baffled by how much it took off, even more&nbsp;&nbsp; baffled by how many people have copied. ChatGPT is now driving more traffic&nbsp;&nbsp; to my newsletter than Twitter. That is the type of capability that&nbsp;&nbsp; has been incredibly retentive. I've been really&nbsp; excited about what we've been doing in search. &nbsp; Can you give us a peek into&nbsp; where this goes long-term? &nbsp; ChatGPT feels a little bit like&nbsp; MS-DOS. We haven't built Windows yet,&nbsp;&nbsp; and it will be obvious once we do. Today, my guest is Nick Turley. Nick&nbsp;&nbsp; is Head of ChatGPT at OpenAI. He&nbsp; joined the company three years ago,&nbsp;&nbsp; when it was still primarily a research lab. He&nbsp; helped come up with the idea of ChatGPT and took&nbsp;&nbsp; it from 0 to over 700 million weekly active&nbsp; users, billions in revenue, and arguably the&nbsp;&nbsp; most successful and impactful consumer software&nbsp; product in human history. Nick is incredible. He's&nbsp;&nbsp; been very much under the radar. This is the first&nbsp; major podcast interview that he has ever done,&nbsp;&nbsp; and you are in for a treat. We talk about all&nbsp; the things, including the just launched GPT-5. &nbsp; A huge thank you to Kevin Weil, Claire Vo,&nbsp; George O'Brien, Joanne Jang, and Peter Deng&nbsp;&nbsp; for suggesting topics for this conversation. If&nbsp; you enjoy this podcast, don't forget to subscribe&nbsp;&nbsp; and follow it in your favorite podcasting app, or&nbsp; YouTube. And if you become an annual subscriber of&nbsp;&nbsp; my newsletter, you get a year free of a bunch&nbsp; of incredible products, including Lovable,&nbsp;&nbsp; Replit, Bolt, n8n, Linear, Superhuman, Descript,&nbsp; Wispr Flow, Gamma, Perplexity, Warp, Granola,&nbsp;&nbsp; Magic Patterns, Raycast, ChatPRD, and Mobbin.&nbsp; Check it out lennysnewsletter.com and click,&nbsp;&nbsp; "bundle". With that, I bring you Nick Turley. This episode is brought to you by Orkes,&nbsp;&nbsp; the company behind open source Conductor, the&nbsp; orchestration platform powering modern enterprise&nbsp;&nbsp; apps and agentic workflows. Legacy automation&nbsp; tools can't keep pace. Siloed, low-code platforms,&nbsp;&nbsp; outdated process management, and disconnected&nbsp; API tooling falls short in today's event-driven,&nbsp;&nbsp; AI-powered agentic landscape. Orkes changes&nbsp; this. With Orkes Conductor, you gain an&nbsp;&nbsp; agentic orchestration layer that seamlessly&nbsp; connects humans, AI agents, APIs, microservices,&nbsp;&nbsp; and data pipelines in real time at enterprise&nbsp; scale, visual and code-first development,&nbsp;&nbsp; built-in compliance, observability, and rock-solid&nbsp; reliability, ensure workflows evolve dynamically&nbsp;&nbsp; with your needs. It's not just about automating&nbsp; tasks, it's orchestrating autonomous agents and&nbsp;&nbsp; complex workflows to deliver smarter outcomes&nbsp; faster. Whether modernizing legacy systems or&nbsp;&nbsp; scaling next-gen, AI-driven apps, Orkes&nbsp; accelerates your journey from idea to&nbsp;&nbsp; production. Learn more and start building&nbsp; at orkes.io/lenny, that's orkes.io/lenny. &nbsp; This episode is brought to you by Vanta, and&nbsp; I am very excited to have Christina Cacioppo,&nbsp;&nbsp; CEO and co-founder of Vanta, joining&nbsp; me for this very short conversation. &nbsp; Great to be here. Big fan of the&nbsp; podcast and the newsletter. &nbsp; Vanta is a longtime sponsor of the show,&nbsp; but for some of our newer listeners,&nbsp;&nbsp; what does Vanta do and who is it for? Sure. So we started Vanta in 2018,&nbsp;&nbsp; focused on founders, helping them start to build&nbsp; out their security programs and get credit for&nbsp;&nbsp; all of that hard security work with compliance&nbsp; certifications, like SOC 2 or ISO 27001. Today,&nbsp;&nbsp; we currently help over 9,000 companies, including&nbsp; some startup household names, like Atlassian,&nbsp;&nbsp; Ramp, and LangChain, start and scale their&nbsp; security programs, and ultimately build&nbsp;&nbsp; trust by automating compliance, centralizing&nbsp; GRC, and accelerating security reviews. &nbsp; That is awesome. I know from experience that these&nbsp; things take a lot of time and a lot of resources,&nbsp;&nbsp; and nobody wants to spend time doing this. That is very much our experience, but before&nbsp;&nbsp; the company, and some extent, during it,&nbsp; but the idea is, with automation, with AI,&nbsp;&nbsp; with software, we are helping customers&nbsp; build trust with prospects and customers&nbsp;&nbsp; in an efficient way. And our joke, we started&nbsp; this compliance company so you don't have to. &nbsp; We appreciate you for doing that, and you have&nbsp; a special discount for listeners. They can get&nbsp;&nbsp; $1,000 off Vanta at vanta.com/lenny, that's&nbsp; vanta.com/lenny for $1,000 off Vanta. Thanks&nbsp;&nbsp; for that, Christina. Thank you! &nbsp; Nick, thank you so much for joining&nbsp; me, and welcome to the podcast. &nbsp; Thanks for having me, Lenny. I already had a billion questions I wanted&nbsp;&nbsp; to ask you, and then you guys decided to launch&nbsp; GPT-5 the week that we're recording this. So, now,&nbsp;&nbsp; I have at least 2 billion questions for you.&nbsp; I hope you have a lot of time. First of all,&nbsp;&nbsp; just congrats on the launch. It's coming tomorrow,&nbsp; the day after recording this. Just congrats.&nbsp;&nbsp; How are you feeling? I imagine this is an ungodly&nbsp; amount of work and stress. How are you doing? &nbsp; It's a busy week, but we've been&nbsp; working on this for a while,&nbsp;&nbsp; so it also feels really good to get it out. So, by the time people hear this, they're going&nbsp;&nbsp; to have their hands on GPT-5, the newest&nbsp; ChatGPT. What's the simplest way to just&nbsp;&nbsp; understand what this is, what it unlocks, what&nbsp; people can do with it? Give us the pitch. &nbsp; I'm so excited about GPT-5. I think for most&nbsp; people, it's going to feel like a real step&nbsp;&nbsp; change. If you're the average ChatGPT user, and&nbsp; we have 700 million of them this week, you've&nbsp;&nbsp; probably been on GPT-4o for a while. You probably&nbsp; don't even think about the model that powers the&nbsp;&nbsp; product. And GPT-5, it just feels categorically&nbsp; different. I'll talk about a lot of the specifics,&nbsp;&nbsp; but at the end of the day, the vibes are good,&nbsp; at least we feel that way. We hope that users&nbsp;&nbsp; feel the same. And increasingly, that is the thing&nbsp; that I think most people notice, right? They don't&nbsp;&nbsp; look at the academic benchmarks. They don't look&nbsp; at evaluations. They try the model and see what&nbsp;&nbsp; it feels like. And just on that dimension alone,&nbsp; I'm so excited. I've been using it for a while,&nbsp;&nbsp; but it is also the smartest, most useful, and&nbsp; fastest frontier model that we've ever launched. &nbsp; On pure SMARTs, one way to look at that is&nbsp; academic benchmarks on many of the standard ones,&nbsp;&nbsp; whether or not it's math, or reasoning, or just&nbsp; raw intelligence. This model is state of the art.&nbsp;&nbsp; I'm especially excited about its performance&nbsp; on coding, whether or not that's SWE-bench,&nbsp;&nbsp; which is a common benchmark, or actually front-end&nbsp; coding is really, really good as well, and that's&nbsp;&nbsp; an area where I feel like there's the true step&nbsp; change improvement in GPT-5. But really, no matter&nbsp;&nbsp; how you measure the SMARTs, it's quite remarkable,&nbsp; and I think people are going to feel the upgrade,&nbsp;&nbsp; especially if they weren't using o3 already. And the second thing beyond SMARTs is it's just&nbsp;&nbsp; really useful. Coding is one axis of utility,&nbsp; whether or not you have coding questions or&nbsp;&nbsp; you're vibe coding an app, but it's also a&nbsp; really good writer. I write for a living,&nbsp;&nbsp; internally, externally. I just wrote a big blog&nbsp; post that we published Monday, and this thing&nbsp;&nbsp; is such an incredible editor. And compared to some&nbsp; of the older models, it's got taste, which I think&nbsp;&nbsp; is really exciting. And to me, that's something&nbsp; that is truly useful in my day-to-day. And there's&nbsp;&nbsp; a bunch of other areas, like it's state of the&nbsp; art on health, which is useful when you need it,&nbsp;&nbsp; but again, the thing you can't really express&nbsp; in use cases or data is the vibe of the model.&nbsp;&nbsp; And it just feels a little bit more alive, a bit&nbsp; more human in a way that is hard to articulate&nbsp;&nbsp; until you try it. So, feel good about that. And yeah, as mentioned, it's faster. It thinks,&nbsp;&nbsp; too, just like o3 did, but you don't have&nbsp; to manually tell it to do that. It'll just&nbsp;&nbsp; dynamically decide to think when it needs to. And&nbsp; when it doesn't need to think, it just responds&nbsp;&nbsp; instantly, and that ends up feeling quite a bit&nbsp; faster than using o3 did. And then maybe the&nbsp;&nbsp; thing that's most exciting is that we're making it&nbsp; available for free, and that's one of those things&nbsp;&nbsp; that I feel like we can uniquely do at OpenAI.&nbsp; Because many companies, I think, if they have a&nbsp;&nbsp; subscription model like us, they would gate it&nbsp; behind their paid plan. And for us, if we can&nbsp;&nbsp; scale it, we will, and that just feels awesome.&nbsp; We did that with 4o as well. So, everyone is going&nbsp;&nbsp; to be able to try GPT-5 tomorrow, hopefully. How long does something like this take? I don't&nbsp;&nbsp; know if there's a simple answer to this, but just&nbsp; how long have you guys been working on GPT-5? &nbsp; We've been working on it for a while. You&nbsp; can view GPT-5 as a culmination of a bunch of&nbsp;&nbsp; different efforts. We had a reasoning tech, we had&nbsp; a more classic post-screening methodologies, and&nbsp;&nbsp; therefore, it's really hard to put a beginning on&nbsp; it, but it really is the end point of a bunch of&nbsp;&nbsp; different techniques that we began for a while. Can you give us a peek into the vision for where&nbsp;&nbsp; ChatGPT is going, GPT in general is going?&nbsp; If you look at on the surface, it's been the&nbsp;&nbsp; same idea with a much smarter brain for a long&nbsp; time. I'm curious where this goes long-term. &nbsp; So, to maybe back up a bit, now, you&nbsp; think of ChatGPT as, "Is this going&nbsp;&nbsp; to be ubiquitous product?" Again, about 10%&nbsp; of the world population uses every week. &nbsp; Holy shit. I think we have 5 million business customers now.&nbsp;&nbsp; It's an established category in its own right.&nbsp; But really, when we started, we set out to build&nbsp;&nbsp; a super assistant, that's how we talked about&nbsp; it at the time. In fact, the code base that we&nbsp;&nbsp; use is called SA Server. It was supposed to be&nbsp; a hackathon code base, but things always turn&nbsp;&nbsp; out a little bit differently. So, yeah, in some&nbsp; ways, that is still the vision. The reason I don't&nbsp;&nbsp; talk about it more than I do is because I think&nbsp; assistant is a bit limiting in terms of the mental&nbsp;&nbsp; model we're trying to create. You think of this&nbsp; very personified human thing, maybe utilitarian,&nbsp;&nbsp; maybe a... And frankly, having an assistant is&nbsp; not particularly relatable to most people, unless&nbsp;&nbsp; they're in Silicon Valley and they're a manager,&nbsp; or something like that. So it's imperfect. &nbsp; But really, what we envision is this entity that&nbsp; can help you with any task, whether or not that's&nbsp;&nbsp; at home, or at work, or at school, really any&nbsp; context, and it's an entity that knows what you're&nbsp;&nbsp; trying to achieve. So, unlike ChatGPT today, you&nbsp; don't have to describe your problem in menu to&nbsp;&nbsp; detail because it already stands your overarching&nbsp; goals and has context on your life, et cetera. So,&nbsp;&nbsp; that's one thing that we're really excited about.&nbsp; The inverse of giving it more inputs on your life&nbsp;&nbsp; is giving it more action space. So, we're really&nbsp; excited to allow it to do, over time, what a&nbsp;&nbsp; smart, empathetic human with a computer could&nbsp; do for you. And I think the limit of the types&nbsp;&nbsp; of problems that you can solve for people, once&nbsp; you give it access to tools like that, is very,&nbsp;&nbsp; very different than what you might be able to&nbsp; do in a chatbot today. So, that's more outputs. &nbsp; And I often think, "Okay, I'm a general&nbsp; intelligence. What happened if I became&nbsp;&nbsp; Lenny's intern, or something?" And I wouldn't&nbsp; be particularly effective despite having both&nbsp;&nbsp; of those attributes that I just mentioned, and&nbsp; it's because I think this idea of building a&nbsp;&nbsp; relationship with this technology is also&nbsp; incredibly important. So, that's maybe the&nbsp;&nbsp; third piece that I'm excited about is building&nbsp; a product that can truly get to know you over&nbsp;&nbsp; time. And you saw us launch some of those things&nbsp; with improved memory earlier this year, and that's&nbsp;&nbsp; just the beginning of what we're hoping to do so&nbsp; that it really feels like this is your AI. So,&nbsp;&nbsp; I don't know if supersystem is still the right&nbsp; exact analogy, but I think people just think&nbsp;&nbsp; of it as their AI. And I think we can put one&nbsp; in everyone's pocket and help them solve real&nbsp;&nbsp; problems, whether or not that's becoming healthy,&nbsp; whether or not that's starting a business,&nbsp;&nbsp; whether or not that's just having a second&nbsp; opinion on anything. There's so many different&nbsp;&nbsp; problems that you can help with people in their&nbsp; daily life, and that's what motivates me. &nbsp; So an interesting between the lines that&nbsp; I'm reading here is the vision is for it&nbsp;&nbsp; to be an assistant for people not to replace&nbsp; people. It feels like a really important piece&nbsp;&nbsp; of the puzzle. Maybe just talk about that. AI is really scary to people, and I understand&nbsp;&nbsp; there's decades of movies on AI that have a&nbsp; certain mental model baked in. And even if&nbsp;&nbsp; you just look at the technology today, everyone, I&nbsp; think, has this moment where the AI does something&nbsp;&nbsp; that was really deeply personal to them and you're&nbsp; thought, "Hey, AI can never do that." For me,&nbsp;&nbsp; it was weird music theory things where I was like,&nbsp; "Wow, this thing actually understands music better&nbsp;&nbsp; than I do," and that's something I'm passionate&nbsp; about. And so it's naturally scary. And I think&nbsp;&nbsp; the thing that's been really important to us for&nbsp; a long time is to build something that feels like&nbsp;&nbsp; it's helpful to you, but you're in the driver's&nbsp; seat, and that's even more important as the&nbsp;&nbsp; stuff becomes agentic, the feeling of being&nbsp; in control, and that can be small things. &nbsp; We built this way of watching what the AI is doing&nbsp; when it's in agent mode. And it's not that you&nbsp;&nbsp; actually are going to watch it the whole time,&nbsp; but it gives you a mental model and makes you&nbsp;&nbsp; feel in control in the same way that, when you're&nbsp; in a Waymo, you get that screen, for those of you&nbsp;&nbsp; who've tried Waymo. You can see the other cars.&nbsp; It's not like you're going to actually watch,&nbsp;&nbsp; but it gives you the sense that you know&nbsp; how this thing works and what's happening,&nbsp;&nbsp; or we always check with you to confirm&nbsp; things. It's a little bit annoying,&nbsp;&nbsp; but it puts you in the driver's seat, which is&nbsp; important. And for that reason, we always view&nbsp;&nbsp; technology and the technology that we build as&nbsp; something that amplifies what you're capable of,&nbsp;&nbsp; rather than replacing it, and that becomes&nbsp; important as the deck gets more powerful. &nbsp; Okay. So you mentioned the beginnings of ChatGPT.&nbsp; I was reading in a different interview. So you&nbsp;&nbsp; joined OpenAI. ChatGPT was just this internal&nbsp; experimental project that was basically a way&nbsp;&nbsp; to test GPT-3.5, and then Sam Altman is&nbsp; just like, "Hey, let me tweet about it,&nbsp;&nbsp; maybe see if people find this interesting," yada&nbsp; yada, yada. It's the most successful consumer&nbsp;&nbsp; product in history, I think both in growth rate&nbsp; in users and revenue, and just absurd. Can you&nbsp;&nbsp; give us a glimpse into that early period before&nbsp; it became something everyone is obsessed with? &nbsp; Yeah. So we had decided that we wanted to do&nbsp; something consumer-facing, I think, right around&nbsp;&nbsp; the time that GPT-4 finished training, and it&nbsp; was actually mainly for a couple of reasons.&nbsp;&nbsp; We already had a product out there, which was our&nbsp; developer product. That's actually what I came in&nbsp;&nbsp; to help with initially, and that has been amazing&nbsp; for the mission. In fact, it's grown up. And now,&nbsp;&nbsp; it's the OpenAI platform with, I don't know, 4&nbsp; million developers, I think. But at that time,&nbsp;&nbsp; it was early stage, and we were running&nbsp; into some constraints with it because&nbsp;&nbsp; there was two problems. One, you couldn't iterate&nbsp; very quickly because, every time you would change&nbsp;&nbsp; the model, you'd break everyone's app.&nbsp; So, it was really hard to try things. &nbsp; And then the other thing was that it was really&nbsp; hard to learn because the feedback we would&nbsp;&nbsp; get was the feedback from the end user to the&nbsp; developer to us. So it was very disintermediated,&nbsp;&nbsp; and we were excited to make fast progress towards&nbsp; AGI and it just felt like we needed a more direct&nbsp;&nbsp; relationship with consumers. So we were trying to&nbsp; figure out where to start. And in classic OpenAI&nbsp;&nbsp; fashion, especially back then, we put together&nbsp; a hackathon of enthusiasts of just hacking on&nbsp;&nbsp; GPT-4 to see what awesome stuff we could create&nbsp; and maybe ship to users, and everyone's idea was&nbsp;&nbsp; some flavor of a super assistant. They were more&nbsp; specific ideas, like we had a meeting bot that&nbsp;&nbsp; would call into meetings, and the vision was maybe&nbsp; it would help you run the meeting over time. We&nbsp;&nbsp; had a coding tool, which full circle now, probably&nbsp; ahead of its time. And the challenge was that we&nbsp;&nbsp; tested those things, but every time we tested&nbsp; these more bespoke ideas, people wanted to use&nbsp;&nbsp; it for all this other stuff because it's just&nbsp; a very, very generically powerful technology. &nbsp; So, after a couple of months of prototyping,&nbsp; we took that same crew of volunteers,&nbsp;&nbsp; and it was truly a volunteer group, right? We&nbsp; had someone from the supercomputing team who&nbsp;&nbsp; had built an iOS app before. We had someone on the&nbsp; research team who had written some backend code in&nbsp;&nbsp; their life. They were all part of this initial&nbsp; ChatGPT team, and we decided to ship something&nbsp;&nbsp; open-ended because we just wanted a real use case&nbsp; distribution. And this is a pattern with AI, I&nbsp;&nbsp; think, where you really have to ship to understand&nbsp; what is even possible and what people want,&nbsp;&nbsp; rather than being able to reason about that a&nbsp; priori. So, ChatGPT came together at the end&nbsp;&nbsp; because we just wanted the learnings as soon&nbsp; as we could, and we shipped it right before&nbsp;&nbsp; the holiday thinking we would come back and get&nbsp; the data and then wind it down. And obviously,&nbsp;&nbsp; that part turned out super differently because&nbsp; people really liked the product as is. &nbsp; So I remember going through the motions of&nbsp; like, "Oh, man, dashboard is broken. Oh, wait,&nbsp;&nbsp; people are liking it. I'm sure it's just going&nbsp; viral and stuff is going to die down," to like,&nbsp;&nbsp; "Oh, wow, people are retaining, but I&nbsp; don't understand why." And then eventually,&nbsp;&nbsp; we fell into product development mode,&nbsp; but it was a little bit by accident. &nbsp; Wow. I did not know that ChatGPT emerged&nbsp; out of a hackathon project. Definitely&nbsp;&nbsp; the most successful hackathon project. I like to tell this story when we do our&nbsp;&nbsp; hackathons because I really do want people&nbsp; to feel like they can ship their idea,&nbsp;&nbsp; and it's certainly been true in the past,&nbsp; and we'll continue to make it true. &nbsp; If you don't want to share these things,&nbsp; but I wonder who that team was. &nbsp; The team is largely still around. Some of&nbsp; the researchers working on GPT-5, actually,&nbsp;&nbsp; were always part of the ChatGPT team. Engineers&nbsp; are still around. Designers are still around. I'm&nbsp;&nbsp; still here, I guess. So, yeah, you've got the team&nbsp; still running things, but obviously, we've grown&nbsp;&nbsp; up tremendously, and we've had to because with&nbsp; scale comes responsibility. And we're going to hit&nbsp;&nbsp; a billion users soon and you have to begin acting&nbsp; in a way that is appropriate to that scale. &nbsp; Okay. So let me spend a little time there. So,&nbsp; I don't know if this is 100% true, but I believe&nbsp;&nbsp; it is that ChatGPT is the fastest growing, most&nbsp; successful consumer product in history. Also,&nbsp;&nbsp; the most impactful on people's lives. It feels&nbsp; like it's just part of the ether of society now.&nbsp;&nbsp; It's just my wife talks to it. Every question&nbsp; I have, I go to it, voice mode. My wife is just&nbsp;&nbsp; like, "Let me check with ChatGPT." It's just such&nbsp; a part of our life now, and I think it's still&nbsp;&nbsp; early. So many people don't even know what the&nbsp; hell is going on. Just as someone leading this,&nbsp;&nbsp; do you ever just take a moment to reflect&nbsp; and think about just like, "Holy shit"? &nbsp; I have to. It's quite humbling to get to run a&nbsp; product like that, and I have to pinch myself very&nbsp;&nbsp; frequently, and I also have to sometimes sit back&nbsp; and just think, which is really hard when things&nbsp;&nbsp; are moving so quickly. I love setting a fast&nbsp; pace at the company, but in order to do that with&nbsp;&nbsp; confidence, I need at least one day every week&nbsp; that I'm entirely unplugged and I'm just thinking&nbsp;&nbsp; about what to do and process the week, et cetera. And the other thing is I've never ever worked on&nbsp;&nbsp; a product that is so empirical in its nature&nbsp; where, if you don't stop, and watch, and listen&nbsp;&nbsp; to what people are doing, you're going to miss&nbsp; so much, both on the utility and on the risks,&nbsp;&nbsp; actually. Because normally, by the time you ship a&nbsp; product, you know what it's going to do. You don't&nbsp;&nbsp; know if people are going to like it, that's always&nbsp; empirical, but you know what it can do. And with&nbsp;&nbsp; AI, because I think so much of it is emergent,&nbsp; you actually really need to stop and listen&nbsp;&nbsp; after you launch something and then iterate&nbsp; on the things people are trying to do and on&nbsp;&nbsp; the things that aren't quite working yet. So, for&nbsp; that reason alone, I think it's very important to&nbsp;&nbsp; take a break and just watch what's going on. Okay. So you take a day off every week... not&nbsp;&nbsp; off. Okay, that's not the right way to put it.&nbsp; You take a day of thinking time, deep work. &nbsp; I need it. Yeah, yeah, yeah. And I&nbsp; need to hard unplug on a Saturday,&nbsp;&nbsp; or something like that. Obviously- On a Saturday [inaudible 00:20:16]. &nbsp; But it's just not possible otherwise.&nbsp; This has been a giant marathon for&nbsp;&nbsp; three years now. Yeah. Like a sprint marathon. &nbsp; Sprint marathon, that's right, or interval&nbsp; training, or something. I don't know how to&nbsp;&nbsp; exactly describe the OpenAI launch cadence,&nbsp; but you've got to set yourself up in a way&nbsp;&nbsp; that is sustainable. Even if this wasn't AI and it&nbsp; didn't have the interesting attributes that I just&nbsp;&nbsp; mentioned, I think you would need to do that. But&nbsp; especially with AI, it's important to go watch. &nbsp; So, along those lines, I talked to a bunch&nbsp; of people that work with you, that work at&nbsp;&nbsp; OpenAI. Joanne specifically said that urgency&nbsp; and pace are a big part of how you operate,&nbsp;&nbsp; that that's just something you find really&nbsp; important, to create urgency within the team&nbsp;&nbsp; constantly, even when you are the fastest&nbsp; growing product in history, growing like&nbsp;&nbsp; crazy. Talk about just your philosophy on the&nbsp; importance of pace and urgency on teams. &nbsp; Well, it's nice of her to say that. Two things,&nbsp; with ChatGPT, when we decided to do it, we had&nbsp;&nbsp; been prototyping for so long and I was just like,&nbsp; "In 10 days, we're going to ship this thing," and&nbsp;&nbsp; we did. So, that was maybe a moment in time thing&nbsp; where I just really wanted to make sure that we go&nbsp;&nbsp; learn something. Ever since then, I spent so much&nbsp; time thinking about why ChatGPT became successful&nbsp;&nbsp; in the first place, and I think there was some&nbsp; element of just doing things where there was&nbsp;&nbsp; many other companies that had technology in the&nbsp; LLM space that just never got shipped. And I just&nbsp;&nbsp; felt like, of all the things we could optimize&nbsp; for, learning as fast as possible is incredibly&nbsp;&nbsp; important. So I just started rallying people&nbsp; around that, and that took different forms. &nbsp; For a while, when we were of that size, I just&nbsp; ran this daily release sync and had everyone&nbsp;&nbsp; who was required to make a decision in it, and we&nbsp; would just talk about what to do and to pivot from&nbsp;&nbsp; yesterday, et cetera. Obviously, at some point,&nbsp; that doesn't scale, but I always felt like part&nbsp;&nbsp; of my role here, obviously, was to think about the&nbsp; direction of the product, but also to just set the&nbsp;&nbsp; pace and the resting heartbeat for our teams.&nbsp; And again, this is important anywhere, but it's&nbsp;&nbsp; especially important when the only way to find out&nbsp; what people like and what's valuable is to bring&nbsp;&nbsp; it into the external world. So, for that reason,&nbsp; I think it's become a superpower of OpenAI, and&nbsp;&nbsp; I'm glad that Joanne thinks that I had some part&nbsp; in that, but it really has taken a village. &nbsp; I love this phrase, "the resting&nbsp; heart rate of your team".&nbsp;&nbsp; That's such a perfect metaphor of just the pace&nbsp; of being equivalent to your resting heart rate. &nbsp; I actually learned that at Instacart, when&nbsp; I showed up there, because we were in the&nbsp;&nbsp; pandemic and it was all hands on deck. For a&nbsp; while, there was this... I think there was a&nbsp;&nbsp; company-wide stand-up because we disbanded all&nbsp; teams. We were just trying to keep the site up.&nbsp;&nbsp; And for me, I had been used to taking my sweet&nbsp; time and just thinking really hard about things,&nbsp;&nbsp; and that's important, but I really&nbsp; learned to hustle over there, and&nbsp;&nbsp; I think that's come in handy at OpenAI. Okay. So, along these same lines, I asked&nbsp;&nbsp; Kevin Weil, your CPO, what to ask you, and&nbsp; he said to ask you about this principle of,&nbsp;&nbsp; "Is it maximally accelerated?" Talk about that. That's funny, we have a Slack emoji, apparently,&nbsp;&nbsp; for this now because I used to say that. Now, I&nbsp; try to paraphrase. Sometimes, I just really want&nbsp;&nbsp; to jump to the punchline of like, "Okay, why&nbsp; can't we do this now?" or, "Why can't we do it&nbsp;&nbsp; tomorrow?" And I think that it's a good way to cut&nbsp; through a huge number of blockers with the team&nbsp;&nbsp; and just instill... especially if you come from a&nbsp; larger company. At some point, we started hiring&nbsp;&nbsp; people from larger tech companies. I think they're&nbsp; used to, "Let's check in on this in a week," or,&nbsp;&nbsp; "Let's circle back next quarter to see if&nbsp; we can go on the plan." And I just, as a- &nbsp; ... on the plan and I just kind of as a&nbsp; thought exercise, always like people asking,&nbsp;&nbsp; "Okay, if this was the most important thing and&nbsp; you wanted to truly maximally accelerate it,&nbsp;&nbsp; what would you do?" That doesn't mean that you go&nbsp; do that, but it's really a good forcing function&nbsp;&nbsp; for understanding what's critical path versus what&nbsp; can happen later. And I've just always felt like&nbsp;&nbsp; execution is incredibly important. These ideas,&nbsp; they're everywhere. Everyone's talking about a&nbsp;&nbsp; personal AI, you might've seen news on that and&nbsp; I really think that execution is one of the most&nbsp;&nbsp; important things in the space and this is a tool.&nbsp; So, it's funny that that became a meme. It's like&nbsp;&nbsp; a little pink Slack emoji that people just put on&nbsp; whatever they're trying to force the question. &nbsp; I was going to ask, what theme [inaudible&nbsp; 00:24:47]. So, it's a little pink,&nbsp;&nbsp; is there something in there like- It's a Comic Sans emoji that says,&nbsp;&nbsp; is this maximally accelerated? Okay. And so, the kind of the culture&nbsp;&nbsp; there is when someone is working on something,&nbsp; the push is, is this maximally accelerated? Is&nbsp;&nbsp; there a way we can do this faster?&nbsp; Is there anything we can unblock? &nbsp; Yeah. And we use that sparingly, right? Because&nbsp; it needs to be appropriate to the context. There's&nbsp;&nbsp; some things where you don't want to accelerate&nbsp; as quickly as possible because you kind of want&nbsp;&nbsp; process. And we're very, very deliberate on that&nbsp; where your process is a tool. And one of the areas&nbsp;&nbsp; where we have an immense amount of process is&nbsp; safety. Because A, the stakes are already really&nbsp;&nbsp; high, especially with these models, GPT-5 which&nbsp; is a frontier in so many different ways. But B,&nbsp;&nbsp; if you believe in the exponential, which I&nbsp; do and most people who work on this stuff do,&nbsp;&nbsp; you have to play practice for a time where you&nbsp; really, really need the process for sure, sure,&nbsp;&nbsp; sure. And that's why I think it's been really&nbsp; important to separate out the product development&nbsp;&nbsp; velocity, which has to be super high from, for&nbsp; things like frontier models, there actually needs&nbsp;&nbsp; to be a rigorous process where you red team, you&nbsp; work on the system card, you get external input,&nbsp;&nbsp; and then you put things out with confidence&nbsp; that it's gone through the right safeguards. &nbsp; So, again, it's a nuanced concept, but I found&nbsp; it very, very useful when we needed and for&nbsp;&nbsp; everything product development, you're a dead on&nbsp; arrival, so it's important to get stuff out. &nbsp; We got to open source those memes so that&nbsp; other teams can build on this approach. &nbsp; Absolutely. So, interestingly with ChatGPT,&nbsp;&nbsp; and it's not a surprise, but not only is it the&nbsp; fastest-growing, most successful consumer product&nbsp;&nbsp; ever, retention is also incredibly high. People&nbsp; have shared these stats that one month retention&nbsp;&nbsp; is something like 90%, six month retention is&nbsp; something like 80%. First of all, are these&nbsp;&nbsp; numbers accurate? What can you share there? I'm obviously limited on what exactly I can share,&nbsp;&nbsp; but it is true that our retention numbers&nbsp; are really exciting and that is actually&nbsp;&nbsp; the thing we look at. We don't care at all how&nbsp; much time you spend in the product. In fact,&nbsp;&nbsp; our incentive is just to solve your problem and&nbsp; if you really like the product, you'll subscribe,&nbsp;&nbsp; but there's no incentive to keep you in the&nbsp; product for long. But we are obviously really,&nbsp;&nbsp; really happy if over the long run, three month&nbsp; period, et cetera, you're still using this&nbsp;&nbsp; thing. And for me, this was always the elephant&nbsp; in the room early on. It's like, "Hey, this may&nbsp;&nbsp; be a really cool product, but is this really the&nbsp; type of thing that you come back to?" And it's&nbsp;&nbsp; been incredible to not just see strong retention&nbsp; numbers, but just see an improvement in retention&nbsp;&nbsp; over time even as our cohorts become less of an&nbsp; early adopter and more the average person, so. &nbsp; Yeah. So, that note is something that I&nbsp; don't think people truly understand how&nbsp;&nbsp; rare this is when a product... The cohort of&nbsp; users comes, tries it out and then retention&nbsp;&nbsp; over time goes down and then it comes back up,&nbsp; people come back to it a few months later and&nbsp;&nbsp; use it more. It's called a smiling curve, a&nbsp; smile curve, and that's extremely rare. &nbsp; Yeah, yeah. Yeah. There's some smiling going&nbsp; on that's just on the team and I feel like&nbsp;&nbsp; have technology, some of it is not the product.&nbsp; I think people are actually just getting used&nbsp;&nbsp; to this technology in a really interesting way,&nbsp; where I find, and this is why the product needs&nbsp;&nbsp; to evolve too, that this idea of delegating to an&nbsp; AI, it's not natural to most people. It's not like&nbsp;&nbsp; you're going through life and figuring out what&nbsp; can I delegate? Certain sphere of Silicon Valley&nbsp;&nbsp; does that because they're in a self-optimization&nbsp; mode and they're trying to delegate everything&nbsp;&nbsp; they can. But I think for most people in the world&nbsp; it's actually quite unnatural. And you really have&nbsp;&nbsp; to learn, "Okay, what are my goals actually and&nbsp; what could another intelligence help me with?" &nbsp; And I think that just takes time and people&nbsp; do figure it out once they've had enough time&nbsp;&nbsp; with the product. But then of course there's been&nbsp; tons of things that we've done in the product too,&nbsp;&nbsp; whether or not it's making the core models better,&nbsp; whether or not it's new capabilities like search&nbsp;&nbsp; and personalization and all that kind of&nbsp; stuff, or just standard growth work too,&nbsp;&nbsp; which we're starting to do. That&nbsp; stuff matters too, of course. &nbsp; So, you might be answering this question&nbsp; already, but let me just ask it directly.&nbsp;&nbsp; People may look at this and be like,&nbsp; "Okay, they're building this kind of&nbsp;&nbsp; layer on top of this God-like intelligence. Of&nbsp; course it will grow incredibly fast and retention&nbsp;&nbsp; will be incredible. What do you guys actually&nbsp; doing that sits on top of the model that makes&nbsp;&nbsp; it grow so fast and retain so much?" Is there&nbsp; something that has worked incredibly well that has&nbsp;&nbsp; moved metrics significantly that you can share? One thing we've learned, I'll answer that question&nbsp;&nbsp; in a minute, but one thing we've learned with&nbsp; ChatGPT is that there really is no distinction&nbsp;&nbsp; between the model and the product. The model is&nbsp; the product and therefore you need to iterate on&nbsp;&nbsp; it like a product. And by that I mean obviously&nbsp; you typically start by shipping something very&nbsp;&nbsp; open-ended, at least if you're OpenAI [inaudible&nbsp; 00:29:38] that's kind of a playbook. But then&nbsp;&nbsp; you really have to look at what are people&nbsp; trying to do? Okay, they're trying to write,&nbsp;&nbsp; they're trying to code, they're trying to get&nbsp; advice, they're trying to get recommendations&nbsp;&nbsp; and you need to systematically improve on those&nbsp; use cases. And that is pretty similar to product&nbsp;&nbsp; development work. Obviously the methodology is a&nbsp; bit different, but discovery is the same. You got&nbsp;&nbsp; to talk to people, you got to do data science&nbsp; and you got to try stuff and get feedback. &nbsp; So, that's one chunk of work that we've been&nbsp; very consciously doing is improving the model on&nbsp;&nbsp; the use cases people care about. And there's also&nbsp; such thing as vibes because I'm sure you know and&nbsp;&nbsp; that's one of the things that I'm excited about&nbsp; in GPT-5 is that the vibes are really good. So,&nbsp;&nbsp; that too is, we have a model behavior team and&nbsp; they really focus on what is the personality of&nbsp;&nbsp; this model and how does it speak and talk. So,&nbsp; there's that kind of work. I would say that's&nbsp;&nbsp; maybe a third of the retention improvements&nbsp; that we see or so just roughly. And then I&nbsp;&nbsp; think another third is what I would call product&nbsp; research capabilities. They're research driven&nbsp;&nbsp; for sure. They have a research component,&nbsp; but they're really new product features&nbsp;&nbsp; or capabilities. And search is one example of&nbsp; that where if you remember in the olden days,&nbsp;&nbsp; maybe 20 months ago or something, you would talk&nbsp; to ChatGPT and it'd be like, "As of my knowledge&nbsp;&nbsp; cut off..." Or, "I can't answer that because that&nbsp; happened to recently," or something like that. &nbsp; And that is the type of capability&nbsp; that has been incredibly retentive and&nbsp;&nbsp; for good reason. It just allows you to do more&nbsp; with the product personalization, like this idea&nbsp;&nbsp; of advanced memory where it can really get to know&nbsp; you over time is another example of a capability&nbsp;&nbsp; like that. I think that's another good chunk.&nbsp; And then the third stuff is the stuff you would&nbsp;&nbsp; do in any product and those things exist too.&nbsp; Not having to log in was a huge hit because it&nbsp;&nbsp; removed a ton of the friction. I think we had&nbsp; this intuition from the beginning, but we never&nbsp;&nbsp; got to it because we didn't have enough GPU&nbsp; or other constraint to really go do that. So,&nbsp;&nbsp; there's the traditional product work too. So, I&nbsp; often think about it as roughly a third, a third,&nbsp;&nbsp; a third, but really we're still learning and we're&nbsp; planning to evolve the product a ton, which is why&nbsp;&nbsp; I'm sure there's going to be new levers. You mentioned something that I want to come&nbsp;&nbsp; back to real quick. You said that it was&nbsp; something like 10 days from Hackathon&nbsp;&nbsp; to Sam tweeting about ChatGPT being live? The Hackathon happened much earlier and we were&nbsp;&nbsp; prototyping for a long time, but at some point we&nbsp; basically ran out of patience on trying to build&nbsp;&nbsp; something more bespoke. And again, that was mostly&nbsp; because people always wanted to do all this other&nbsp;&nbsp; stuff whenever we tested it. So, it was 10 days&nbsp; from when we decided we were going to ship to when&nbsp;&nbsp; we shipped. And the research we'd been testing&nbsp; for a long time, it was kind of an evolution&nbsp;&nbsp; of what we'd called instruction following, which&nbsp; was the idea that instead of just completing the&nbsp;&nbsp; sentence, these models could actually follow you&nbsp; instructions. So, if you said summarize this, it&nbsp;&nbsp; would actually do so. And the research had evolved&nbsp; from that into a chat format where we could do it&nbsp;&nbsp; multi-turn. So, that research took way longer than&nbsp; 10 days and that kind of baking in the background,&nbsp;&nbsp; but the productization of this thing was very,&nbsp; very fast and lots of things didn't make it in. &nbsp; I remember we didn't have history, which of course&nbsp; was the first user feedback we got. The model had&nbsp;&nbsp; a bunch of shortcomings and it was so cool to be&nbsp; able to iterate on the model. The thing I just&nbsp;&nbsp; talked about, treating the model as a product was&nbsp; not a thing before ChatGPT because we would ship&nbsp;&nbsp; in more hardware where there'd be a release GPT-3&nbsp; and then we would start working on GPT-4 and these&nbsp;&nbsp; weird giant big spend R&amp;D projects that would&nbsp; take a really long time and the spec was whatever&nbsp;&nbsp; the spec was and then you'd have to wait another&nbsp; year. And ChatGPT really broke that down because&nbsp;&nbsp; we were able to make iterative improvements to it&nbsp; just like software. And really, my dream is that&nbsp;&nbsp; it would be amazing if we could just ship daily&nbsp; or even hourly like in software land because you&nbsp;&nbsp; could just fix stuff, et cetera. But there's&nbsp; of course all kinds of challenges in how you&nbsp;&nbsp; do that while keeping the personality intact&nbsp; while not regressing other capabilities. So,&nbsp;&nbsp; it's an open field to get there. That's such a good example of is it&nbsp;&nbsp; maximally accelerated? Okay, we're&nbsp; going to ship ChatGPT 10 days. &nbsp; [inaudible 00:33:48]- Holy moly. We've been talking about&nbsp;&nbsp; ChatGPT. Clearly it's kind of a chat interface.&nbsp; Everyone's always wondering is chat the future&nbsp;&nbsp; of all of this stuff? Interestingly, Kevin Weil&nbsp; made this really profound point that has always&nbsp;&nbsp; stuck with me when he was on the podcast that chat&nbsp; is actually a genius interface for building on a&nbsp;&nbsp; super intelligence because it's how we interact&nbsp; with humans of all variety of intelligence. It&nbsp;&nbsp; scales from someone at the lower end to a super&nbsp; smart person. And so, it's really valuable as&nbsp;&nbsp; a way to scale this spectrum. Maybe just talk&nbsp; about that and is chat the long-term interface&nbsp;&nbsp; for ChatGPT, I guess it's called ChatGPT. I feel like we should either drop the chat&nbsp;&nbsp; or drop the GPT at some point because it&nbsp; is a mouthful. We're stuck with the name,&nbsp;&nbsp; but no matter what we do, the product will&nbsp; evolve. I think that I agree that there's&nbsp;&nbsp; something profound about natural language. It just&nbsp; really is the most natural form of communicating&nbsp;&nbsp; to humans and therefore it feels important that&nbsp; you should be communicating with your software&nbsp;&nbsp; in natural language. I think that's different&nbsp; from chat though. I think chat was the simplest&nbsp;&nbsp; way to ship at the time. I'm baffled by how much&nbsp; it took off as a concept. Even more baffled by&nbsp;&nbsp; how many people have copied the paradigm rather&nbsp; than trying out a different way of interacting&nbsp;&nbsp; with AI. I'm still hoping that will happen.&nbsp; So, I think natural language is here to stay,&nbsp;&nbsp; but this idea that it has to be a turn-by-turn&nbsp; chat interaction I think is really limiting. &nbsp; And this is one of the reasons I don't love&nbsp; the super system analogy, even though we&nbsp;&nbsp; used to always use it is because if you think&nbsp; that way, then you kind of feel like you're&nbsp;&nbsp; talking to a person and GPT-5 it's amazing&nbsp; at making great front-end applications. So,&nbsp;&nbsp; I don't see a reason why you wouldn't have AIs&nbsp; that can render their own UI in some way. And&nbsp;&nbsp; you obviously want to make that predictable and&nbsp; feel good. But it feels limiting to me to think&nbsp;&nbsp; of the end-all-be-all interface as a chatbot. It&nbsp; actually kind of feels dystopian almost where I&nbsp;&nbsp; don't want to use all my software through the&nbsp; proxy of some interface. I love being in Figma,&nbsp;&nbsp; I love being in Google Docs. Those are all&nbsp; great products to me and they're not chatbots. &nbsp; So, yes on natural language, but no on chat is&nbsp; where I would describe my point of view. And I'm&nbsp;&nbsp; just hoping in general that we see more consumer&nbsp; innovation on how people interact with AI because&nbsp;&nbsp; there's so many possibilities and you just got to&nbsp; try stuff. That's why chat stuck is we just did&nbsp;&nbsp; it and people liked it. So, I'm hoping that we&nbsp; see more there and we'll try to do our part. &nbsp; So, you mentioned that you kind of got&nbsp; stuck with this name ChatGPT. Maybe this&nbsp;&nbsp; is part of the answer, but I'm curious just&nbsp; are there any accidental decisions you guys&nbsp;&nbsp; made early on that have stuck and have&nbsp; essentially become history changing? &nbsp; There's so many and it is funny, because you have&nbsp; no time to think about them and then they end up&nbsp;&nbsp; being super consequential. The day was one, we&nbsp; went from chat with GPT-3.5 to ChatGPT the night&nbsp;&nbsp; before, slightly better but still really bad. What was it called before? &nbsp; It was going to be Chat with GPT-3.5 because we&nbsp; really didn't think it was going to be successful&nbsp;&nbsp; product. We were trying to actually be as&nbsp; nerdy as we could about it because that's&nbsp;&nbsp; really what it was. It was a research demo, not&nbsp; a product. So, we didn't think that was bad. But&nbsp;&nbsp; I think that in the original release, making it&nbsp; free was a big deal. I don't think we appreciate&nbsp;&nbsp; that because the GPT-3.5 model was in our API for&nbsp; at least six months prior to that. I think anyone&nbsp;&nbsp; could have built something like this. It might not&nbsp; have been quite as good on the modeling side, but&nbsp;&nbsp; I think it would've taken off. So, making it free&nbsp; and putting a nice UI on it, very consequential in&nbsp;&nbsp; the way that you take for granted now. And this is&nbsp; why I think that A, distribution and the interface&nbsp;&nbsp; are continuously important even in 2025. The paid business, which now it's a giant&nbsp;&nbsp; business both in the consumer space and in the&nbsp; enterprise space. The birth of that was just to&nbsp;&nbsp; turn away demand originally. It was not like we&nbsp; brainstormed, "Oh, what is the best monetization&nbsp;&nbsp; model for AI?" It was really what monetization&nbsp; model or what mechanism would allow us to turn&nbsp;&nbsp; away people who are less serious than the people&nbsp; who are really trying to use it? And subscriptions&nbsp;&nbsp; just happened to have that property and it grew&nbsp; into a large business. I think shipping really&nbsp;&nbsp; funky capabilities before they were polished is&nbsp; another thing where that feels like a tactical&nbsp;&nbsp; decision, but it became a playbook because we&nbsp; would learn so much. Remember when we shipped&nbsp;&nbsp; Code Interpreter, we learned so much after&nbsp; we shipped it. Now it's known as I think&nbsp;&nbsp; data analysis in ChatGPT or something like that&nbsp; just because we actually got real world use cases&nbsp;&nbsp; back that we could then optimize. So, I think&nbsp; there's been a lot of decisions over time that&nbsp;&nbsp; proved pretty consequential, but we made&nbsp; them very, very quickly as we have to, so. &nbsp; The $20 a month feels like an&nbsp; important part of this. Feels&nbsp;&nbsp; like everybody's just doing that now and- On that one actually, I remember I had this kind&nbsp;&nbsp; of panic attack because we really needed to launch&nbsp; subscriptions because at the time we were taking&nbsp;&nbsp; the product down every time. It was, I don't know&nbsp; if you remember, we had this fail whale, there's a&nbsp;&nbsp; little [inaudible 00:39:09] generated poem on it.&nbsp; So, they were like, "We had to get this out." And&nbsp;&nbsp; I remember calling up someone I greatly respect&nbsp; who's incredible at pricing and I was like,&nbsp;&nbsp; "What should I do?" And we talked a bunch and I&nbsp; just ran out of time to incorporate most of that&nbsp;&nbsp; feedback. So, what I did do is ship a Google Form&nbsp; to Discord with, I think the four questions you're&nbsp;&nbsp; supposed to ask on how to price something- [inaudible 00:39:32]? &nbsp; Yeah, exactly. It literally had those four&nbsp; questions and I remember distinctly A, you&nbsp;&nbsp; [inaudible 00:39:38] a price back and that's kind&nbsp; of how we got to $20. But B, the next morning,&nbsp;&nbsp; there was a press article on you won't believe&nbsp; the four genius questions the ChatGPT team asked&nbsp;&nbsp; to price their... It was like if only you knew.&nbsp; So, there's something about building in this&nbsp;&nbsp; extreme public where people interpret so much&nbsp; more intentionality into what you're doing than&nbsp;&nbsp; might've actually existed at the time. But we got&nbsp; with the $20. We're debating something slightly&nbsp;&nbsp; higher at the time. I often wonder what would've&nbsp; happened because so many other companies ended&nbsp;&nbsp; up copying the $20 price point. So, I'm like, "Did&nbsp; we erase a bunch of market cap by pressing it this&nbsp;&nbsp; way?" But ultimately I don't care because the more&nbsp; accessible we can make this stuff, the better. And&nbsp;&nbsp; I think this is the price point that in Western&nbsp; countries has been reasonable to a lot of&nbsp;&nbsp; people in terms of the value that they get back. And most importantly, we were able to push things&nbsp;&nbsp; down to the free tier semi-regularly and we always&nbsp; do that when we can [inaudible 00:40:35], but- &nbsp; So, the survey, just to give the official&nbsp; name, the Van Westendorp survey is how you&nbsp;&nbsp; guys ended up pricing ChatGPT? It was the top Google result. This&nbsp;&nbsp; was before ChatGPT has real-time information.&nbsp; Otherwise, it could have maybe price itself,&nbsp;&nbsp; but it was Discord plus Google Form plus a blog&nbsp; post on that methodology that got us there. &nbsp; That is incredible. What a fun story. This&nbsp; is the survey that Rahul Vohra at Superhuman&nbsp;&nbsp; popularized in his first- round article- Yeah. Yeah, yeah, that's right. That's right.&nbsp;&nbsp; Definitely don't bring me on here as&nbsp; a pricing expert, I think you have&nbsp;&nbsp; got better people for that. Whether it was right or wrong,&nbsp;&nbsp; it is now the fastest-growing, insane&nbsp; revenue generating business in the world. So,&nbsp;&nbsp; I wouldn't feel too bad. No, it worked out. Yeah. &nbsp; It worked out. And by the way, I'm on the $200&nbsp; a month tier, so there's clearly a room- &nbsp; Thank you. Thank you. ... [inaudible 00:41:25]- &nbsp; The story of that one is interesting too because&nbsp; originally the purpose of the Plus plan was to be&nbsp;&nbsp; able to ship first uptime and then be able to ship&nbsp; capabilities that we couldn't scale to everyone.&nbsp;&nbsp; And at some point it got so many people in the&nbsp; Plus tier that had just lost that property. So,&nbsp;&nbsp; the main reason we came up with the $200 tier is&nbsp; just we had so much incredible research that's&nbsp;&nbsp; actually really, really powerful. Like o3 Pro or&nbsp; tomorrow GPT-5 Pro and just having a vehicle of&nbsp;&nbsp; shipping that to people who really, really care&nbsp; is exciting even though it kind of violates the&nbsp;&nbsp; standard way a SaaS page should look, it's&nbsp; a little jarring to see the 10X jump. So,&nbsp;&nbsp; thank you for being a subscriber on that&nbsp; and thank you everyone else who's watching&nbsp;&nbsp; you subscribed to any tier, it's great. I'm just going to throw a fishing line into&nbsp;&nbsp; this pond of are there any other stories like&nbsp; this? You shared this incredible story of Chat&nbsp;&nbsp; with GPT-3.5 being the original name, how you&nbsp; came up with pricing. Is there anything else? &nbsp; Enterprise is interesting one too because&nbsp; we've seen so much incredible adoption in the&nbsp;&nbsp; Enterprise and it's sort of objectively crazy to&nbsp; try to take on building a developer business and&nbsp;&nbsp; a consumer business and an enterprise business&nbsp; and all at once. But the story there is in like&nbsp;&nbsp; month one or two, it was very clear that most&nbsp; of the usage was work usage, actually much more&nbsp;&nbsp; than today where you've got so many consumers on&nbsp; the product and it's kind of sort of transcended&nbsp;&nbsp; into pop culture. But at the time it was writing,&nbsp; coding, analysis, that kind of stuff. And we were&nbsp;&nbsp; pretty quickly in organically in 90% of Fortune&nbsp; 500 companies in a way that I had seen maybe at&nbsp;&nbsp; Dropbox back when that was my two jobs ago where&nbsp; we had a similar story. And since then there's&nbsp;&nbsp; been more PLG companies. But the real reason&nbsp; we did Enterprise, remember we were debating&nbsp;&nbsp; should we do enterprise or should we launch an&nbsp; iOS app because that's how small the team was. &nbsp; The reason we did is we were starting to get&nbsp; banned in companies because they all felt&nbsp;&nbsp; rightfully or wrongfully that the privacy and&nbsp; deployment story, et cetera wasn't there. So,&nbsp;&nbsp; I was just like, "Man, we have to do something.&nbsp; We're going to miss out on a generational&nbsp;&nbsp; opportunity to build a work product." And&nbsp; we've literally defined AGI as outperforming&nbsp;&nbsp; most humans at economically valuable work or I'd&nbsp; probably [inaudible 00:43:45] that, but I think&nbsp;&nbsp; that's the way we put it. And so, I feel like&nbsp; we had to be present there and it was a fairly&nbsp;&nbsp; quick decision at the time, but it's grown into an&nbsp; immense business. We just hit 5 million business&nbsp;&nbsp; subscribers up from 3 million, I think a month&nbsp; or two ago. So, it is kind of the spinoff that&nbsp;&nbsp; it's taking a life of its own that I'm really,&nbsp; really excited about for [inaudible 00:44:11]- &nbsp; That is a lot to be handling the platform&nbsp; essentially the API, the consumer product,&nbsp;&nbsp; the fastest-growing, most successful product in&nbsp; history and also the B2B side, which is clearly&nbsp;&nbsp; a massive business. Do you have any kind of&nbsp; heuristics for how to make these trade-offs do all&nbsp;&nbsp; this at once and stay sane and be successful?