================================================================================
YOUTUBE VIDEO EXTRACTION
================================================================================
VIDEO_ID: vvlE8-MzxyA
URL: https://www.youtube.com/watch?v=vvlE8-MzxyA
TITLE: Dylan Patel on the AI Chip Race - NVIDIA, Intel & the US Government vs. China
CHANNEL: a16z
PUBLISHED: 2025-09-22
DURATION: 1h 38m 58s
VIEWS: 72,432
LIKES: 0
COMMENTS: 136
TAGS: a16z, andreessen horowitz

DESCRIPTION:
----------------------------------------
Nvidia’s $5 billion investment in Intel is one of the biggest surprises in semiconductors in years. Two longtime rivals are now teaming up, and the ripple effects could reshape AI, cloud, and the global chip race.

To make sense of it all, Erik Torenberg is joined by Dylan Patel, chief analyst at SemiAnalysis, joins Sarah Wang, general partner at a16z, and Guido Appenzeller, a16z partner and former CTO of Intel’s Data Center and AI business unit. Together, they dig into what the deal means for Nvidia, Intel, AMD, ARM, and Huawei; the state of US-China tech bans; Nvidia’s moat and Jensen Huang’s leadership; and the future of GPUs, mega data centers, and AI infrastructure.

Timecodes: 
0:00  Introduction
0:29  Nvidia and Intel: Unlikely Allies
2:11  Investment and Capital in Semiconductors
4:27  The Impact on AMD and ARM
5:21  China’s AI Chip Race: Huawei’s Rise
14:01  The HBM Bottleneck and Manufacturing
19:00  Nvidia’s Global Competition: The Huawei Threat
22:32  Jensen’s Next Move: Nv
... [truncated]

SUBTITLE AVAILABILITY:
----------------------------------------
Total languages: 157
English available: True (auto)

EXTRACTED CAPTIONS:
----------------------------------------
Method: easysub-api
Language: en
Word count: 20,004

TRANSCRIPT:
----------------------------------------
How you buy GPUs, it's like buying cocaine. You call up a couple people, you text a couple people, you ask, "Yo, how much you got? What's the price?" If you're two arch nemesis suddenly team up, it's the worst possible news you can have. I did not see this coming. I think it's amazing development. Like a Warren Buffett coming into a stock. Jensen is like the Buffett effect for the semiconductor world. It's kind of poetic that everything's gone full circle and Intel's sort of crawling to Nvidia. Dylan, welcome back to the podcast. Thanks for having me. Yeah. Uh, it just so happens that there's some big news just as we're as we're having you. Nvidia, uh, announcing $5 billion investment in Intel and them teaming up to jointly develop custom data centers and PC products. What do you think about the collaboration? I think I think it's hilarious that like Nvidia could invest, it gets announced, and their investment's already up 30%. $5 billion investment, a billion dollar profit already, right? Like I think it's fun because uh they need their customers to really uh have big buy in. So when their c potential customers uh buy in and commit to certain types of products, it makes a lot of sense, right? And it's kind of uh funny in a way because in the past um there was this whole like thing around how Intel was sued for being anti-competitive with their chipsets and Nvidia actually got like a settlement from Nvidia uh Intel right way back when when like the graphics were separate from the GPU and the the graphics were really put on the chipset which had like all this other IO um like USB and all this stuff. Um, so, so it's kind of a a a funny like turn of events that now Intel is going to make like a chiplet and package it alongside a chiplet from from Nvidia and then that's like a PC product, right? So, you know, it's kind of poetic that everything's gone full circle and Intel's sort of crawling to Nvidia, but actually it might just be the best like device, right? Um, I don't want an ARM laptop because it can't do a lot of things and so an x86 laptop with Nvidia graphics fully integrated would be probably the best product in the market. Um, so are you optimistic? How how do you think this will go? I mean, sure. I mean, I hope I hope, right? I'm I'm I'm a perpetual optimist on Intel because uh I have to be I was thinking that uh the structure of the deal that at least like a lot of the government folks and uh Intel were sort of trying to go for was people give you know big customers and the biggest suppliers directly give capital to Intel. Um, but this is sort of the other way around where they're buying some of the stock uh having some ownership, but they're not really like diluting the other shareholders and then the other shareholders will get diluted slash everyone will get diluted when Intel finally does raise the capital from the capital markets. But because they've announced these deals and they're pretty small, right? Five billion Nvidia, two billion Soft Bank, um, US government was 10. Um, you know, the these are still relatively small. Pretty small. Yeah. Yeah. On the nature of things, right? I mean like uh you know last time I think I said Intel needs like $50 billion right now. Now when they go to the capital markets it's it's better and may and and and hopefully they get another you know couple of these announcements maybe uh you know there's there's all sorts of speculation that Trump is involved in you know sort of um getting these companies to invest uh Nvidia um and now now you know the government as well of course and now you know is Apple going to come invest right and also do something with Intel or who else will come in and that'll really boost investor confidence and they can dilute slashgo get debt like a Warren Buffett coming into a stock. The Jensen is like the Buffett effect. So, the semiconductor world. Um, Guido, you were the CTO of the Intel data center and AIBU. Yep. What are your thoughts? I think it's really good for customers and consumers in the short term, right? Having having both Intel and like specifically for the laptop market, right? Having the two collaborate is is is amazing. Um it I wonder what's going to happen with any of the internal graphics or AI products at Intel, right? They might just push a reset and give up on that for now, right? They currently don't have anything competitive, right? There was the Gaudi F4 that's more or less done, right? There was the internal graphics chips which never competed really at the high end, right? So from that perspective, it makes a lot of sense, right? It's um for for for both sides. Look, I think the for Intel, they needed a breath of fresh air, right? They were sort of desperate. So I think it's it's a very good thing. I think AMD is [ __ ] right? I mean, they're you're just if if your two arch nemesis suddenly team up, right? That's the worst possible news you can have, right? They were already struggling, right? Their their cards are good. Their software stack is not, right? They they were getting very limited traction, right? They now they now have a bigger problem that side. I think ARM is a little bit screwed as well, right? Because they their their biggest selling point was sort of like look, we can partner with everybody that doesn't want to partner with Intel. And there in a sense they're number one, you know, like Nvidia is probably the most dangerous of the future CPU competitors, right? And so they now suddenly have access to Intel technologies and might get in that direction. It it remixes the card, right? It's it's I did not see this coming. I think it's it's amazing development. Yeah. Will be very interesting to see this play out. Um to Eric's point, packed news uh week. Um, the other thing that we wanted to pick your brain on since we have you here, Dylan, is the other news dropping on Huawei unveiling their kind of AI roadmap. And, you know, obviously they're hyping up the capabilities. Um, I think you guys have been sort of ahead of the curve of trying to gauge, hey, what what can the 950 supercluster actually do? Um, but would love your thoughts on everything that's going on from the China front, right? And this kind of coupled with Deep Seek saying their next models are going to be on domestically produced Chinese chips. the Chinese government uh kind of banning companies from buying the uh produced specifically for China Nvidia chips. So there's just sort of a lot of dominoes falling right now and the semi market in China. But would love your take overall and I mean drill into some uh detail. Yeah, I think when you sort of zoom out to even like you know let's let's let's walk from 2020 because I think it's really important to recognize how cracked Huawei is or even just historically like they've always been really good. Sure, initially they stole like Cisco uh source code and firmware and all this stuff, but then they rapidly passed them up as well as every other telecom company. In 2020, they released uh an Ascend chip and submitted to impartial public benchmarks and they were the first to bring 7 nmter AI chips to market. They were the first to um have that right now. You could still say Nvidia was ahead uh but the gap was like like nothing, right? And this is when they could access the full foreign supply chain. This was when they just passed Apple to be TSMC's largest customer. They were, you know, clearly ahead of everyone on a manufacturing supply chain sort of design standpoint on in a total basis. Right now, of course, Nvidia still had higher market share, but it was so nent then like it could have they could have really taken over the market. Quali got banned by the Trump one administration from accessing and then it went into effect in 2020, right? The the full ban. And so they were only able to make a small volume of these chips, but they had trained significant models on these chips that they made then. And then over the next couple years, right, Nvidia continued to accelerate. Huawei because they were banned from TSMC had to go and try and figure out how to manufacture at SMIC, the domestic TSMC. Um and then they were also in parallel trying to go through shell companies to manufacture uh at TSMC and acquire memory from Korea and so on and so forth. So by the end of 24 they had this had gotten in full swing and it was uh caught, right? It was caught and they finally shut it down. But they were able to acquire three million uh chips, 2.9 million chips from TSMC through these other entities, right? Uh roughly $500 million worth of orders. Um which which ends up being a billion dollar fine that the US government gave TSMC if I recall correctly or at least there was a Reuters article. I don't know if I they actually issued it which is which is important and interesting to gauge because the number of ascends floating out there is not has not consumed this entire capacity yet right so now we get to 2025 right the H20 got banned in the beginning of the year um Nvidia had to write off you know huge amounts of money uh our our revenue estimate for Nvidia and China for just H20 was north of 20 billion because that's what they were booking in capacity slash had to write off and and it got banned. They cut the supply chain. Like they just said, "No, we're not doing this anymore." They had their inventory gets reapproved. They resell the inventory. But now they're like, "Do we even restart production?" Um is is Nvidia's question. And and now you have China saying, "Hey, like we don't need Nvidia. We have domestic alternatives, right? Whether it be Huawei or Cameracon. Um these companies have, you know, capacity, but most of this capacity is de is still foreign produced, right? whether it be wafers from TSMC uh memory from Korea, right? Samsung and SKH Highix. So the question is sort of like how much can they do domestically and there's sort of two fronts there right there's the logic i.e replacing TSMC and there's the memory i.e replacing cinx, Samsung, micron. And on the logic side, they are they're behind, but they're really ramping there. And I think they can they can sort of get to the production capacity uh estimates needed. And the US is still allowing them to import all the equipment necessary pretty much. Uh the bands are really for beyond the current generation of techn beyond 7 nanometer. The the the bands are really for 5 nanometer and below. Um even though the government says they're for 14 nanometer, the the actual equipment that's banned is only for below seven nanometer. And so they'll be able to make a lot of seven nanometer AI chips and maybe even get to five with you know using existing uh equipment for five nanometer rather than using uh rather than like taking the new techniques. And so like there's the logic side and then there's the memory side. And the the aspect of Huawei's announcement that was surprising was that they're doing custom memory, right? Yeah, that's that's the part that is sort of like, hey, this is really exciting. They announced, you know, two different types of chips for next year. Um, one that's focused on recommendation systems and prefill and then one that's focused on uh decode. There's the trend these days. Yeah. So, and at NVIDIA, the same thing. They just announced a prefill specific chip recently. Um, there's numerous AI hardware startups that are really focusing on pre-fill versus decode. And so, this sort of split of inference up into two workloads. you know, Huawei is doing the same thing for their next year chip. And what's interesting is the decode one has, you know, custom HBM. What does that mean? What is the manufacturing supply chain because that that's the that's the one that's tricky, right? How much can they manufacture of that custom HBM? And Nvidia and others are also adopting custom HPM only starting next year, right? So, it's not like, you know, yes, the manufacturing capacity is not there. The maybe maybe it consume it is going to consume a bit more power. it's going to be slightly lower bandwidth, but the fact that they're able to do, you know, some of the same things that Nvidia's plans to do, AMD plans to do in their memory uh is is, you know, evidence that they're catching up. But then, you know, the the main question that remains is production capacity. So, as far as like, hey, Nvidia's banned in China, right? Like, they're saying don't buy Nvidia chips. I think for a period of time, that's fine because fine for China, right? From a perspective of, hey, I'm China. That's fine because you have all this capacity that you, you know, shipped in uh in 2024 that you haven't turned into AI chips. Now you're turning them into AI chips. You're running all that stockpile down. Um what about the transition from running that stockpile down to ramping your new stuff, right? And that that that transition is the one that's really tricky. China's either shooting itself in the foot by not purchasing Nvidia chips during that time period or China's able to ramp. Um I think they'll be able to ramp. I think it'll take a little bit longer. Um and there will be like a sort of a gap uh in between where China probably backtracks and says it's fine like like bite dance and is like begging for Nvidia chips, right? Like they they don't want to use uh they use some Cambercon, they use some uh Huawei, but they really want to use Nvidia because it's way better. They don't care about like the domestic supply chain. They want to make the best models. They want to deploy their AI as efficiently as possible. And so this is like, you know, the the government can mandate them to like not do it, right? So So it's not that Nvidia is not competitive, it's that the government is sort of trying to um instigate it. And and then like I guess the the the last sort of thing is like, you know, there's always the argument of like, hey, if if if banning Nvidia chips to China is so good for China, why didn't China do it for itself? And they're finally doing it for themselves. So again, like it'll be interesting to see. smuggling is still happening, right? Reexportation of chips from, you know, other countries to China, that is still happening uh at some volume, low volume. Um lower lower medium volume, right? Then you know the direct shipments of Nvidia chips that are legally allowed to China are not necessarily happening today but may may have to restart at some point because China won't have the production capacity to you know they would just have so many fewer AI chips being deployed domestically versus the US and at some point you kind of have to pick like am I am I all about the internal supply chain or am I all about chasing you know super powerful AI. Yeah. So is is is there is there an angle here about a negotiation angle as well because currently there's still discussions ongoing what exactly are the boundaries what can be exported to China. So these are sort of welltimed announcements if you want to make a point um that you know US should allow more exports is do you think that's a factor or not? Yeah. So, so I, you know, in the report we did a few weeks ago about uh the production capacity of Huawei um and the supply chain, there was a bit in there that we wrote about how you know honestly like if you are China and you want Nvidia, you do want Nvidia chips actually, how do you play this, right? And and and it's by it's by hyping up your domestic supply chain and it's by it's like it's like yes, we can do everything. It's Huawei announced the most crazy [ __ ] possible. announced seven years of [ __ ] or three years of road mapaps that are so they read your report basic question I think I think they do I mean they were already b and then like say we're banning Nvidia right like and then it's like then the government official is going to think alongside sort of like lobbying from domestic players like of course we want to ship them better AI chips like we're losing this market we can't lose this market u and it's sort of like it is 10,000 IQ right and and and we're here playing checkers while they're playing chess well So, I guess negotiating trip aside, um, in that report you talked about HBM or high bandwidth memory being a bottleneck to Huawei, um, to your point on one of the surprising aspects of the announcement. Do you do you think it's credible that it's no longer a bottleneck based on what they're saying or are they is it just hype? I think I think production capacity wise it is still absolutely a bottleneck. They um certain types of equipment required for making HBM need to be imported. They're working on domestic solutions, but as far as we know, they have not imported enough equipment for this. Although um if you look at Chinese import data uh for different types of equipment, right, there's there's sort of like fabs spend, you know, roughly it depends on the process technology, but fabs spend roughly different amounts of money on lithography, etch deposition, metrology, right? Like these different steps. Um and historically lithography has hovered around u you know 17 18% with EUV it it grew to 25%. Right. Um but China because they they wanted they they sort of like wanted to stockpile lithography and they were worried about the coming ban. They were importing lithography at a much higher rate than that right like 30 40% of their equipment imports were lithography and they were just stockpiling lithography equipment. this is sort of like reversed now in that like hey if I want to and so if you look at the monthly import export data both into provinces in China but also out of countries uh you can see that etch etch uh specifically is skyrocketing and and the main thing about um you know stacking HBM is that you have to you know when you have each wafer you have to etch create like this thing called a through silicon via so it can connect from the top to bottom and then you stack them on top of each other right 12 high 16 high for HBM that's how you make super high bandwidth memory and and their imports for etch is like skyrocketing now. So it's like it's it's they don't have the production capacity yet. How fast can they ramp it as a function of how much equipment can they get? A and B like the yields, right? Improving yields is really hard on manufacturing. Intel and Samsung are really good and TSMC is just amazing. Not not that those companies suck, like I think is a better way to put it. And and so you know it's those two things. I think yield they haven't even started production of highspeed of of HBM3 right they they've only done some sampling of HBM2 HBM 3 came out like a few years ago so there there's still quite a bit of ways on like going up the learning curve I I obviously I expect them to catch up faster than it took you know the technology to be developed because it exists right um in the world we know how to do it it's just a m matter of actually doing it versus uh inventing it um and then the other one is sort of the production capacity uh you know a couple months of import export data is not enough to you know set up for you know years worth of supply chain buildup right which is what we have today in in Korea um for the Korean companies now Heinix is also investing in the US in Illinois and then Micron's primarily in Japan the American memory companies primarily in Japan and Taiwan but they're also expanding in Singapore and the US now like there's so much capital that's been invested it would take some time for China to build up that production capacity to actually match the west and when I say the west I mean East Asia uh in production in non-China East Asia in production capacity so it'll take some time to get there and I don't think I think it's like hey we can design this it's it's always a question of can we manufacture and then and then the thing like that Jensen would say is like you're betting on China not being able to manufacture like right you know that's a it's a matter of when not uh if and that's the whole calculus that like I think the US government has to be aware of when they're like, hey, what level of AI chips do we sell? Do we sell everything? Um, probably not because AI is far more powerful and a large the end market of AI is going to be way larger than the end market of semiconductors and equipment. Do we sell, you know, what level do we sell at? Well, how much can China make at each specific, you know, sort of performance tier? And then, you know, analyze that and what's the volume and then figure out like what is okay, which is like maybe a little bit above or around the same level. Yeah. So, so um if you to your point on like playing chess versus checkers, if you're Jensen, what would your next move be given the situation at hand? It's both like partially true that he's afraid of Huawei more than he is like an AMD, right? He called them formidable. Yeah. Well, like I mean like every other like Huawei's beat Apple, right? They they passed Apple up in TSMC orders. They passed Apple up in phone market share. uh not in the US but like in many parts of the world um before the bands came down and then even now they're growing back again in market share without like western supply chains. Um you know they they've done this to numerous other industries. I would say Apple's like a formidable competitor right like they they've beaten a lot of industries and so it's it's reasonable that he's afraid of them. It's it's sort of you know and he's not afraid of A and B. So like I think like the best thing is like try and sew as much like Huawei what Huawei announced is reality rather than like their hope target. Yeah. Um and so away all doubt on manufacturing capacity which I think is not fair right like I think manufacturing capacity is a real uh bottleneck for them. Um, and then the yield learning is a real bottleneck like temporary maybe. Um, we'll see how long and we'll see how fast the rest of the, you know, the Nvidia technology advances past what Huawei is capable of, right? Um, and and how fast Huawei is able to close the gap. But I think I think his main sort of pitch would be Huawei is is real. They're a formidable competitor. They're going to take over not just the Chinese market, but also uh foreign markets, right? whether it be uh the Middle East or Southeast Asia or South Asia or Europe or Latam, right? Everywhere besides America and the the sort of there's a I think I think uh Noah Smith has this analogy, right? This whole idea is that you should go China, right? Make them have their own domestic industry that is so different from the rest of the world, right? kind of what happened with Japan in the 70s and 80s there and and 90s, their PCs were so specific and hyper optimized to the Japanese market with like you know the weird like I don't know if you've seen the weird scroll wheel on the on these Japanese PCs like you literally like it's like you go like this and it scrolls right and it's like and then the touchpad is a circle and then that's around it. It's like things like that are so weird. Totally. And the rest of the world doesn't care but Japan market likes it, right? His whole idea is like let's go them i.e. keep their technology within China and then that's like dead weight loss and they never expand outside versus uh that we serve the whole world. But the whole risk is that the opposite can also happen, right? Our our technologies is hyper optimized to running you know uh language models at this scale and RL and you keep you keep like hardware software codeesign can take you down a tra path of the tree that like is a dead end and then China like because they're not allowed to access this tree. They're like, "Oh, okay." And then they end up in the like optimal spot, right? We we hit a local minima. They had a local local maxima. They had a local uh a global maxima, right? Like that that sort of like technological goalposting is sort of what Noah Smith's analogy is. I like it a lot. Um I don't know if it's accurate, but uh it's an interesting one. Yeah. Yeah. I love that. Um well, actually, maybe just taking a step back from current events, uh even though there's so much to talk about right now. Um, last time you appeared with us, Nvidia came up obviously. Uh, and you talked about a couple of the potential paths forward for Nvidia. Give us maybe the bull case, the bare case. Fair enough. There's a lot embedded in their numbers now. Uh, but what's interesting is um consensus for uh the banks is is like for across like this the hyperscalers. So uh Microsoft, Corore Reeve, Amazon, Google and Oracle, right? Uh Meta, right? So it's the six hyperscalers, right? Who I would consider hyperscalers. The consensus for the banks is $360 billion of spend next year across all of them. Um and my number is closer to like it's like 450500. Um and that's that's based on like you know all the research we do on like data centers and like tracking each individual data center the supply chains, right? So, so, so this is just Nvidia spend. This is this is capex for the hyperscalers, right? And then capex gets split up across different companies, but the vast vast majority still goes to Nvidia, right? Um, and Nvidia is in a position not where they take they can't take share, right? It's they grow with the market defend share. Yeah. Um, and so the question is like how fast is the growth rate of of capex for hyperscalers and other users, right? And the reason I included Oracle and Core as hyperscalers even though they're traditionally not called hyperscalers is because they are OpenAI's hyperscaler. Right. Right. So you know when you look and you look at the Oracle announcement, right? Like uh first of all the Oracle announcement I don't understand why people don't think this is crazier. They did the most unprecedented thing in the history of like stocks and and public and companies ever. They gave a four-year guidance. Um, and it made Larry the richest man in the world, you know, like all these things. Anyways, you know, the the question is like how fast does revenue grow, right? Do you think Oracle and Open Do you think OpenAI, which signed a $300 billion plus deal with with Oracle, will actually be able to pay $300 billion, right, across raising capital and revenue. And I think most and and and it gets to a rate of like over 80 billion over $90 billion a year uh in just a handful of years, right? So it's like h do you believe the market will grow that fast? Um it's it's very possible. Yes. And it's very possible for like you know OpenAI what is their revenue going to be exiting next next year? Some people think 35 billion. Some people think 40 billion. Some think people think 45 billion. You know ARR by the end of the year next year. This year they hit 20 right? Um ARR you know. So, so if that growth rate is maintained, then all of that cost goes to compute plus all the capital they continue to raise, right? And again, there are financials that they sort of like gave to investors for their last round was like, hey, we're going to bend we're going to burn like $15 billion next year. It's probably more likely going to be like 20, but like you know, and you stack this on and they're not turning a cash flow. They're not going to be profitable until 2029. So you sort of have like they're going to continue to b burn 15 202$25 billion of cash each year plus revenue growth that's their compute spend and you do this for enthropy you do this for open air you do this for all the labs it's very possible that the pi does get to you know you know more than 500 you know not 360 billion next year 500 billion next year and for cap total capex and the pi continues to grow for hyperscalers Nvidia says actually it's going to be multiple trillions a year on AI infrastructure and he's going to capture a huge portion of it. That's his bullcase, right? That's the bullcase is is AI is actually um so transformative and the world just gets covered in data centers and and the majority of uh your interactions are with AI whether it's like you know business productivity and telling an agent to do some code or you're just talking to your AI girlfriend Annie right like it doesn't matter um you know all of this is running on Nvidia for the most part the bare case is you know even if it does grow a lot so yeah the bull case for a second I think fundamentally the value creation I think personally is there right I mean trillions of dollars of value with AI I can totally see this happen so assume it's true where will Nvidia top out I guess how how much do you believe in takeoffs right yes uh yeah so like if there if there is like a takeoff scenario right where like powerful AI builds more powerful AI or you know that creates more and more you know each level of intelligence like uh enables more for the economy right like how many how many monkeys can you employ in your business versus how many like humans right you know sort of the same or how many dogs right like you know there's sort of like what is the value creation of a human versus a dog sort of like the same with AI so so like I mean in in this case the tr the value creation could be hundreds of trillions if not you know the after that I mean do you do you even need this I mean if you take every white collar worker make them twice as productive with AI that's in the hundreds of trillions isn't it yeah but like what is what is twice you know like I mean If you talk to people at the labs, right? Like twice as productive. What does that even mean? It's replaced them, right? It's be 10 times better than death. Like I mean like I don't I don't know how soon if sort of if a sort of white color work is essentially useless without a constant stream of LM tokens, right? That make him that make him productive, right? At that point, you basically can can tax every single knowledge worker in the world, right? Which is most most workers in the world long term. Yeah. So so I don't know. I mean what's what's your guess? Give give us a number. What's the cap for cap? I mean like why why aren't we making a matrioska brain? Like I don't know like uh like uh I mean at some point the the machine says humans don't need to live and we need I need even more compute. One step before that maybe are we are we are we colonizing Mars yet? TBD. Yeah. Um I I don't know man. It's it's it's I I find it like completely like impossible to predict anything beyond 5 years given how much stuff is changing. like a linear time is a large number. I'll leave them to economist, right? Like you know like honestly like you know supply chain stuff is like three four years out and that's it. Yeah. Um and then fifth year is like sort of like yolo, right? Um so like I I just try and ground myself in the supply chain stuff right like it's like uh you know supply chain and then like what is the adoption of AI and what's the value creation? what's the usage like? And you can see that in like a a short horizon beyond that like I don't know like are we all going to be connected to computers like BCIs and stuff like I don't know dude um are humanoid robots are they going to be you know I mean you saw Elon's thing right like he's like yeah humanoid robots are why Tesla's worth more than 10 trillion okay great what is all that being trained on great Nvidia okay awesome so that's worth also 10 trillion right like I don't I don't know like uh it's too it's too out there for me I don't like the out fair discussions. Very fair. Um, read some sci-fi books. So, um, so just pulling out the thread where you talked about, I mean, this is kind of a throwaway comment, but how market share can't really grow just because of it's such a dominant market share. And, uh, we talked about or you guys talked about the moat of Nvidia last time. Um, and obviously this moat is tied to maintaining that very high market share that they current currently have. Um, and I love this sort of historic journey you took us through with Huawei just earlier. Um, can you kind of walk through what Nvidia did throughout history to build their moat? It's super awesome because, you know, they failed multiple times in the beginning and they bet the whole company multiple times, right? Like Jensen is just crazy enough to bet the whole company, right? like um whether it was like certain chips, ordering volume before he knew it even worked and it was like all the money he had left or like ordering volumes for projects he had not won yet. Like I heard a rumor that or not a rumor but like a story from someone who's like a graveyard in the industry and I think would know was like yeah no no like Nvidia ordered the volume for the Xbox before Microsoft gave them the order. They're just like literally he was just like, "Fuck it. YOLO." Yeah. Right. Um I don't I don't know like I don't know how real true this I'm sure there's more nuance there like you know verbal indication or whatever but like the order was placed before he got the order right like is is what he said. Um, you know, there's there's cases like with the crypto bubbles, right? Like there was a couple of them, but like Nvidia did their damn best to convince everyone the supply chain that it wasn't crypto and that it was gaming and that it was durable, real demand and it was gaming and data center and and uh professional visualization and therefore you guys should ramp your production. and they all ramped production and spent all this capex on increasing production and and building out new lines for them and they pay they pay per item and then they bought them and sold them at and made shitloads of money and then and then when it all fell apart they just had to write down a quarter's worth of inventory whatever. Yeah. Everyone else was like well crap I have all these empty production lines right and so it's like you know but but like what did AMD do then? Right. their chips that were actually better for cryptomining, right? On a on a, you know, amount of silicon uh cost versus how much you hash, but like they just didn't they AMD was like, ah, we're going to not really raise production, right? Like as a reasonable, you know, thing, right? It wasn't a so sort of like strike while the iron's hot. And so like, you know, the same has happened with Nvidia, right? They've uh in recent in recent times like sort of they've ordered capacity that no one believes, right? multiple times. Um they they see the in demand obviously, but in many cases they're just like their number for like Microsoft was higher than Microsoft's internal planning, right? And and then Microsoft's internal planning went up, but like their number for Microsoft was way higher. And it's like ah we just don't think Microsoft's going to need this much even though they tell us this. It's like who the heck is like no no no customer, you're going to buy more like and and orders, right? And then and then when the orders come through the supply chain it's like I have to put pay NCNR right non-cancold non-returnable like you know this is uh I asked a question in Taiwan once uh there was like a it was it was Colette which is the CFO and Jensen CEO they were they were both there um and it was it was a room full of like mostly finance bros and they were asking stupid finance questions like three days before earnings so obviously they just could not answer anything because it's like you know SEC regulations but then my question to them was Look, Jensen, you're like so vibes uh like driven and like very gut feel and like very visionary. And then Colette's, you know, CFO, like she she's amazing in her own right, but like you know that those those personalities clash. How do you work together? And he's like, I hate spreadsheets. I don't look at him. I just know, right? Like is his response. And it's like, of course, you know that the best innovators in the world have really good gut instinct, right? Right. And so like the gut instinct to like order with you know with non-cancable when you don't know and they've had to write down over their history multiple times right many many billions of dollars in accumulative orders right so accumulate in total orders whether it be you know the H20 which is more regulatory but like other cases they've ordered and had to cancel um is that many billions it's many billions peanuts well it depends right the crypto writedown was like multiple billion when their stock was like less than 100 billion, right? Like it's like a you know it's it's peanuts compared to the upside, right? I think everything you did was right and I think everything AMD did was wrong like you know in that in that scenario but like it it is it is crazy to especially in a cyclical industry like semiconductors where companies go bankrupt all the time which is why we have all this consolidation is every down cycle companies go bankrupt. I mean, if you look at from a risk return perspective, right, these bets were totally worth taking. Yes. If you look at it from I'm a CEO, I want to have, you know, predictable quarters for Wall Street, it's a very different story. And I think that's sort of where part of the tension is from now. Yeah. So, so we we uh I don't know if you've seen these like uh Lee Kuanu edits where they're like him like saying some like fiery speech and then like and then it's like some cool music at the end and it's like showing different pictures of him. And so we made one of Jensen recently and put it on social media, right, on like Instagram, Tik Tok, uh XHS, Redbook, right? Uh Twitter, of course, right? Like all the different social media. Uh and I really liked it because he's like he's like, you know, the goal of like playing is to win and and the goal or sorry and the reason you win is so you can play again, right? And he compared it to pinball where like actually you just play all day and you keep getting more rounds. And it's like his whole thing is like I want to win so I can play the next game. Um and like it's only about the next generation, right? It's only about now, next generation. It's not about 15 years from now because that's it's a whole new playing field every time or five years from now. Um I think that's that's you're right. It's the riskreward is is is correct. Yeah. But there's few people take these kind of risks. It's the only semiconductor company that's worth, you know, I think even north of $10 billion, uh, that was founded as late as it was. Like MediaTek was in the late in the early 90s and then, uh, Nvidia and everyone else is like from the 70s mostly. Yeah. Um, the big ones. Yeah. Yeah. Yeah. I think you raised this great point on these bet the bet the farm and he's actually been wrong a couple times to your point. Mobile, right? Like what the hell happened with mobile? Exactly. and he still takes them. And I think uh Mark actually had this great conversation with Eric where he talked about being founder run where you have this memory of the risks you took to get to where you are today, right? And so in in a lot of cases if you're a CEO brought on later on, you're sort of like, okay, continue to steer the ship as is. Um but in this case, he he remembers all the times they they almost went belly up and he's like, I've got to bet, keep making bets like that. Um, how do you think he's changed over I mean he's been one of the longest running CEOs over 30 he's kind of right up there with Larry Ellison now. Um, how do you think he's changed over the last 30 years or so? Um, I I I mean obviously like I'm I'm 29. I don't freaking know what he was like. Uh I' I've watched a lot of old interviews. Yeah. I won't say he wasn't longer than you've been alive. Yeah. Exactly. Exactly. Like uh Nvidia was founded before I was born. I'm 96, right? you know. Well, yeah. Maybe anything over the last couple of years. No, no, probably better. I think even like watching old interviews, right? Like I watched a lot of old interviews, a lot of old like uh presentations he's given. Uh one thing is that he's just like sauced up and dripped up like way like the charisma he's gotten has only gotten stronger, right? Um which is which is an interesting point. I don't know if it's quite relevant. Totally agree with that. Yeah. Uh but like the man like has learned to be a rockstar more even though he was always charismatic. It was like he's a complete rockstar now. Uh and he was a rockstar you know a decade ago too. It's just people maybe didn't recognize it. I think I think the first live presentation that I watched it was extreme was like um it was what's the what's the cons CES like 2014 or 2015 or whatever. Um he's he's he's it's it's consumer electronics show. I'm I'm like moderating like gaming sub gaming hardware subreddits, right? Like at the time I'm a teenager and like the dude is like talking only about AI. He's telling he's telling like all these gamers about AlexNet and self-driving cars, right? It's like know your audience first of all, but also like like um it's not has nothing to do with consumer electronics. said gaming, you know, at the time I was also like I was half like, "Holy crap, this is amazing." But I also was half like, "I want you to announce new gaming GPU, right?" Like, you know, but I know like on the forums quickly everyone was like, you know, screw this, you know? I want to hear about the gaming GPUs. Nvidia's price gouging like, you know, of course Nvidia's always had the like we price the value and like plus a little bit, right? because we we're just smart enough to know, you know, I'm guessing Jensen just has the gut feel of how to price things, right? He he'll change the price like at least on gaming watches, he'll change the price up until like right before the presentation. Wow. So like it really is like a a gut feel thing probably. Um and anyway, so so he he had that charisma to know what was right, but I think people a lot of people were like, "Oh, no, whatever. Jensen's wrong. He doesn't know what he's talking about." But now like he he talks people are like, "Oh, very very uh you know." So it might just be that he's been right enough. Yeah. There's a post on X recently that said he had moved up into god mode with a select group of CEOs, but that this was re like it's exactly who who's god who's who's the other gods? Uh it was Zuck. Um who are the other gods? Elon. Elon Elon Zuck and Jensen. Nice. Nice. Okay. Crew to be in. So So we pray to Silicon Valley. Yeah, sort of the cold now is it? Exactly. Um, just on one more one last thing on people, you mentioned Kallet, his CFO. Um, and you know, there's there's sort of a famously loyal crew at Nvidia even though all of the OGs could retire at this point. Um, is there anyone akin to a Gwyn Shotwell at SpaceX or previously a Tim Cook to Steve Jobs at Apple that is at Nvidia today? I mean, he had two co-founders, right? Like that's, you know, let's not overlook that. Um, one of them, one of them's like, you know, not involved and hasn't been for a long time, but the other one was involved up until just a, you know, few years ago, right? Uh, so it's not just Jensen running the show, right? Totally. Uh, although he was running the show. Um, there's quite a few people on the hardware side. Um, I've always, uh, there there's someone at Nvidia that's like mythical to me. Like when you talk to the engineering teams, he leads a lot of the engineering teams. Um he is a private person so I don't want to say his name actually. Fair enough. Um but you know he he's he's he's like uh he's like effectively like chief engineering officer is like his role. Um and people within his org will know who he is. And um I think I think there are people like that. But you know there there there he's intensely loyal and there's there's a number of these types of people. There's another fella who's like, you know, like there's all these like innovative ideas at Nvidia and he's the guy who literally is like we need to get this silicon out now. We're cutting features. And that's like that's like what he's famously known for. And all the technologist in Nvidia hate him. This is this is like a second guy. There's a second guy also intensely loyal to Nvidia. Has been around for a long time. But it's like, you know, sort of like when you have such a visionary company and forward, you know, one one problem is that you get lost in the sauce, right? you know, oh, I want to make this. It's got to be perfect, amazing. It's like, you know, you got to have that sort of like and and these people are like, you know, obviously they're close to Jensen for a reason because Jensen also believes like these things, right? Have the visionary future looking, but also like screw it, cut it, we'll put in the next one ship, right? Like, you know, ship now, ship faster, like um in a space like silicon, which is like really hard to do. Um and and and sort of like the thing about Nvidia that's always been, you know, super impressive and it's from the beginning days, right? He's talked about this before is their first chip, their their first successful chip, they they were going to run out of money and he had to go get money from other people um to even finish the development and even then he just had enough money because he'd already had a failed chip before this um was the chip came back and it had to work otherwise it would not you know and so they they were like because they could only pay for it's called a mask set right basically you put these like I'll call them stencils into the lithography tool and then it like says where the patterns are and you know, you put the stencil in, you deposit stuff, you etch stuff, you deposit materials on the way for etch it away. Um, and you put the stencil in and like you you like tell it where to put stuff, right? And then the the deposition and etch keeps happening in those spots and you stack dozens of layers on top of each other and you make them a chip. These stencils are custom to each chip, right? And they cost today in the orders of tens and tens of billions of dollars. Uh, but even back then it was still a lot of money. Um, it it wasn't that much then, of course. Um, you know, it it sort of he could they could only pay for one set. Um, but the typical thing with semiconductor manufacturing is, you know, as good as you can simulate, as good as you can do all the verification, you'll send a design in and you have to change it. There's going to be something. It's it's so hard to simulate everything perfectly. And the thing about Nvidia is they tend to just get it right the first time. Yeah. Um, even like even great executing companies like AMD or Broadcom or whoever, they often have to ship, you know, they're denoted in like A and then a number or B and then a number. So it's like two different parts of the masks. So like Nvidia always ships a zero almost always. They sometimes ship A1. And a lot of times even if they'll start production of the you know the A is basically the transistor layer then the number is like the wiring that connects all the transistors together. So Nvidia will start production of the A and ramp it really high and then just hold it right before you transition to the metal just in case they do need to change the metal layers. And so like the moment they're ready and they've confirmed that it works, they can just, you know, blast through a lot of production whereas everyone else is like, "Oh, let's get the chip back. Okay, a Z doesn't work. We got to make this tweak. Make this tweak. Get the chip back." Uh it's called a stepping, right? Um at we were very jealous of of Nvidia at that time, right? They consistently delivered in the first one. We did not. That's what it the the the data center CPU group there was one product where you know I said A1 A you know A Z A1 or you go to B if it's you have to change the transistor layer as well so it's like B Nvidia sorry uh Intel got to like E2 once E2 like it's like a 15 revision this is this is this is like the peak of AMD's um market like when they went skyrocketing on market share versus Intel was when Intel was at E2 right like 15 stepping because it's quarters of delay, right? I mean, it's it's it's catastrophic for a go to market. Yeah. Each each time is is a quarter of delay or something, right? Yeah. So, it's it's it's absurd. So, I think that's the other thing about Nvidia is like, you know, screw it, let's ship it, let's uh let's get the volume ASAP. Let's um let's let's, you know, let's do these things that, you know, and and so anyways, they they like, you know, have some of the best simulation, verification, etc. that lets them sort of go from design uh you know from idea to shipment as fast as possible um you know cutting out any unnecessary features that could delay it uh making sure they don't have to do revisions so that they can get you know they can respond to the market ASAP there's a story about how Volta which was the first Nvidia chip with tensor cores um you know they saw all the AI stuff on the prior generation P100 Pascal um and they decided we should go all in on AI I and they added the tensor cores to Volta like only a handful of months before they sent it to the fab like they said screw it you know let's change it and it's crazy and it's like if they hadn't done that who would have maybe someone else would have taken the AI chip mark right so there's all these times where they and it's those are major changes but there's often like minor things that you have to tweak right number formats or like some architectural detail Nvidia is just so fast and the other crazy thing is they have a software division that can keep up with that, right? I mean, if you if you come out with the chip, right, and basically no stepping required, it's immediately in the market, then being ready with drivers and and you know, all the infrastructure on top of that's just super impressive. Yeah, I I love that point because you think of Nvidia benefiting from tailwind after tailwind, but I think both of you are saying you got to be you have to move fast enough and execute well enough and take advantage of those tailwinds. Um, and if you think about and by the way, I loved your CES story. I'm just envisioning him more than 10 years ago talking about self-driving cars. Um, but you know, if you think about nailing the video game tailwind, VR, Bitcoin mining, obviously AI now. Um, you know, one thing that or one of the things that Jensen talks about today is robotics, AI factories. Um, maybe my last question on Nvidia, what do you think about the next 10 to 15 years? Um, I know calling beyond five is hard. Um, but like what does Nvidia Nvidia's business look like? Um it's it's it's really a question of and this is like I think every time I've talked to uh you know some executives at Nvidia have asked this question because I really want to know and you know they won't answer it obviously but it's like what are you going to do with your balance sheet like you are the most high cash flow company in like like you have so much cash flow um now the hyperscalers are all taking their cash flow like way down right? Uh because they're expending on GPUs. Um what what is what what are you going to do with all this cash flow? Right? Like you know even even before this whole takeoff, he wasn't allowed to buy ARM, right? Um so so what can he do with all this capital and all this cash, right? Even this $5 billion investment in Intel is uh there's regulatory scrutiny there, right? Like um it's it's in the announcement like yeah, this is subject to review, right? like, yeah, you know, I imagine that'll get passed, but like he can't buy anything big. He's going to have hundreds of billions of dollars of cash on his balance sheet. What do you do? Is it is it start to build AI infrastructure and data centers? Maybe. Um, but like why would you do that if you can just get other people to do it? Um, and just take the cash. Uh, well, he's investing those, right? Investing peanuts, right? you you know like he he gave recently like a core a backs stop uh because because today it's really hard to find a large number of GPUs for burst capacity right like hey I want to train a model for three months right I have my base capacity where I don't know all my experiments but I want to train a big model three months done we know from our portfolio yeah yeah so so like Nvidia sees this issue they think it's a real problem with startups it's why the labs have such an advantage uh but what if I could you know right now like you know most companies in the uh in the Valley spend what 75% of their round on GPUs, right? Or at least Yeah. with CD. What if you could do 75% in three months on one model run, right? You know, yeah. Uh and and really scale and have some sort of like competitive product and then you have the model, then you raise more capital, right? Or start deploying, right? Um what do you do with it? Is it is it start buying a crapload of humanoid robots and to put deploying them? But like they don't really make good software. They they don't make really that amazing software for them. um in terms of the models right they make you know the layer below is great um where they deploy their capital is is like the question he he has been investing up and down the supply chain a little bit though right investing in in the the neoclouds investing in some of the model training companies yeah but again it's small fries like he could have just done the entire anthropic round if he wanted to of course he didn't right and and then like really got them to use GPUs or like he could have done the entire you know open he could have done the entire like any xai round do you think these are things he should be doing which I mean like yeah good question. I I don't know right. I think I think like we'll quote you over for the next round that we're ra but anyways uh he could he could make venture a dead industry take all of the best rounds put a lot of business. Yeah. You know you could do the seeds and then have Jensen mark you up. That's why no I don't think I don't like it. I think picking winners is obviously really tough for him because he has customers all across this ecosystem. And if he starts picking winners then like his customer his customers will even be even more anxious to leave and give even more effort to whether it's AMD or you know some startup or their internal efforts um etc etc right uh buying TPUs whatever it is like you know people will he can't just like invest in these like you know he can do a little bit right a few hundred million in an open AI round is fine or a few hundred million in XAI round is fine um corewave right like yeah everyone's like throwing a fuss about it but it's like he invested did a couple hundred million plus you know early on plus um you know rented a cluster from them for internal development purposes instead of renting it from a hyperscaler which is cheaper for Nvidia to do right it's better for them to do it from them than the hyperscalers it's like did he really like is he really backstopping or coreweave that much right um or you know any of the other customers or neo clouds like there's some investment but it's like it's more like this is a good cloud you know we'll throw like five or 10% of the round, right? It's it's not he's taking 50% plus of the round. Is he also reshaping his market? I mean, look, a couple of years ago there were four big purchases of these cards. You just listed six. To what extent is that that him and Nevius and there's a long list there of course. Yeah. Is is there is that a strategy? It is. I think it absolutely is. Um but he didn't have to put much capital down to do this. Like what does Chip one earlier than the other? I don't know. Yeah, that's No, but it's like if you look at the grand amount of capital that he spent investing in the Neoclouds, it's it's it's few billion, but he has a lot of other levers if he wants to. Right. Right. Um allocations as you mentioned. Um what's nice is, you know, historically you gave volume discounts to hyperscalers. Uh but because he can use the argument of antitrust, he's like everyone gets the same price. Uh as so fair, it's very fair. It's very fair, you know. So what should he do with the C or what should guide his uh I mean I think like you know like there is the argument he should invest in data centers and only the data center layer not the not the not what goes in the data centers so that more people build data centers and then if the market demand continues to grow up data centers and power are not the issue right invest in data centers and power um I've said that to them they should invest in data centers and power not in the cloud layer because the cloud layer is is is is quite com not commoditized but quite um it's it's commoditizer compliment right is the whole phrase And I won't say being a cloud is commoditized, but it's certainly like you have a lot of competitors who are decent now. Um, and and and you've you've educated the commercial real estate and other, you know, infrastructure investment firms into going into AI infra as well. So like I don't think it's the cloud layer that you invest in, right? Um, do you invest in data centers and energy? Yeah. Uh, do you invest it because that's the bottleneck for your growth really. um is is a well how much people want to spend and can spend and b the ability to actually put them in data centers um and then like robotics and like I think there's like areas he could invest in but nothing requires $300 billion of capital so what do you do with the capital like I I really I really don't know and I like feel like Jensen has to have some idea there's some visionary plan here because that's what shapes the company right is I mean they could sell c they they could they could just continue to you know I mentioned 200 million dollar of free cash flow, $250 billion of free cash flow a year. What do they do with it? Like, do they just buy back stock for ever? Like, do they go Apple route? And the reason why Apple hasn't done anything interesting in like, you know, nearly a decade is is, you know, they've got they've got a not visionary at the head. Tim Cook's great at supply chain. Um, and they're just plowing the money into buybacks. They're not really, you know, automotive the self-driving car thing failed. Uh, we'll see what happens with ARVR. um you know we we'll see what happens with wearables right but like meta and openi might be even better than them we'll see like and others right so so what does he invest in I have no clue but nothing what what requires so much capital is the tough question um and actually gets a return because the easy thing is like my cost of equity right I just buy back and doesn't completely change the company culture I think that's another thing right there probably areas you could invest it in but you suddenly end up with the company doing two completely different things which are very difficult to keep on but they they do like 10 completely different things, right? I mean I mean one way to look at it is we build AI infrastructure and in the guise of we build AI infrastructure robots humanoids around the world are AI infrastructure um or or data centers and energy is AI infrastructure right like you know like so the humanoids would totally work right if you suddenly pouring concrete and and building power plants has completely different culture completely different set of people getting much much harder agree there's different ways to do it like invest in the various companies or like uh backs stop like the building of power plants right like, you know, because no one wants to build power plants because they're 30-year underwriting things. Um, you know, there's all these different areas where could it use capital to, you know, allow something to happen, right? Not necessarily owning it himself. And look, look, bear in mind at Intel, one of the biggest problems we had was that our customer base sucked, right? Right. I mean, we were selling to most of the chips went into the large hyperscalers, you know, which they're way too concentrated and they build their own chips and so you can push down your prices. So, honestly, spending it on diversifying the cl, you know, was in 2014, you guys should have just charged so much that your margins were 80%. What would the world have done? Nothing. The margins were pretty good back then. That wasn't the problem. That was the primary problem. They were 60 65. They were 80 still. Yeah. Oh boy. Jensen is Jensen PTSD is kicking in here. Well, wait. I think Guido's comment is actually a really good segue into something else we wanted to talk to you about, which um is the hyperscalers. Uh and one of the reasons that I love reading semi- analysis is you guys make these out of consensus calls that you're often right about. Um and one of them recently was calling only often. But you have a Jensen hit rate. It's very high. Um, but where's my billion dollar, you know, uh, PV positive bet? Um, but, uh, the one that caught my eye was, uh, Amazon's AI resurgence. Um, so I wanted to talk to you a little bit about that just because, you know, I think we found it pretty interesting being on the ground helping our portfolio companies pick who their partners are. Um and so we have some micro data on this, but you sort of walk through why they are behind. Yeah. So in um Q1 2023, I wrote an article called uh Amazon's cloud crisis. Um and it was about all these neo clouds are going to commoditize Amazon. Um it was about how Amazon's entire infrastructure was really good for the last era of computing, right? What they do with their um elastic fabric um ENA and EFA, right? their nicks uh what they and the whole protocol and everything behind them what they do for custom CPUs um etc right like it was really good for the last era of scale out computing and not this era of sort of scale up AI infra um and how Neil clouds were going to commoditize them and how their silicon teams were focused on you know cost optimization whereas the name of the game today is uh max performance per cost right but like that often means you just drive up performance like crazy uh even if cost doubles, you drive up performance more, triples, uh because then the cost per performance falls still. Uh that's sort of the name of the game today with Nvidia's hardware. Um and it ended up being like really good call. everyone like like was calling us out like no you're wrong because and this was like when Amazon was like like the best stock and Microsoft really hadn't like started taking off yet and and nor had like all these other u you know Oracle and so on and so forth and and since then Amazon has been the worst performing uh hyperscaler um totally and the call here is that you know they still have structural issues right they still use um elastic fabric although that's getting better uh still behind Nvidia's networking still behind Broadcom's uh Aarista like type networking nyx um they still use you know their their internal AI chip is okay but the main thing is that they're now waking up and being able to actually capture business right so the main call here is that uh since since that report um AWS has been decelerating revenue year-on-year revenue has been falling consistently and and our big call is that it's actually going to start reacelerating right and that's because of um enthropic is because of all the work we do on data centers, right? Tracking every single data center when that goes online and what's in there. Uh the flow through on cost, right? If you know how much the chips cost, the networking cost, the power cost, uh you you know how much you know generally margins are for these things, then you can sort of start estimating revenue. So when we build all that up, it's very clear to us that they trough on um AWS revenue growth this quarter, right? This is the lowest ads revenue growth will be uh on a year-over-year basis for at least the next year, right? Um and it's reacelerating to north of 20% again. Um because of all these massive data centers they have online with uh cranium and GPUs, right? It depends on which one depends on which customer. Um the experience is not as good as you know say a core or whatever. But the name of the game is capacity today. Um core can only deploy so much. they have to get they only have can get so much data center capacity and they're really fast at building but the company with the most data center capacity in the world that and still today although um they may get passed up in the next two years um is Amazon actually they will get passed up based on what we see is Amazon but incrementally Amazon still has the most spare data center capacity that's going to ramp into AI revenue over the next year is let let me ask a question is that the right type of data center capacity like for the high density AI buildouts today you need, you know, massively more cooling. You need to have enough water close by, you need to have enough power close by. Is is that is it in the right place or is it is it the wrong type of So data center capacity um in this sense I mean all the way from power is secured to substations built to transformers to uh you can provide the power whips to the racks. Now obviously the data center capacity will differ, right? Um you know historically actually Amazon's had the highest density data centers in the world, right? uh they went to like 40 kilowatt racks when everyone was still at 12. And if you've ever stepped inside of foot inside of most data centers, they're like pretty cool um and dryish. If you step inside of Amazon data center, they feel like a swamp. It feels like where I grew up, right? It's like uh it's like it's like humid and hot uh because they're like optimizing every percentage. And so sort of like your pointed here is that like Amazon's data centers aren't equipped for the new type of infrastructure, but when you compare them to the cost of the GPU, like getting getting, you know, having a complex cooling arrangement is fine, right? Um, you know, we made a call on Aera Labs a few months ago, a couple months ago when they were like at 90 and it's it's gone to 250 the month after uh because of what they're what orders Amazon is placing with them. But there's certain things with Amazon's infrastructure. I won't get too much into it, but the rack infrastructure requires them using a lot more of like a Sterolabs connectivity uh products. Um and the same applies to cooling, right? So on the networking and cooling side, they just have to use a lot more of this stuff. But again, this stuff is inconsequential in cost compared to the GPU. Um you can build, right? And my question was more like, look, uh I may need a major river close by for cooling at this point, right? It's in many areas I just can't get enough water. And you know, it's probably power in the same region. There's 2 gawatt scale sites that they have power all sec uh secured. Uh wet wet chillers and dry chillers all secured. Like everything everything's fine. It's just not as efficient, but you know, that's fine, right? Like you know, they're they're going to ramp the revenue. They're going to add the revenue. Um, not that I necessarily think Amazon's internal models are going to be great or hey, their internal ship is better than Nvidia's are competitive with TPU like or their hardware architecture is the best. I don't necessarily think that's the case. Um, but they're they could build a lot of data centers and they could fill them up with stuff that will be rented out, right? And it's it's it's a pretty simple it's a it's a pretty simple uh thesis. How how important has Enthropic been to the co-design for Tradeium? Because I I remember we had a portfolio company, this was summer 2023. They invited them to AWS. They spent, man, I think eight hours with them over the course of uh a week trying to figure out trrenium back then. It was just impossible to work through. Um is that you know that obviously that portfolio company hasn't gone back and and tried it now, but like how how different is it now based on what you're hearing? And oh, it's still bad. just okay. Um, got it. You know, it's it's tough to use. Um, so there's sort of like this is sort of the argument that every inference company offers, right? Including the AI hardware startups is because I'm only running like three different models at most. I can just hand optimize everything and write kernels for everything and even like go down to like an assembly level, right? How hard can it be? Yeah, it is. It is pretty hard. Uh but like you tend to do this for production inference anyways. M like you aren't using KDUDNN which is Nvidia's like library that's like super easy to generate your you know to generate kernels and stuff right like you're not or not generate kernels but anyways um you're you're you're still use you're not using these like ease of use libraries you know when you're running inference you're either um you know using cutless or stamping out your own PTX or you know in some cases people are even going down to the SAS level right um and like when you look at like say an open AI or like you know anthropic when they run inference on GPUs they're doing this right um and the ecosystem is not that amazing uh when you once you get all the way down to that level it's not like using Nvidia GPUs is is easy now I mean you have an intuitive understanding of the hardware architecture because you work on it so much and everyone's worked on it and you can talk to other people but at the end of the day it's not like easy right whereas you know anthropic train or TPUs actually the hardware architecture is a little bit more simple than a GPU. Um larger, more simple cores rather than having all this functionality. Um you know, less general uh so it's a little bit easier to code on um there's there's tweets from enthropic people saying they uh when they're doing that low level actually they prefer working on tranium and TPU because of the simplicity. Um now interesting to be clear and TPU at I mean tranium especially is very hard to use like not for the faint of heart. Um, it's it's very difficult, but you can do it if you're just running like if I'm anthropic and I must only run Claude 4.1 Opus for Sonnet and and screw it. I won't even run highQ. I'll just run highQ on like on on GPUs or whatever, right? I'm just going to run two models. And actually, screw it. I'm just going to run Opus on GPUs too and and TPUs. Sonnet is the majority of my traffic anyways. I could I could spend the time. And how often am I changing that architecture every four or six months, right? like how much it's not even changing that much honestly, right? I think I think from three to four definitely did change, right? Yeah. I mean define architectural change, you know, at a high level like the primitives are more or less the same across the last couple of generations. I don't know enough about anthropics model architecture to be honest. But I think I think from what I've seen at other places there have been enough changes that it takes time to you know program this and and really get uh the the main thing is like you know if I'm anthropic and I have uh what 7 billion AR now or whatever um north of 10 you know by by the end of next year north of 20 right like AR is like maybe even 30 is like uh that's that's and my margins are 50% 70%. um that's $15 billion of tranium that I need right uh that I can that can run on sonnet and most of that's going to be sonnet three five or sorry four five whatever it is right it's going to be one model serving most of the use cases so like you know I could I could spend the time and it'll work on this hardware yeah totally um maybe on the topic of non-conensus calls you've made uh and and maybe I'll I'll move to another cloud uh in June you guys said that Oracle is winning the AI comput market. And then in this pod, we've already referenced the the big jump obviously that Oracle had. I think it was the single largest gain that a company with over 500 billion in market cap has ever had. Um so and was the 2023 Q1 Nvidia, not bigger. It might have been smaller. Okay. I think it was maybe close. We we'll fact check ourselves. That's amazing. But um but you know, obviously this is the massive commitment that was announced. uh can you walk us through why you made that call then um and just sort of why Oracle is poised to do so well at a such a competitive space? Yeah, so Oracle they're the largest balance sheet in the industry that is not dogmatic to any type of hardware, right? Um they're not dogmatic to any type of networking. They will deploy uh Ethernet with Arista. They'll deploy Ethernet through their own white boxes. They'll deploy NVIDIA networking. Um, Infiniband or or Spectrum X. Um, and they have really good network engineers. They have really great software across the board, right? Again, like Cluster Max um they were they were cluster max gold because their software is great. There's a couple things that they needed to add uh that would take them higher and they're they're adding those, right? Um to platinum, right, which was where Core was. Um and so like when you couple you couple two things, right? like OpenAI's got insane compute demand. Uh Microsoft is quite pansy. Um they're not willing to uh invest in they don't believe OpenAI can actually pay the amount of money. Right? I mentioned earlier, right? Right. The $300 billion deal, Open AI, you don't have $300 billion and Oracle's willing to take the bet. Now, of course, um the bet is a bit like there's a bit more security in the bet in that um Oracle really only needs to secure the data center capacity, right? So, so this is sort of like how we how we came across the bet right is and and we've been telling our institutional clients especially in like a super detailed way whether it be the hyperscalers or AI labs or semi companies or you know investors uh in our data center model because we're tracking every single data center in the world uh Oracle doesn't build their own data centers either right by the way they they get them from other companies they co-engineer uh but they don't physically build them themselves and so they're quite nimble in terms of like being able to assess new data centers engineer them so we we saw all these different data centers. Oracle is snatching up in deep discussion, snatching up, signing, etc. And so we have, you know, hey, gigawatt here, gigawatt there, gigawatt there, right? Um, Abalene, you know, two gigawatts, right? You know, you have all these different sites that they're they're signing up and discussions with and we're we're noting them. And then we have the timeline because we're tracking entire supply chain. We're tracking all the permits, uh, regulatory filings, you know, um, through, you know, language models, uh, using satellite photos constantly, um, and then supply chain of like chillers, transformer equipment, um, generators, etc. Um, we're able to make a pretty strong estimate of quarter by quarter in our data center or quarter by quarter how much power there is for each of these sites, right? So, some of these sites that we know of aren't even ramping until 2027, uh, but we know that Oracle signed it, right? Um, and we we have the sort of ramp path. So then it's this question of like okay let's say you have a you you have a megawatt right for simple sake simplicity sake which is a ton of power but now it doesn't feel like much you know we're in the gigawatt era but you know if you're talking about a megawatt right um you fill it up with GPUs how much do the GPUs for a megawatt cost right uh or actually it's like even simpler to do the math right if I'm talking about um a GV200 right each individual GPU is 1 watts uh but when you talk about the CPU, the whole system, it's roughly 2,000 watts. Um, at the same time, you know, all in everything simplicity sake, $50,000 per GPU, right? The GPU doesn't cost them. There's all the peripheries, right? Um, so $50,000 capex for 2,000 watts. So, $25,000 for one 10,000 watts. Um, and and then what's the rental price for GPU? Um, if you're on a really long-term deal, volume 270, right? 260 in that range. Um then you end up with oh it costs like $12 million per megawatt uh to rent a megawatt. Yeah. Um and then you and then each chip is different. So we track each chip, what the capex is, what the networking is. So you know what each chip is. You can predict what each you know what chips they're putting in which data centers when those data centers go online, how many megawatts by quarter. And then you end up with oh well Stargate goes online in this time period. They're going to start renting at this time. It's this many chips each Stargate site, right? Um, and so therefore, this is how much OpenI would have to spend to rent it. And then you you you prick that out and we were able to predict um Oracle's revenue with pretty high certainty and we matched pretty dead on what they announced for 25 26 27 and we were pretty close on 28. The the surprise for us was that, you know, they announced some stuff that 28 29 data centers that they uh we don't we haven't found yet, but we'll find them, right? Of course. uh um and sort of like this methodology lets you see sort of hey what data centers are you getting how much power um what are they signing uh how much incremental revenue that is when that comes online and so that's sort of the basis of our Oracle uh bet um obviously in the newsletter we included a lot less detail um but you know you know sort of it was it was that thesis right that like hey they have all this capacity they're going to sign these deals um and in our in our newsletter We talked about two main things. We talked about the open eye business and then we talked about the bite dance business. Um and presumably tomorrow, you know, on Friday there's going to be announcement about Tik Tok and all this, but like the bite dance business, um you know, huge amounts of data center capacity that Oracle is also going to lease out uh to Bite Dance, right? And so we did the same methodology there. Um you know, with Bite Dance, it's pretty certain they'll pay because they're a profitable company. With OpenAI, it's not. And so there's got to be some like error bars as you go further out in terms of like will open exist in 28 29 30 and will they be able to pay the 80 plus billion dollars a year that they've signed up to Oracle with right that's the only like risk here. Um and if that happens then Oracle's downside is also somewhat protected because they only sign the data center which is a minority of the cost right the GPUs are everything and the GPUs they purchase one to two quarters before they start renting them. So they they're not, you know, the downside risk is pretty low for them in terms of if they don't get the deal. Well, they don't get the revenue, but they're not it's not like they have they're stuck with a bunch of assets they bought that are worthless. Yeah. Yeah. Is there another angle here? I mean, OpenAI and Microsoft were of EFFs and and now they filed to voice papers and they just want to diversify and then that's pushing them away to towards other providers. Yeah. So so Microsoft was exclusive compute provider. got reorged to write a first refusal. Um, you know, and then and then Microsoft, is it not your last choice or something like that? No, it's still it's still it's still write a first refusal, but it's like Microsoft those two are not mutually exclusive. Well, if open is like we're going to sign a $80 billion contract or a $300 billion contract for the next five years, you guys want it or you know, it's like and they're like, "No, what? Okay, cool." Right? It's like it's like and then and then they go to Oracle, right? It's it's OpenAI is like sort of like this is this is the you know OpenAI needs someone with a balance sheet to actually be able to pay for it, right? Because and then and then they'll make tons of money if you know off of OpenAI um on the margins on the compute and the infra and all these things but someone's got to have a balance sheet um and OpenAI doesn't have a balance sheet. Oracle does. uh although given the scale of what they signed we also we had also had another uh source of information which was that uh they were they were talking to debt markets right uh because Oracle actually just needs to raise debt to pay for this many GPUs over time now they won't do it like immediately like they can pay for everything this year and next year from their own cash but like in 27 28 29 they'll start to have to use debt to pay for these GPUs which is what you know core has done and many of the Neil clouds most of it's debt financed um even meta wet and gut debt for uh their Louisiana mega data center. Not because just because it's cheaper than it's it's it's literally better on a financial basis to do buybacks with your cash and and get debt because the debt is cheaper than the return on your stock. Like it's like a a financial engineering thing, but like um you know who's out there, right? It could be Amazon, it could be Google, it could be Microsoft very short list or it could be uh Oracle or Meta, right? Meta's obviously not. Microsoft's chickened out. Amazon, Google, and Oracle, right? That's all that's left. Google would be an awkward fit. So, yeah, Google would be an awkward fit. Amazon would be a fine fit, but you know, Exactly. Right. It's like Yeah. Well, well, I I guess maybe, you know, on the topic of these giant data center buildouts, um you guys just released a piece on XAI and um Colossus 2. Do you are you getting less impressed by these feats of building something this massive in six months or is it still very impressive to you guys? Um, you know, this is the like uh thing I've said about AI researchers is that they're like the first class of humans to think about things on an order of magnitude scale whereas like people have always thought about things in terms of like percentage growth like ever since industrialization and before that it was just like absolute numbers right uh you know sort of like humanity is evolving in terms of how we think because things are changing faster everything is an upscale and so like you know it was like really impressive when GPT uh you know 2 was trained on so many chips and then GPD3 was trained on that you know like on on 20K100s and you know or sorry Guty 4 20k 100s GP you know sort of like it's like holy crap and then it was like oh the era of 100k GPUs clusters right and we did some reports around 100k GPU clusters but now there's like there's like 10 100k GPU clusters in the world I was like okay this kind of boring but it's like 100k GPUs is like, you know, over 100 megawatts. Now it's like, you know, you know, like literally, you know, we in our in our Slack and and some of these channels like, oh, we found another 200 megawatt data center. There there there's uh there's someone who like puts the yawning emoji every time. And I'm like, dude, what? Like now it's only it's only exciting if you do giggle scale. Gigawot era. Yeah. Yeah. Yeah. And and I'm sure like, you know, in you know, I'm not sure. Maybe maybe we'll start yawning to that too. But like you know the log scale of this is like the capital numbers are crazy, right? Like you know it was like it's crazy enough that open did like hundred billion dollar training run. Um you know or you know like then they did a billion dollar training run now we're talking about $10 billion training runs, right? Like you know it's it's it's crazy that we think in log scale but yes things are only impressive. Yeah. when they do it like what Elon's doing. So what Elon's doing in in in in uh Tennessee in Memphis first time was crazy, right? 100k GPUs in six months. He bought a factory in like February of 24. Um and and had models training within six months, right? Um and and he did liquid cooling, you know, first large scale data center with liquid at this scale for AI doing liquid cooling, like all these sorts of crazy firsts. um putting generators outside like CAT turbines, all these things for different things to get the power um you know, mobile substations, all these different crazy things. Um tapping the natural gas line that's like running alongside the factory, all these Yeah. So, so he does this. It's like, holy crap. And he did it for 100k GPUs, right? You know, 200 300 megawatts, right? Now he's doing it for a gigawatt scale and he's doing it just as fast, right? And and so like you would think like this is obviously way more impressive that he did it again. Yeah. But like maybe I'm desensitized, but like it's like you know like you you've given the child too much candy, right? Exactly. And now like the child has no you know it's like you know doesn't like apples, right? Like um I don't know. Um so so so like yeah a gigawatt data center. Um there was all these protests around his Memphis facility. people like, "Oh, you're destroying the air." And it's like, "Have you looked around that area of Memphis?" Like, there is like a gigawatt gas turbine plant that's just powering generally that area. Um, there's a sewage plant that's servicing the entire city of Minnesota or sorry, city of Memphis. Um, and there's like open air pits of like the like like there's open air mining. Like there's all sorts of disgusting [ __ ] around there. Uh, which is needed, right? We need that stuff to have a country run, right? Like to be clear. Um and you know um it's like people were complaining about like a couple hundred megawatts of air. Yeah. Of of of generation. Uh so he he got like protests from all sorts of people. You know he got super into the politics side of things and NAACP even protested him like and so like he really got like some local municipalities to be like oh I don't like you know like this. And so he couldn't do as much as he wanted to in in Memphis. uh but he still needed the data center to be close because he wanted to connect these data centers super high bandwidth, super close. Um and he also already had a lot of infrastructure set up there. So he he bought another f uh distribution center at this time. Um and it's still in Memphis, but the cool thing about Memphis is it's right across the border from uh Mississippi. Right. So now, you know, it's like 10 miles away from his original one, but his facility is like a mile away from Mississippi and he bought a power plant in Mississippi. um and he's putting turbines there because the regulation is completely different, right? And and if the scale if the question is really like galvanize resources and build it really fast, maybe maybe Elon is is ahead of everyone. Um you know, he hasn't made the best model yet or he doesn't have the best model at least today. I think um you know, you could argue Grock 4 was the best for a little period of time, but like you know, it's it's it's it's truly amazing how fast he's able to build these things. Um and and for first principles it's like most people are like [ __ ] like you know they they they we can't we can't we can't build the power we can't do power here anymore guess we have to find a new site and it's like no just go across the border go to Mississippi um and the my favorite thing is like Arkansas's right there so Mississippi gets mad you know I don't you know there the regulation all future data centers uh you know built in places where multiple states meet is that the four quarters y the optimal reg I think there's There's one. There we go. Is there is there a point in the US with five? I know there's a point with four uh four states intersect. Yeah. Uh maybe maybe that's going to data center kind of concern. All right. I'm going to buy real estate in that area Reddit. Um well, I guess on the topic of just maybe new hardware, um you had this piece analyzing TCO for GB200s. Um and I'm kind of going to ask this question on behalf of our portfolio companies, which it sounds like you're helping them already. Um, but one of the findings that I thought was really interesting was TCO was sort of 1.6 6x uh H100s for GB200s. Um, and so obviously, you know, there's this point on, okay, that's sort of the benchmark for the performance boost that you're going to need to at least make the sort of performance cost uh ratio benefit um from switching over. maybe just talk about what you've seen um from a performance standpoint and what do you recommend to portfolio companies maybe in a smaller scale than XAI who are you know thinking about new hardware try to get it there's capacity constraints obviously yeah I mean um that's a challenge right is uh with each generation of GPU it gets so much faster um that you end up like you want the new one and and and you know in some metrics you could say GB 2000 is three times faster faster than or two times faster than the prior generation. Other metrics you can say it's way more than that, right? Um so if you're doing pre-training versus inference, right? You can run everything for a bit, right? Yeah. If you can run it for a bit or just inference and take advantage of the huge NVLink uh NVL72, you know, um there there's there's ways you can you could squit and say GB200 is only 2x faster than H100. Uh in which case 1.6x TCL, it's you know, it's worthwhile, right? it's worth going to the next gen but more marginal. It's more marginal. Um it's not a big deal. Then there's other cases where it's like well on uh if you're running DeepSeek inference the performance difference per GPU is like north of like 6 7x and it continues to optimize um you know for for Deepseek inference. Um and so the qu you know then then it's like well I'm only paying 60% more for 6x and it's like it's a 4x or 3x performance per dollar gain like absolutely right. if you're like in running inference of deepseek that can also include RL, right? Um, and so the question is sort of and then and then the other question is like, well, the GPU is new. You know, there's also B200, there's GB2000, there's B2000. B200 is much more simple from a hardware perspective. It's just 8 GPUs in a box. So then it's not as much of a performance gain, especially in inference, but you have um you have all this stability, right? It's an 8GPU box. It's not going to be unreliable. The GV200s are still having some reliability challenges. Those are being worked through. It's getting better and better by the day. Uh but it's still a challenge. Um but you know when when you have a GB2 when you have a uh H100 right box or H200 8 GPUs, one of them fails, you take the entire server offline. You have to fix it, right? So usually your if your cloud's good, they'll swap it in, right? Um but if if it's GB 200, what do you now do with 72 GPUs? If one fails, do you break the whole thing and you get a new 72? The blast radius of a failure, right? Nope. GPU failure rates at best are the same and likely worse, right? Gen on genen because everything's getting hotter, faster, etc. So at best the failure rates are the same. Even if you model the failure rates as the exact same because you go from one out of eight to one out of 72, it's a huge problem. So now what a lot of people are doing is they run a high priority workload on 64 of them and then the other um eight you run low priority workloads which is then like okay there's this whole like infrastructure challenge like I have to have high priority workloads, I have to have low priority workloads. when a higher priority workload has a failure, instead of taking the whole rack offline, you just take some of the GPUs from the low priority one, put it in the high priority one, and then like you just let the dead GPU sit there until you service the rack at a later date. And it's like there's all these like complicated infrastructure things that make it so oh wait actually that that 3x or 2x performance increase in pre-training is lower because the downtime is higher slash I'm not using all the GPUs always slash I'm not able to per you know I'm not smart enough or I don't have the infra to like have low priority and high priority workloads like it's not impossible the labs are doing it right like it's just I mean if I'm running a cloud it's actually really hard right because I probably have to rent the spot one like like the spares out of spot instance or something. No, no, no, no. Because then because it's a it's a coherent domain. It's NV link. You don't want anyone touching that. So, it has to be the end customer doesn't have to leave them as empty spares. That's even worse. No, the end customer usually will just be like I want them and I'll I will, you know, and the SLAs's and the pricing everything is like accounting for that, right? So, like generally when you have a cloud, you have an SLA, right? Um that is, hey, it's going to be uptime is going to be 99%, you know, blah blah blah, right? Or for this period. uh with GB200 it's it's 99% for 64 GPUs not 72 and then it's like 95% for 7 72 now it differs across every cloud every cloud has a different SLA but like they've adjusted for this because they're like look this hardware is just finicky do you still want it um you know we will credit you in that 64 of them will always work right not not 72 and so like there's this whole like finicky nature and the end customer has to be capable of dealing with the unreliability and it's like and the end customer can just continue to use V200, right? Performance gains not as much. The whole reason you want this 72 domain is so you can have, you know, some of these gains, right? Um but you have to be smart enough to be able to do it and and that's challenging for small companies. Totally. So the Nvidia just announced the the Reuben prefill cards like CtX CX CPX CPX. There we go. What's your take on that? Does it cannibalize? Dude, by the way, I I don't know if this is like brain rod or like I don't know, but like I can't remember what I had for lunch yesterday, but I know the model number of every [ __ ] chip. Like, hu your dreams. We're broken. We're broken. Living the dream. No, no, no, no, no. Um, you know, why do you pre-announce a product that's 5x faster for certain use cases? Is that that that much? Oh, I think I think I think like historically AI chips were AI chips, right? Um, and then we started getting a lot of people saying this is a training chip, this is an inference chip. Actually training and inference are switching so fast in terms of what they require that like now it's like still like one chip. Um, actually there are still workload level dynamics that like differ. But the main workload is inference even in training, right? It's because of RL. most of that is is you know generating stuff in an environment and trying to you know achieve a reward right so it's it's inference still right training is now becoming mostly dominated by inference as well but inference has like two main operations right um there is calculating the KB cache uh for prefill right here's all these documents do the attention between all of them right between all the tokens however you know whatever type of attention you use and then there's decode which is gener auto reggressively generate each token Um these are very very different workloads and so initially the ideas or infrastructure techniques uh the ML systems techniques were oh okay I will just make the batch size every single you know forward pass this big and it you know if I I make it let's call it I'll make it a thousand big and maybe maybe I'll run 32 users concurrently that way you know now I still have you know 900 something left 960 left right um that 960 is actually doing the prefill for you know if a request comes in it chunks it it's called trunk prefill you pre-fill chunks of it now you get really good utilization on GPUs um but then that that ends up like impacting the decode workers right the people were autogressively generating each token end up being having slower TPS uh and and tokens per second is is really important for user experience and all these other things right so then so then the idea is like okay these two workloads are so different and you they are literally different right you prefill and then you decode um it's not like you're inter interle them. So why don't we split them entirely? And this is this is done on the same type of chip, right? Open, Anthropic, Google, pretty much everybody does that. Every everyone everyone good everyone together, fireworks, all these guys do uh pre-filled decode uh disagregated pre-filled decode. Um so they run pre-fill on a set of GPUs, decode on a certain set of GPUs. Why is this beneficial? Because you can autoscale them, right? You can, hey, all of a sudden I have a lot more long context workers. Um I allocate more resources to prefill u. Oh, all of a sudden I have a you know not all of a sudden but like you know over time my traffic mix is not long input short output it's short input long output I have more decode workers um this way I can guarantee and so now I can autoscale the resources differently and I can also guarantee that my prefill time is you know by the you know what's really important in search is how fast you get the page to start loading not when does the resource happen what what do people do in games like the loading screen often has some sort of interactive environment or it blends in over time or whatever it is, it has tips and tricks, ways to distract you. The same thing is it it show there's like studies and papers out there that users prefer a faster time to first token, right? First token gets streamed to me in like sooner even if the total time to get all my tokens is a little bit longer. I can't read that fast anyways, right? So, I mean I like to give I like to give. Yeah. I mean most models return above speed reading speed, but you need that, right? I think I think but like you know the the idea is that you want to guarantee time to first token is a certain level for user experience reasons otherwise people like screw this not using AI the decode speed matters a lot too but not as much as time to first token and so by having separate pre-filled decode you you do this right but now you've already and this is all in the same infrastructure you've already done this um so now it's like what's the next logical step these workloads are so different decode you have to load all the parameters in and the KV caches is to generate a single token. You batch a couple users together, but very quickly you run out of memory capacity or memory bandwidth because everyone's KV cache is different. Yeah. Um the attention of all the tokens, right? Whereas on prefill, I could even just serve like one or two users at a time because if they send me a 64,000 context request, that is a lot of flops, right? Uh 64,000 context requests. I'll use I'll use Llama 70B because it's simple to do math on like 70 billion parameters. Uh that's that's 140 gigaflops per token. 70 times uh 64,000 that's that's that's many many paraflops. You can use the entire GPU for like a second, right? Like potentially, right? Depending on the GPU um to just do the prefill, right? And that's just one forward pass. So I don't necessarily care about, you know, loading all the tokens or all the parameters in KV cache in fast. All I care about is all the flops. And so that leads us to sort of like, you know, I had to give this longwinded explanation because it's hard for people to understand what CPX is. Um I've had a lot of like even my own clients like we sent like multiple notes like explaining and they're like I still don't understand. I'm like [ __ ] Okay. Um send attention is all you need paper and you can't expect I mean like think about like a like like a networking person like they're like I don't know I don't need to know about this. You know attention is all you need right? Like it's like or think about an investor right like you know there's all people data center operator like they're like oh there's two chips why should I build my data center for differently it's like like you know I got to explain everything or just like no you don't have to build differently uh but anyways you you get to know in Stanford at least 25% of all students not CS students of all students read their paper read paper attention all you need that's low the majors and you don't like the philosophy I find this amazing anyway Sorry. The the Middle East, I can't remember what country it is, has AI education starting at like age like eight and in high school they have to read attention is all you need. Wow. Someone someone told me that their Santa had to read attention is all you need. Which is you I don't I don't know. Look look top down mandates for education you know maybe they work maybe they don't like you know maybe people like homeschooling their kids. I don't know. I went to public school but like uh back to your readers. Yeah. Um just on the topic of hardware cycles I wanted to maybe uh I actually explained what CPX is. So CPX is is a very like compute optimized chip whereas you know for prefill and then and then decode is just statistically say is is like the rest is the normal chips with HBM. HBM is more than half the cost of the GPU. If you strip that out um you end up having a much cheaper chip uh passed on to the customer. So or or like you know if Nvidia takes the same margin then then the cost of this prefill chip is much much lower and now the whole process is way cheaper more efficient now long context can be adopted. All right. Yeah. So I I love that we're actually going to all this detail because I had a more 10,000 foot view uh question for you which is um I haven't been following the semi market as closely as you have. I probably started with the A100. Um, and I I remember helping Gnome at Character, this is summer of June 2023, um, chase down GPUs and the only thing that mattered at that time was delivery date because there was a huge capacity crunch. Um, and then to see that over the last two years evolve where, you know, let's say 6 to 12 months ago, people were doing these RFPs to 20 Neoclouds, right? And the only thing that mattered to some degree was price. People actually do RFPs for GPUs. Yes. So, so, so just to be clear, my opinion on how you buy GPUs is that it's like buying cocaine um or any other drug. This is described to me, not me. I don't buy cocaine. Someone tells me this. I'm like, "Holy [ __ ] it's right." You call up a couple people, you text a couple people, you ask, "Yo, how much you got? What's the price?" It's like, exactly. This is [ __ ] like buying drugs like Oh, sorry. Sorry. No, I mean to this day like I just it's the same way. You just send like we we have Slack connects with like 30 Neoclouds and like as well like some of the major ones and we just send them a message like hey customer wants this much you know this is what they're looking for and then they send quotes and I know this guy. I know a guy. Well, so I think that's actually a very accurate description and I've sent countless port codes your cluster max original post because I thought it did a really good job breaking them down. Um, but maybe one question to end on for me is just what era are we in now with Blackwells coming online? Are we sort of back to the summer 2023 era and it's that's kind of the the cycle uh that we've just entered or what what's sort of your view on where we are? So for a very good question for one of your port codes um we we were like you know after their difficulties with Amazon we tried to we were like okay let's let's actually like get you GPUs. the original deals we got you were gone, but like here's some other deals, right? It turned out that um multiple major NeoClouds had sold out of hopper capacity. Um and and their Blackwell capacity comes online in a few months. Um so it's it's a bit of a challenge, right, in that due to inference. Um inference demand has been skyrocketing this year, right? Reasoning models. Yeah, these these reasoning models, the revenue um it's been skyrocketing this year. And then and then also like there's a bit of like the you know blackwell comes online but it's hard to deploy so it takes a little you know there's a learning curve to deploying it. So whereas like you got down to like you buy the hopper you install the data center it's running within like you know a month or two right for for for black belt it was like it's a longer time frame because of reliability challenges it's a new GPU I mean it's just learning per pain right learning learning uh growing pains. So there was like this gap of like how many GPUs are coming onto the market right as revenue starting to inlect and so a lot of capacity got sucked up right and actually prices for Hopper bottomed like three or four months ago or like five or six months ago. Yeah. And actually they've like crept up a little bit now. they're still like, you know, not not so so um I do I don't think we're quite 2023 2024 era of uh GPUs are tight, but certainly if you want to if you want like just a few GPUs, it's easy. Uh but if you want a lot, it's it's it's hard. Yeah. Like you you can't get capacity that instantly. Yeah. Wow. What a time. Shall we uh shall we wrap on that? Dylan, this was another uh instant classic. Thank you so much for coming to the podcast. It was like two hours, bro. What? I missed. Thank you. We couldn't couldn't stop. Thanks so much. This is great. Thank you so much for having me.