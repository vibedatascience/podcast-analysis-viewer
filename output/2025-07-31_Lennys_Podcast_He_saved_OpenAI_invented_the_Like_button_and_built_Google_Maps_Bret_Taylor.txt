================================================================================
YOUTUBE VIDEO EXTRACTION
================================================================================
VIDEO_ID: qImgGtnNbx0
URL: https://www.youtube.com/watch?v=qImgGtnNbx0
TITLE: He saved OpenAI, invented the “Like” button, and built Google Maps: Bret Taylor (Sierra)
CHANNEL: Lenny's Podcast
PUBLISHED: 2025-07-31
DURATION: 1h 28m 58s
VIEWS: 34,648
LIKES: 596
COMMENTS: 22

DESCRIPTION:
----------------------------------------
Bret Taylor’s legendary career includes being CTO of Meta, co-CEO of Salesforce, chairman of the board at OpenAI (yes, during that drama), co-creating both Google Maps and the Like button, and founding three companies. Today he’s the founder and CEO of Sierra, an AI agent company transforming customer service. He’s one of the few people I’ve met who’s been wildly successful at every level—from engineer to C-suite executive to founder—and across almost every discipline, including PM, engineer, CTO, COO, CPO, CEO, and board member.

*In this conversation, you’ll learn:*
1. The brutal product review that nearly ended his Google career—and how that failure led to creating Google Maps
2. The question Sheryl Sandberg taught him to ask every morning (“What’s the most impactful thing I can do today?”) that transformed how he approached every role
3. The three AI market segments that matter
4. Why AI agents will replace SaaS products
5. His framework for knowing whose advice to actually listen 
... [truncated]

SUBTITLE AVAILABILITY:
----------------------------------------
Total languages: 157
English available: True (manual)

EXTRACTED CAPTIONS:
----------------------------------------
Method: yt-dlp
Language: en
Word count: 16,164

TRANSCRIPT:
----------------------------------------
You're CTO of Meta. You&nbsp; are a co-CEO of Salesforce,&nbsp;&nbsp; you're chairman of the board at OpenAI. How do&nbsp; you think the AI market is going to play out? The whole market is going to go towards agents.&nbsp; I think the whole market is going to go towards&nbsp;&nbsp; outcomes-based pricing. It's just so obviously&nbsp; the correct way to build and sell software. This makes me think about, I had&nbsp; Marc Benioff on the podcast. You&nbsp;&nbsp; guys were co-CEOs. He was extremely agent-pilled. It's so hard to sell productivity&nbsp; software, which I learned the hard way. What's a story that comes to mind when&nbsp; you think about your biggest mistake? I was the product manager&nbsp; for, it was called Google&nbsp;&nbsp; Local had a pretty tough product&nbsp; review with Marissa and Larry,&nbsp;&nbsp; and to not do that well with a link from&nbsp; the Google homepage is embarrassing. I think it's really empowering for people to hear&nbsp;&nbsp; it's possible to succeed in spite&nbsp; of a massive failure like this. They gave me another shot to do the V2&nbsp; of it that resulted in Google Maps. We&nbsp;&nbsp; got about 10 million people&nbsp; using it on the first day. What mindset contributed to you being&nbsp; successful in such a variety of roles? Waking up every morning, what is the&nbsp; most impactful thing I could do today? Today, my guest is Bret Taylor. Bret is an&nbsp; absolute legendary builder and founder. He&nbsp;&nbsp; co-created Google Maps at Google. He co-founded&nbsp; the social network, FriendFeed invented the like&nbsp;&nbsp; button and the real-time newsfeed, which he sold&nbsp; to Facebook. He then became CTO at Facebook. He&nbsp;&nbsp; then started a productivity company called Quip,&nbsp; which he sold to Salesforce for $750 million. He&nbsp;&nbsp; then became co-CEO of Salesforce. He's also&nbsp; currently chairman of the board at OpenAI.&nbsp;&nbsp; At one point he was chairman of the board&nbsp; at Twitter. Today, co-founder and CEO of&nbsp;&nbsp; Sierra an AI started building agent to help&nbsp; companies with customer service sales and more.&nbsp; In our conversation, we cover so much ground,&nbsp; including what skills and mindsets have most&nbsp;&nbsp; helped Bret be so successful in so many roles,&nbsp; why we're all still sleeping on the impact that&nbsp;&nbsp; agents are going to have on the business world.&nbsp; How coding is going to change in the coming years,&nbsp;&nbsp; where the biggest opportunities remain&nbsp; for startups, lessons on pricing and&nbsp;&nbsp; go-to-market in AI, the story behind the like&nbsp; button and so much more. This is a truly epic&nbsp;&nbsp; conversation with a legendary builder. If you enjoy this podcast, don't forget&nbsp;&nbsp; to subscribe and follow it in your favorite&nbsp; podcasting app or YouTube. Also, if you become&nbsp;&nbsp; an annual subscriber of my newsletter, you get&nbsp; a year free of a bunch of incredible products,&nbsp;&nbsp; including Replit, Lovable, Bolt, n8n, Linear,&nbsp; Superhuman, Descript, Wispr Flow, Gamma,&nbsp;&nbsp; Perplexity, Warp, Granola, Magic Patterns,&nbsp; Raycast, ChatPRD, Mobbin and more. Check&nbsp;&nbsp; it out at Lenny'snewsletter.com and click&nbsp; bundle. With that, I bring you Bret Taylor.&nbsp; This episode is brought to you by CodeRabbit,&nbsp; the AI code review platform transforming how&nbsp;&nbsp; engineering teams ship faster with AI without&nbsp; sacrificing code quality. Code reviews are&nbsp;&nbsp; critical, but time-consuming CodeRabbit acts&nbsp; as your AI co-pilot providing instant code&nbsp;&nbsp; review comments and potential impacts of every&nbsp; pull request. Beyond just flagging issues,&nbsp;&nbsp; CodeRabbit provides one click fix suggestions and&nbsp; lets you define custom code quality rules using&nbsp;&nbsp; AST GREP patterns, catching subtle issues that&nbsp; traditional static analysis tools might miss.&nbsp; Coderabbit also provides free AI code reviews&nbsp; directly in the IDE. It's available in VS. Code,&nbsp;&nbsp; Cursor and Windsurf. CodeRabbit has so far&nbsp; reviewed more than 10 million PRs installed&nbsp;&nbsp; on 1 million repositories and is used by over&nbsp; 70,000 open source projects. Get CodeRabbit for&nbsp;&nbsp; free for an entire year at CodeRabbit.ai&nbsp; using code, Lenny. That's CodeRabbit.ai.&nbsp; This episode is brought to you by Basecamp.&nbsp; Basecamp is the famously straightforward&nbsp;&nbsp; project management system from 37signals.&nbsp; Most project management systems are either&nbsp;&nbsp; inadequate or frustratingly complex, but Basecamp&nbsp; is refreshingly clear. It's simple to get started,&nbsp;&nbsp; easy to organize and Basecamp's visual tools&nbsp; help you see exactly what everyone is working&nbsp;&nbsp; on and how all work is progressing. Keep all your&nbsp; files and conversations about projects directly&nbsp;&nbsp; connected to the projects themselves so that&nbsp; you always know where stuff is and you're not&nbsp;&nbsp; constantly switching contexts. Running a business&nbsp; is hard. Managing your project should be easy.&nbsp;&nbsp; I've been a long time fan of what 37signals has&nbsp; been up to and I'm really excited to be sharing&nbsp;&nbsp; this with you. Sign up for a free account at&nbsp; basecamp.com/Lenny. Get somewhere with Basecamp.&nbsp; Bret, thank you so much for being&nbsp; here and welcome to the podcast. Thanks for having me. My pleasure. There's so much that I want to&nbsp; talk about. You've done so many incredible&nbsp;&nbsp; things over the course of your career. Just&nbsp; boggles the mind, the things that you've done,&nbsp;&nbsp; and we're going to talk about a lot of that&nbsp; sort of stuff, but I want to actually start&nbsp;&nbsp; with the opposite. I want to talk about a time&nbsp; that you messed up, a time that you screwed up&nbsp;&nbsp; in a big way. We have this recurring segment&nbsp; on the podcast called Fail Corner, and so, I&nbsp;&nbsp; thought it'd be fun to just start there before we&nbsp; get into all the great stuff you've done. What's&nbsp;&nbsp; a story that comes to mind when you think about&nbsp; maybe your biggest mistake in building a product? It may not be the biggest, but it was my first&nbsp; prominent mistake as a product manager at&nbsp;&nbsp; Google. So for me, it feels big because it was&nbsp; very formative for me as a product designer.&nbsp;&nbsp; So I joined Google in late 2002, early 2003, and I&nbsp; was one of the earliest associate product managers&nbsp;&nbsp; at the company and first, was working on the&nbsp; search system, essentially expanding our index&nbsp;&nbsp; from 1 billion webpages to 10 billion, which was a&nbsp; big deal at the time. It seems quaint now. Then I&nbsp;&nbsp; did a decent job and so my boss, Marissa Meyer,&nbsp; gave me the opportunity to lead a new product&nbsp;&nbsp; initiative, which was a big bet on me and it was&nbsp; both an opportunity to do something for Google,&nbsp;&nbsp; but I was also being pretty scrutinized just&nbsp; as a young new product manager and the premise&nbsp;&nbsp; given to me was work on local search. At the time, the Yellow Pages was still&nbsp;&nbsp; dominant and well, Google was really good at&nbsp; searching the web. It wasn't really good for&nbsp;&nbsp; finding a plumber or a restaurant just because it&nbsp; wasn't really a huge part of the internet at the&nbsp;&nbsp; time. So this content wasn't necessarily on the&nbsp; internet and even if it was, you didn't really&nbsp;&nbsp; want to find plumbers in Manhattan, you wanted&nbsp; to find plumbers in San Francisco, if you're&nbsp;&nbsp; me. And so it was both a technical problem&nbsp; and a product problem and a content problem.&nbsp; We launched the first version of that product&nbsp; that I was the product manager for, was called&nbsp;&nbsp; Google Local and it was, I'll be a little bit more&nbsp; critical now than I might've been at the time, but&nbsp;&nbsp; it was a little bit of a me too version of Yahoo&nbsp; Yellow Pages, essentially grafting on Yellow Pages&nbsp;&nbsp; search on top of Google Search and with a properly&nbsp; crafted query you could see those listings at the&nbsp;&nbsp; top of your search results but a standalone&nbsp; site at local.google.com. Actually, it was an&nbsp;&nbsp; important enough initiative that actually, there&nbsp; was on the Google homepage, it had Web, Images and&nbsp;&nbsp; Local was up there as well, so it's got top bill. I mean you could put almost any link on the Google&nbsp;&nbsp; homepage and get a lot of traffic to it. And&nbsp; despite that, it didn't do that well and to not&nbsp;&nbsp; do that well with a link from the Google homepage&nbsp; is embarrassing. There's not much one can do more&nbsp;&nbsp; than giving you that kind of traffic to give&nbsp; you an add that as a product leader or a product&nbsp;&nbsp; manager. And the product was fine, it worked, but&nbsp; it really wasn't differentiated. And in many ways,&nbsp;&nbsp; I think, again, I think I've had these reflections&nbsp; more sense than at the time, that I had some of&nbsp;&nbsp; the time, but why use this instead of Yahoo Yellow&nbsp; Pages? But more than anything else, why use this&nbsp;&nbsp; instead of the Yellow Pages? It was a digital&nbsp; version of something that had come before. Had a&nbsp;&nbsp; pretty tough product review with Marissa and Larry&nbsp; and others and it was fine. I wasn't about to get&nbsp;&nbsp; fired or something, but it was, I don't know, the&nbsp; shine on my reputation was waning a little bit.&nbsp; And they gave me another shot to do a V2 of it and&nbsp; I got the impression it wasn't like my last shot,&nbsp;&nbsp; but I certainly was feeling a little dejected from&nbsp; going from a hot shot, new PM to a new thing. So,&nbsp;&nbsp; we spent a lot of time thinking about how can you&nbsp; make something that's just much more compelling&nbsp;&nbsp; and not just a digital version of the Yellow&nbsp; Pages and not just so similar to some of the&nbsp;&nbsp; other products out there. And that ended up being&nbsp; the thread that we pulled that resulted in Google&nbsp;&nbsp; Maps. We had licensed from MapQuest, the ability&nbsp; to put this little map next to the search results,&nbsp;&nbsp; it was always the ugliest part of the product&nbsp; and we always made these backhanded comments&nbsp;&nbsp; about it internally and we spent a lot&nbsp; of time saying, what if we inverted the&nbsp;&nbsp; hierarchy here and made the map the canvas? We ended up finding Lars and Jens Rasmussen&nbsp;&nbsp; who had been working on this Windows mapping&nbsp; product and we got them into the company and&nbsp;&nbsp; started exploring this space and it ended up&nbsp; where, through that exploration we ended up&nbsp;&nbsp; integrating a lot of different products. We&nbsp; ended up integrating mapping local search,&nbsp;&nbsp; driving directions, like all of these products at&nbsp; the time were actually separate product categories&nbsp;&nbsp; and ended up with something that redefined the&nbsp; industry and certainly my career. But it took,&nbsp;&nbsp; I think for me as a product leader, it&nbsp; changed the way I think about product just&nbsp;&nbsp; because there's feature and functionality and&nbsp; then there's like why should I use this thing&nbsp;&nbsp; in the first place? And it was notable,&nbsp; there was a couple of interesting moments.&nbsp; When we launched Google Maps we got about&nbsp; 10 million people using it on the first day,&nbsp;&nbsp; which at that scale of the internet at the&nbsp; time was huge. And then in August of 2005,&nbsp;&nbsp; we integrated satellite imagery from a recent&nbsp; acquisition called Keyhole, which became Google&nbsp;&nbsp; Earth and we got 90 million people using it on&nbsp; the same day. Everyone wanted to look at the&nbsp;&nbsp; top of their house when the imagery came out.&nbsp; And it was really interesting because there's&nbsp;&nbsp; so many subtle product lessons in there. First&nbsp; is, I think as you have these new technologies,&nbsp;&nbsp; rather than literally digitizing what came before,&nbsp; if you can create an entirely new experience,&nbsp;&nbsp; it answers the question for a new customer,&nbsp; why should I give this the time of day? And so,&nbsp;&nbsp; really disassembling the Lego set and reassembling&nbsp; into something new rather than just digitizing&nbsp;&nbsp; what was there before. Certainly, that&nbsp; was the lesson I think in Google Maps,&nbsp;&nbsp; really was native to the platform in&nbsp; a way that a paper map couldn't be and&nbsp;&nbsp; that was a really meaningful breakthrough. And then with satellite imagery, it honestly&nbsp;&nbsp; wasn't the most important part of Google Maps,&nbsp; but it was the sizzle to the steak and it created,&nbsp;&nbsp; I don't think the term viral was a thing&nbsp; people said back then, but it created a&nbsp;&nbsp; viral moment. We were on Saturday Night Live,&nbsp; which is the coolest thing. Andy Samberg in,&nbsp;&nbsp; I think it was called Lazy Sunday rapped about&nbsp; Google Maps and Lars and I were texting each&nbsp;&nbsp; other. We did it. We're on Saturday Live.&nbsp; Mission accomplished. And it was also showing&nbsp;&nbsp; that as you're there thinking about products,&nbsp; there's the why you decide to use a product and&nbsp;&nbsp; then what is the enduring value. And those are&nbsp; deeply related but not all the same thing. And&nbsp;&nbsp; I just learned so many lessons that I took with&nbsp; me for every subsequent product that I worked on. That is an awesome story. One I think&nbsp; it's really empowering for people to hear,&nbsp;&nbsp; even you Bret, who I'm going to&nbsp; share all the successes you've had,&nbsp;&nbsp; have had a massive failure with the CEO of&nbsp; Google [inaudible 00:11:30] just like Bret,&nbsp;&nbsp; you screwed up. And it was such a big bet. So&nbsp; one, just it's possible to succeed as you have&nbsp;&nbsp; succeeded in spite of a massive failure like this.&nbsp; And then some of the product lessons you shared,&nbsp;&nbsp; just to highlight a few of these things&nbsp; because I think this is great, is just&nbsp;&nbsp; you will often not win if you just make something&nbsp; that's a better copy of something else, what you&nbsp;&nbsp; want to look for is something that is an entirely&nbsp; new experience, something that's differentiated,&nbsp;&nbsp; something that's a lot more compelling. Let's&nbsp; flip to talk about what you've learned from&nbsp;&nbsp; actually being very successful at a lot of things. So I was looking at your resume and you basically&nbsp;&nbsp; have been very successful at every level of&nbsp; the career ladder and in such a huge variety&nbsp;&nbsp; of roles. So let me just read a few of these&nbsp; things for folks that aren't super familiar&nbsp;&nbsp; with your background. You were CTO of Meta, you&nbsp; were co-CEO of Salesforce, you're also CPO and&nbsp;&nbsp; COO at Salesforce. At Google, you joined as an&nbsp; associate product manager where you famously,&nbsp;&nbsp; you didn't mention this but you rebuilt Google&nbsp; Maps on weekend. We're not going to talk about&nbsp;&nbsp; that. You're chairman of the board at OpenAI. You&nbsp; were chairman of the board at Twitter. You've also&nbsp;&nbsp; founded three different companies, one social&nbsp; network, one productivity docs company called&nbsp;&nbsp; Quip, and now, Sierra. Fun fact, at FriendFeed&nbsp; you invented the like button and I don't know if&nbsp;&nbsp; people know that and also just the newsfeed, I'll&nbsp; just throw that out there to give you some credit.&nbsp; So you're basically an associate product manager,&nbsp; an IC product manager, an engineer, CPO, COO, CTO,&nbsp;&nbsp; CEO of three different companies including&nbsp; a public company. Very rare that somebody&nbsp;&nbsp; is successful at all these types of roles and&nbsp; all these levels. So, let me just ask you this&nbsp;&nbsp; question. What mindsets or habits or just ways of&nbsp; working have you worked on building in yourself&nbsp;&nbsp; that you think have most contributed to you being&nbsp; successful in such a variety of roles and levels? Yeah. It's actually something I am proud of.&nbsp; I like the fact I've worn different hats. It's&nbsp;&nbsp; actually amusing when I meet colleagues that I've&nbsp; known from one of those jobs, they'll often think&nbsp;&nbsp; of me through the lens of that job. And so, I'll&nbsp; go to meet folks from Facebook and they think of&nbsp;&nbsp; me largely as an engineer. I'll meet folks from&nbsp; Google, they think me largely as a product person.&nbsp;&nbsp; At Salesforce, a lot of the folks there interacted&nbsp; with me as like a, lack of a better word, a suit,&nbsp;&nbsp; the boss. And I'm not sure they think of me as an&nbsp; engineer at all, even though I was still probably&nbsp;&nbsp; coding on the weekends for fun. And one of&nbsp; the things that is a principle for me is to&nbsp;&nbsp; have a really flexible view of my own identity. I&nbsp; probably would self-describe as an engineer, but&nbsp;&nbsp; more broadly I think of myself as a builder and I&nbsp; like to build products and I think companies are&nbsp;&nbsp; one of the most effective ways to build products. There's also things like open source, but I think&nbsp;&nbsp; I'm a huge believer in the confluence&nbsp; of technology and capitalism to produce&nbsp;&nbsp; just incredible outcomes for customers.&nbsp; And as a consequence, I think to really&nbsp;&nbsp; build something of significance, I think to be&nbsp; a great founder, you really need to be able to&nbsp;&nbsp; not have such a ossified view of your identity&nbsp; that you can't transform into what the company&nbsp;&nbsp; needs you to be at that point. And every founder&nbsp; you'll talk to, one day, I think selling is a&nbsp;&nbsp; big part of being a founder. You have to sell&nbsp; investors on wanting to invest in your company.&nbsp;&nbsp; You have to sell candidates on wanting to work&nbsp; at your company. You have to sell customers&nbsp;&nbsp; to want to use the product that your customer&nbsp; produces. You have to have good design taste,&nbsp;&nbsp; not just for your product but for your marketing&nbsp; and essentially, soliciting your customers.&nbsp; You have to have good engineering. If you're&nbsp; building a technology company, the technology&nbsp;&nbsp; comes first. It's why this industry is so&nbsp; transformative. I probably credit, and I've told&nbsp;&nbsp; this story before, but I'm very grateful for her,&nbsp; but I probably credit Sheryl Sandberg for really&nbsp;&nbsp; changing the way I approach new jobs. The story,&nbsp; and I might be embellishment a little bit, but I&nbsp;&nbsp; think it's broadly accurate. So I had just become&nbsp; the chief technology officer of Facebook and when&nbsp;&nbsp; I first got the job, it was the flavor of CTO or&nbsp; that relatively small group reporting into me,&nbsp;&nbsp; but contributed almost as a very senior architect&nbsp; on a number of projects. And then at some point,&nbsp;&nbsp; Mark Zuckerberg reorganized the company and&nbsp; split it into a bunch of different groups.&nbsp;&nbsp; I ended up with a very large group, 100 under&nbsp; me and I was essentially running our platform&nbsp;&nbsp; and mobile groups, products, design engineering. So I went from a handful of reports to, I don't&nbsp;&nbsp; know, over 1,000 or something. It was a big group.&nbsp; And it was the largest management job. I had&nbsp;&nbsp; become a manager at Google, but a modest team. And&nbsp; so, I was doing okay but not great. And I had this&nbsp;&nbsp; moment where Sheryl saw me, I think I was editing&nbsp; a presentation for a partner just because the&nbsp;&nbsp; presentation I got didn't meet my quality bar and&nbsp; I was editing it and griping about it. She pulled&nbsp;&nbsp; me into a room and gave me talking to a little bit&nbsp; about holding my team to as high of a standard as&nbsp;&nbsp; I have. If someone wasn't meeting my expectations,&nbsp; what was my plan to manage them out of the company&nbsp;&nbsp; or... Just giving me management one-on-one. And she's a remarkable mentor in the sense&nbsp;&nbsp; she can give you feedback that's very&nbsp; direct and often, a bit uncomfortable,&nbsp;&nbsp; but you know she cares about you. And so it was&nbsp; the type of feedback you listen to. I went home&nbsp;&nbsp; that night and I was stewing on it and not very&nbsp; happy. I was like, you get naturally a little&nbsp;&nbsp; defensive in those moments. Is that really true?&nbsp; Am I really fucking it up or is she overreacting?&nbsp;&nbsp; And then I woke up the next day, I was like, "No,&nbsp; she's right." And I had realized this subconscious&nbsp;&nbsp; limiter that was limiting my success in the job,&nbsp; which is, I was trying to conform the job to the&nbsp;&nbsp; things I thought I liked to do. So, I was spending&nbsp; a lot of my time on some product and technology&nbsp;&nbsp; things that I was passionate about, thinking I'm&nbsp; the boss. I should focus on what I want to focus&nbsp;&nbsp; on instead of thinking about, okay, I'm running&nbsp; the mobile and platform teams at Facebook. What's&nbsp;&nbsp; the most important thing to do today to make&nbsp; our mobile and developer platform successful?&nbsp; And when I reframed the job that way, I did&nbsp; different things. And the thing that was the&nbsp;&nbsp; biggest pleasant surprise to me was I liked&nbsp; it. I thought I liked engineering and product,&nbsp;&nbsp; but in fact, when I changed an organization&nbsp; and it turned out to be more successful,&nbsp;&nbsp; I derived a great deal of joy from seeing that&nbsp; success. Our developer platform had a lot of&nbsp;&nbsp; partners and when there was an issue there and&nbsp; I'd spend time on partnerships and it worked&nbsp;&nbsp; and our platform became healthier, the partner&nbsp; became more successful. I took pride in that&nbsp;&nbsp; success and then I just started being better&nbsp; at my job and I realized that the actual act&nbsp;&nbsp; of engineering or product design or all the things&nbsp; I thought I liked, what I really liked is impact.&nbsp; And so, that conversation led to my waking up&nbsp; every morning, sometimes literally, but certainly,&nbsp;&nbsp; in the broadest sets of the words saying, "What&nbsp; is the most impactful thing I can do today?" And&nbsp;&nbsp; really thinking almost like, if you had an&nbsp; external board of advisors telling you what&nbsp;&nbsp; are the things where if you focus on them, you&nbsp; can maximize the likelihood that what you're&nbsp;&nbsp; trying to achieve will happen? Sometimes, it's&nbsp; recruiting, sometimes, it's product, sometimes,&nbsp;&nbsp; it's engineering, sometimes, it's sales. And I've&nbsp; become much more self-reflective just about what&nbsp;&nbsp; is important to work on. And I have become much&nbsp; more receptive to doing things that I previously&nbsp;&nbsp; would've said aren't my favorite things to do&nbsp; because I derive so much joy from having an&nbsp;&nbsp; impact that I enjoy a lot more things now. And&nbsp; so, I really credit Sheryl, I'm so grateful.&nbsp;&nbsp; And actually, it's interesting, I think a lot&nbsp; about this when I give feedback to people now,&nbsp;&nbsp; just those moments that can change the trajectory&nbsp; of your career. I give her all the credit for it. There's so many people that share&nbsp; stories of Sheryl Sandberg giving&nbsp;&nbsp; them advice and that changing&nbsp; their life. What a mensch. Yeah. My biggest takeaway from this, which&nbsp; is this question of what is the most&nbsp;&nbsp; impactful thing I could do today? Such a powerful&nbsp; heuristic just to keep in mind. To your point,&nbsp;&nbsp; you may realize you don't want to be doing sales&nbsp; or hiring, but if that's the most impactful thing&nbsp;&nbsp; and you end up doing it, you may realize I like&nbsp; this and I'm good at this and have thought about- Can I double click on that though for a second? Absolutely. I think it's really hard. One of the&nbsp; dangers for founders and product managers,&nbsp;&nbsp; but I think particularly for founders&nbsp; is incorrect storytelling. People don't&nbsp;&nbsp; like my product because of X. And if you tell&nbsp; that to yourself and you tell it to your team,&nbsp;&nbsp; all of a sudden, it goes from being an intuition&nbsp; to being a fact. Well, you better hope you're&nbsp;&nbsp; right because if you orient your strategy&nbsp; around fixing a problem and you're wrong,&nbsp;&nbsp; your company's going to fail. So why did you lose&nbsp; a deal? You could talk to the salesperson who is&nbsp;&nbsp; on the account or perhaps maybe a product&nbsp; manager was involved in the conversation.&nbsp;&nbsp; It's very important to have intellectual&nbsp; honesty in those moments because you could&nbsp;&nbsp; say something like, "Oh, they didn't buy&nbsp; it because the platform cost too much."&nbsp;&nbsp; And that's something a salesperson might say. Maybe the real reason is they didn't actually&nbsp;&nbsp; see much value in your platform. So it was&nbsp; communicated to the salesperson as it was&nbsp;&nbsp; too expensive. But in fact, the problem was&nbsp; product differentiation. And you could end up&nbsp;&nbsp; going into a discussion on pricing when in fact,&nbsp; there was a much deeper, much harder problem to&nbsp;&nbsp; solve there. But just like when you break up&nbsp; with someone, you don't say, it's because I&nbsp;&nbsp; don't like you anymore. You say it's not you,&nbsp; it's me. You say all these pleasantries because&nbsp;&nbsp; we're all social animals and you want to&nbsp; be pleasant with the people around you.&nbsp;&nbsp; So literally taking what a customer says or what a&nbsp; user says in a focus group or a usability study is&nbsp;&nbsp; rarely correct. It often is related to what the&nbsp; truth is, but it's very important to get right.&nbsp;&nbsp; And so, I think one of the things I've observed&nbsp; with first time founders in particular is you're&nbsp;&nbsp; often a single issue voter based on your skillset. So if you're a great engineer, the answer to&nbsp;&nbsp; almost every problem in your business is&nbsp; engineering. If you're a product designer,&nbsp;&nbsp; the answer almost to the proverbial redesign,&nbsp; I joke, it's like the dead cap balance of a&nbsp;&nbsp; consumer product like this next redesign will fix&nbsp; all of our problems. I don't know if it's ever,&nbsp;&nbsp; ever worked. And then I met a lot of entrepreneurs&nbsp; who come from a business development background,&nbsp;&nbsp; they're always thinking about partnerships and&nbsp; oh, if we just get this partnership done for&nbsp;&nbsp; this distribution channel, everything's going to&nbsp; change. And I think it's really important when&nbsp;&nbsp; you're a founder to be self-aware that you will&nbsp; naturally, subconsciously pick the thing that is&nbsp;&nbsp; your strength, your superpower as a solution to&nbsp; more problems. And in fact, if you think that's&nbsp;&nbsp; a solution to your problem, it may be right,&nbsp; but you probably by default should question it.&nbsp; If you think the thing that you've been doing&nbsp; your whole career is the way to fix your problem,&nbsp;&nbsp; it's at least 30% likely that you've chosen&nbsp; that because of comfort and familiarity not&nbsp;&nbsp; truth. And so, I think one of the skills I think&nbsp; is, it really goes around to do you have a good&nbsp;&nbsp; co-founder? Do you have a good leadership team?&nbsp; If you're a product manager, you're a partner&nbsp;&nbsp; in engineering, you're a partner in marketing,&nbsp; you really want to have very real conversations&nbsp;&nbsp; to ensure that you're actually working on the&nbsp; actual correct thing. And I think it's easy&nbsp;&nbsp; to say what's the most impactful thing to do&nbsp; today? My guess, if a lot of people try that,&nbsp;&nbsp; they'll lie to themselves more often than&nbsp; not. And it's a very challenging question&nbsp;&nbsp; to answer. The question's interesting. Being able&nbsp; to answer it accurately is actually the hard part. This feels like such an important lesson&nbsp; you've learned. Is there an example that&nbsp;&nbsp; comes to mind where you learned this the&nbsp; hard way where you actually ended up- Oh, yeah. You just want to spend this whole&nbsp; thing on my failures, but I'm fine with that. You've had too much success. Frontier was my first company. At our peak we&nbsp; had 12 employees, 12 of the best people I've ever&nbsp;&nbsp; worked with. Started the company with Jim Norris,&nbsp; who's an engineer I've known since Stanford and&nbsp;&nbsp; Paul Buhite and Sanjeev Singh who Paul started&nbsp; Gmail. Sanjeev was the first engineer at Gmail,&nbsp;&nbsp; so we had the Google Maps people and&nbsp; Gmail people. It was a pretty awesome&nbsp;&nbsp; founding team. We made a social network, as you&nbsp; said. We invented a lot of concepts that became&nbsp;&nbsp; popular in the newsfeed. We invented the like&nbsp; button. It was really neat. It was a fun time.&nbsp;&nbsp; We were only really popular in Turkey, Italy and&nbsp; Iran, and at one point, we were blocked in Iran,&nbsp;&nbsp; so we were only popular in Turkey and Italy&nbsp; and Silicon Valley. To this day, actually a&nbsp;&nbsp; lot of folks in Silicon Valley are like, "I&nbsp; love FriendFeed." I'm like, that's awesome.&nbsp; It wasn't really a successful business. We&nbsp; were a follower-oriented social network,&nbsp;&nbsp; not a friendship-oriented social network,&nbsp; which meant a lot of our content was more&nbsp;&nbsp; like X or Twitter than it is Facebook in that&nbsp; respect. And a lot of sharing newspaper articles,&nbsp;&nbsp; interests, scientific communities, things like&nbsp; that. And there was a period when Twitter,&nbsp;&nbsp; which was one of our competitors at the&nbsp; time, that there was a lot more social&nbsp;&nbsp; networks at the time. I am probably screwing&nbsp; this up a little bit. I think Obama, Ashton&nbsp;&nbsp; Kutcher and Oprah Winfrey all went on Twitter&nbsp; in a summer and we just got our ass kicked.&nbsp; And it was a great example of you... I think&nbsp; 11 of those 12 people were engineers and we&nbsp;&nbsp; were just making product and I think it was&nbsp; Biz Stone. If you talk to the Twitter folks,&nbsp;&nbsp; they could give you the history on this, but&nbsp; I think Biz was really focused on getting&nbsp;&nbsp; celebrities and public figures onto Twitter, which&nbsp; is totally obvious. If you have a social service&nbsp;&nbsp; that's oriented towards following people, put some&nbsp; people on there worth following and instead, we&nbsp;&nbsp; were exclusively focused on polishing the product. And we actually, I think at our peak of&nbsp;&nbsp; popularity, we were very confident just, I think&nbsp; it was a time when Twitter had the fail whale&nbsp;&nbsp; and it was down half the time and people couldn't&nbsp; even use it. And our product, we were innovating&nbsp;&nbsp; faster, we had more features, people liked it and&nbsp; we were up 100% of the time and we totally lost&nbsp;&nbsp; for no reason related to product at all. And it&nbsp; was an example of, I think somewhat famously not&nbsp;&nbsp; a lot of great entrepreneurs have come out&nbsp; of Google because Google was so successful,&nbsp;&nbsp; I think it's hard as a product manager to see&nbsp; distribution and product design and even business&nbsp;&nbsp; model when you have AdWords and money's raining&nbsp; from the sky. There wasn't as much scrutiny and I&nbsp;&nbsp; think folks like the PayPal Mafia I think learned&nbsp; a lot more about entrepreneurialism than a typical&nbsp;&nbsp; PM at Google. So, we're just getting punched&nbsp; in the face and learning this the hard way.&nbsp; And so, that was probably the most prominent&nbsp; example of it and I think we probably did have&nbsp;&nbsp; a... I can tell you all the flaws of that&nbsp; product, but I don't think that was the&nbsp;&nbsp; reason why we lost. There's a lot of reasons. I&nbsp; think there was a lot of flaws of the product,&nbsp;&nbsp; but it was a lot of other stuff. And so, I've&nbsp; learned, accumulated these skills over time,&nbsp;&nbsp; but I say the hard part of that question is&nbsp; answering it correctly, is it's hard when you&nbsp;&nbsp; don't have experience in something, than to have&nbsp; intuition in it. So I think if there's probably a&nbsp;&nbsp; structural flaw, it wasn't that... I don't know&nbsp; if I could have figured out how to reach out to&nbsp;&nbsp; Ashton Kutcher [inaudible 00:27:28], it's&nbsp; not he's on my Rolodex. But I probably&nbsp;&nbsp; wasn't soliciting advice from the right people. I think that what's great about the technology&nbsp;&nbsp; industry is there's a lot of advice. Choosing whom&nbsp; you listen to is actually quite difficult, but&nbsp;&nbsp; I think we're somewhat myopic. We're in our own&nbsp; little world, creating this product and we weren't&nbsp;&nbsp; asking people from the outside in to say, what&nbsp; are you seeing that could go wrong? What are you&nbsp;&nbsp; seeing that could go right? What are you seeing in&nbsp; the industry that we're not doing that you think&nbsp;&nbsp; we might want to do? And this is why boards are&nbsp; important. This is why finding the right advisors,&nbsp;&nbsp; the advisors will actually tell you what you not&nbsp; [inaudible 00:28:09] want to hear, but you need to&nbsp;&nbsp; hear. I think that was probably the missing part.&nbsp; I'm not sure I was great at market at the time,&nbsp;&nbsp; but if I had solicited the right advice, I could&nbsp; have learned that that was a shortcoming. And I&nbsp;&nbsp; think that was a deep lesson I took from that. I'm&nbsp; a huge believer in boards and getting good advice. Any heuristics or advice for people to&nbsp; know whose advice to listen to? What do&nbsp;&nbsp; you pay attention to when you're like, okay,&nbsp; ignore this person but listen to this person? Yeah, that one's tough. It does come down to good&nbsp; judgment and being judge of people's character.&nbsp;&nbsp; One thing that is particularly hard is there's&nbsp; not a strong correlation between the confidence&nbsp;&nbsp; with which someone expresses an opinion&nbsp; and the quality of that opinion. I don't&nbsp;&nbsp; want to say it's inversely correlated, but&nbsp; that's funny, with all the podcasts out now,&nbsp;&nbsp; if there's topics I know a lot about, sometimes&nbsp; the most eloquent, confident statements about&nbsp;&nbsp; things I know a lot about, are the least accurate&nbsp; and it sounds extremely persuasive. And so,&nbsp;&nbsp; it does require very good judgment. One thing is&nbsp; I think, not just asking for advice but asking&nbsp;&nbsp; people, who should I talk to get good advice? And&nbsp; you'll find some common answers there and that's&nbsp;&nbsp; often a really strong signal of good judgment. And then one thing I found is when you ask for&nbsp;&nbsp; advice, don't just ask what to do but why. Be&nbsp; an obnoxious two-year-old kid, why? Why? Why?&nbsp;&nbsp; Why? And really try to understand the framework&nbsp; that someone is using to give you advice. The&nbsp;&nbsp; interesting thing about advice is people are often&nbsp; extrapolating from relatively few experiences.&nbsp;&nbsp; So they will say, never do this or always do&nbsp; that. And it's because they had one experience&nbsp;&nbsp; where something backfired or something could have&nbsp; gone better if they had done it. So it's a useful&nbsp;&nbsp; anecdote, but if you don't ask why and understand&nbsp; they had one experience and here's what happened,&nbsp;&nbsp; it can come across as a rule when in fact,&nbsp; it's [inaudible 00:30:08] data and if you&nbsp;&nbsp; ask advice of three people and they all have&nbsp; very similar interactions, you can create&nbsp;&nbsp; a first principles framework from which that&nbsp; advice emerges. And when you start applying it,&nbsp;&nbsp; you're applying it with a degree of nuance that&nbsp; you couldn't if you're just following a rule. So,&nbsp;&nbsp; I think one is, it does come down to good&nbsp; judgment, I think. I don't know how to teach that.&nbsp; I'm a huge believer in good judgment. It's&nbsp; one of the things I hire for. I just think&nbsp;&nbsp; that's something that probably comes from a&nbsp; mix of self perfection. You really need to&nbsp;&nbsp; hold yourselves accountable as an entrepreneur,&nbsp; as a product manager. If you made a bad decision,&nbsp;&nbsp; spend time reflecting on it, number one. And&nbsp; really, try to understand why and try to always&nbsp;&nbsp; improve your judgment. I think at the end of the&nbsp; day, that is why you are a good entrepreneur,&nbsp;&nbsp; a good product manager. And number two, when&nbsp; you get advice, really understand where it's&nbsp;&nbsp; coming from and why so that you can create your&nbsp; own independent view of where that advice came&nbsp;&nbsp; from and recognize that no one's advice is&nbsp; statistically significant or very rarely is&nbsp;&nbsp; it. If you're getting advice on investing from&nbsp; Warren Buffett, yeah, okay, it's statistically&nbsp;&nbsp; significant, but most advice is like something&nbsp; happened to you once and you have regrets. I love that you're like, I don't know if I&nbsp; have a great answer then you just give us&nbsp;&nbsp; an incredible answer to this question. I want to&nbsp; go in a different direction. You mentioned that&nbsp;&nbsp; you describe yourself as an engineer. I know I&nbsp; heard you code to relax still. Let me just ask&nbsp;&nbsp; you this question, something a lot of people in&nbsp; college are thinking about. Do you think it still&nbsp;&nbsp; makes sense to learn to code? Do you think this&nbsp; will significantly change in the next few years? I do still think studying computer science&nbsp; is a different answer than learning to code,&nbsp;&nbsp; but I would say I still think it's extremely&nbsp; valuable to study computer science. I say that&nbsp;&nbsp; because I think computer science is more than&nbsp; coding. If you understand things like Big O&nbsp;&nbsp; notation or complexity theory or study algorithms&nbsp; and why a randomized algorithm works and why two&nbsp;&nbsp; algorithms with the same Big O complexity, one can&nbsp; then practice perform better than others and why a&nbsp;&nbsp; cache miss matters and just all these little...&nbsp; There's a lot more to coding than writing the&nbsp;&nbsp; code. The reason I think that is I do think the&nbsp; act of creating software is going to transform&nbsp;&nbsp; from typing into a terminal or typing into&nbsp; Visual Studio code to operating a code-generating&nbsp;&nbsp; machine. I think that is the future of creating&nbsp; software. But I think operating a code-generating&nbsp;&nbsp; machine requires systems thinking and I think that&nbsp; computer science, there are other disciplines as&nbsp;&nbsp; well, but computer science is a wonderful major to&nbsp; learn systems thinking and at the end of the day,&nbsp;&nbsp; AI will facilitate creating this software. We may do a lot more in the next few years&nbsp;&nbsp; we can't even imagine, but your job as the&nbsp; operator of that code-generating machine is&nbsp;&nbsp; to make a product or to solve a problem and you&nbsp; really need to have great systems thinking and&nbsp;&nbsp; you're going to be managing this machine that's&nbsp; doing a lot of the tedious work of making the&nbsp;&nbsp; button or connecting to the network. But as you're&nbsp; thinking of the intersection of a technology and&nbsp;&nbsp; a business problem, you're trying to affect a&nbsp; system that will solve that problem at scale&nbsp;&nbsp; for your customers and that systems thinking is&nbsp; always the hardest part of creating products.&nbsp; I'll just give you, it's this cheesy simple&nbsp; example, but I think it's representative.&nbsp;&nbsp; At Facebook, we spent a lot of time designing&nbsp; the newsfeed and if you ever had a really,&nbsp;&nbsp; really good designer and they showed you at the&nbsp; time, a Photoshop mock-up of the newsfeed, it was&nbsp;&nbsp; just all as beautiful. The photos, the family was&nbsp; happy and the photo was a perfect photo and the&nbsp;&nbsp; posts were all perfectly grammatically correct and&nbsp; of a completely normal length and the comments and&nbsp;&nbsp; there was the like... Everything was just perfect.&nbsp; And then you'd implement that design and you'd&nbsp;&nbsp; look at your own newsfeed and it looked like shit&nbsp; because it turns out not everyone's photos were&nbsp;&nbsp; made by a professional photographer. The posts&nbsp; were all these different lengths. The comments&nbsp;&nbsp; were like, you suck and... All that stuff. And then all of a sudden you realize that&nbsp;&nbsp; designing a newsfeed, Photoshop is the easy part.&nbsp; You need to actually design a system that produces&nbsp;&nbsp; both in content and visual design, like a&nbsp; delightful experience given input you don't&nbsp;&nbsp; control. And that's a system, it's sort of a&nbsp; design and it's just, what we did practically,&nbsp;&nbsp; I am sure it's changed a lot since I left in&nbsp; 2012, but we made a system so designers had&nbsp;&nbsp; to show their newsfeed designs with real&nbsp; newsfeed data that was messy rather than&nbsp;&nbsp; anything artificial because I think it&nbsp; forced the process to be more realistic.&nbsp; But I say that because I think that whether&nbsp; AI is writing code or doing the design or&nbsp;&nbsp; doing all these other things, you need to learn&nbsp; how to have a system in your head. You need to&nbsp;&nbsp; understand the basics of what's hard and what's&nbsp; easy and what's possible and what's impossible.&nbsp;&nbsp; And AI can help you do that too, by the way. But&nbsp; I do think that's a really useful skill. I think&nbsp;&nbsp; in general, with the advent of AI agents and AI&nbsp; approaching super intelligence in certain domains,&nbsp;&nbsp; I think the tools with which we do our job will&nbsp; change a lot. I think it's very important to have&nbsp;&nbsp; a very loose attachment to the way we do our&nbsp; jobs and that story that we won't talk about&nbsp;&nbsp; when I rewrote Google Maps, everyone talks&nbsp; about that story and I think it's because of&nbsp;&nbsp; Paul [inaudible 00:35:57] who told it on some&nbsp; podcasts and that's where it made the rounds.&nbsp; I think that's going to end up this vestige of the&nbsp; past, almost like the human calculators at NASA&nbsp;&nbsp; before the computers were invented, like wow, a&nbsp; person was a calculator? Whoa, that's fun. Tell me&nbsp;&nbsp; that story. I think just what I was good at will&nbsp; no longer be useful in the future or certainly not&nbsp;&nbsp; valuable in the future and that's okay. So I think&nbsp; we need to have a really loose view of it, but the&nbsp;&nbsp; idea that you shouldn't study these disciplines,&nbsp; it's like people say, I don't want to study math&nbsp;&nbsp; because I'm not going to use it in my career for&nbsp; X. Well, studying maths is quite important. It&nbsp;&nbsp; teaches you how to think. It teaches you how the&nbsp; world works, physics, math, and I think computer&nbsp;&nbsp; science especially, at least the foundations of&nbsp; it, will continue to be the foundations of how&nbsp;&nbsp; we build software and understanding that when&nbsp; you're interacting particularly with something&nbsp;&nbsp; that's smarter than you, producing code you might&nbsp; not completely understand how you constrain it and&nbsp;&nbsp; how you get it to produce these outcomes. I think&nbsp; it will require a lot of sophistication actually. That's such a great answer. There's&nbsp; this always sense of this binary,&nbsp;&nbsp; should I learn to code or not? And your point&nbsp; here is learn to understand how engineering&nbsp;&nbsp; works and how systems work and what your&nbsp; code does and how it all interconnects,&nbsp;&nbsp; but the way you actually do the coding at your&nbsp; desk will change significantly. This reminds me of&nbsp;&nbsp; something you mentioned on a podcast recently.&nbsp; This idea that you think there's going to,&nbsp;&nbsp; or there should be a new programming language&nbsp; that is more designed for LLMs versus humans.&nbsp;&nbsp; Can you just talk about that because I think&nbsp; a lot of people aren't thinking about that? I don't know if it's a language, I would call it a&nbsp; programming system because I think language might&nbsp;&nbsp; be too limited. My reductive version of the&nbsp; past, what 40 years of computers maybe more,&nbsp;&nbsp; is we created the hardware for computers, then we&nbsp; created punch cards, which is the way in the late&nbsp;&nbsp; '70s you would tell a computer what to do or&nbsp; maybe mid to late '70s. Then we invented early&nbsp;&nbsp; operating systems and time-sharing systems from&nbsp; the invention of things like Unix at Bell Labs and&nbsp;&nbsp; Berkeley, you ended up with the C programming&nbsp; language, Fortran and a lot of higher level&nbsp;&nbsp; programming languages. I think Fortran and then C. And we moved up the layers of abstraction. No one&nbsp;&nbsp; does punch cards anymore, obviously. Few people&nbsp; write assembly language. Some people write C,&nbsp;&nbsp; some people write REST. But a lot of people write&nbsp; Python and TypeScript and things like that. And as&nbsp;&nbsp; we've invented more and more abstractions, we've&nbsp; made it easier to do high-leverage things. So,&nbsp;&nbsp; if you look at how remarkable Google was back&nbsp; in the day or Google Maps, you could probably&nbsp;&nbsp; give a lot of react programmers the task of make&nbsp; a draggable map now and I think a lot of people&nbsp;&nbsp; could do it. That was true RND back in the day. When Salesforce was created in 1998, just putting&nbsp;&nbsp; a database in the cloud was hard and that alone&nbsp; was a technical moat that is now trivial with&nbsp;&nbsp; Amazon Web Services and that technical moat is&nbsp; comically narrow, but the product moat is quite&nbsp;&nbsp; large. I think that if the act of writing code&nbsp; is going from something that is very costly to&nbsp;&nbsp; the marginal cost of that going to zero, how many&nbsp; of the abstractions that we've built are based on&nbsp;&nbsp; human program or productivity? I think a ton.&nbsp; I always laugh that I assume Python is probably&nbsp;&nbsp; the most common generated code just because&nbsp; of how much it's in the training data and&nbsp;&nbsp; data scientists love Python and I love Python too.&nbsp; It's such a comically bad thing for AI to generate&nbsp;&nbsp; just because it's one of the most inefficient&nbsp; programming languages of all time. If you know&nbsp;&nbsp; the global interpreter lock and just slow. And&nbsp; I've written a lot of high-scale web services and&nbsp;&nbsp; it's just quite slow and it's very hard to verify. It's not as bad as Perl, but if you have a big&nbsp;&nbsp; Python program, how many errors will you find&nbsp; at runtime versus before releasing it? So,&nbsp;&nbsp; Python was designed to be very ergonomic,&nbsp; almost looked like pseudo code for humans,&nbsp;&nbsp; for me to write code in a delightful way. That's&nbsp; why data scientists love it so much. So as we move&nbsp;&nbsp; to a world where let's just postulate, and&nbsp; I'm not sure this will be completely true,&nbsp;&nbsp; that we're not going to write a lot of code&nbsp; as people. We're going to be operating these&nbsp;&nbsp; code-generating machines. We probably don't care&nbsp; how ergonomic the programming language is. What we&nbsp;&nbsp; care about is when this machine generates code, do&nbsp; we know that it did what we wanted it to do? And&nbsp;&nbsp; if it doesn't do we want it to do, can we change&nbsp; it easily? I think there's a lot of insights in&nbsp;&nbsp; programming languages that could serve this. So Rust I think, is interesting because if&nbsp;&nbsp; I asked you to look at a C program and say,&nbsp; "Does it leak memory?" You probably couldn't&nbsp;&nbsp; do it that well just because it's really hard&nbsp; and if it's a very, a million line C program,&nbsp;&nbsp; it's going to be very, very hard. If I asked you&nbsp; to verify that a Rust program doesn't leak memory,&nbsp;&nbsp; you would just have to compile it. And&nbsp; because it has compile time, memory safety,&nbsp;&nbsp; just the act of compiling successfully tells&nbsp; you that's true. I think we need more things&nbsp;&nbsp; like that because if an AI is generating this&nbsp; code, by definition, if you have to read every&nbsp;&nbsp; line that is going to be the limiting factor for&nbsp; producing the code or worse, you're just not going&nbsp;&nbsp; to read every line and you're going to emit a&nbsp; bunch of unsafe unverified code into the wild.&nbsp; And so, the question is how do you enable humans&nbsp; to have as much leverage as possible? Which means&nbsp;&nbsp; using computers to do the work on your behalf. You&nbsp; could have obviously the simplest form of this,&nbsp;&nbsp; is AI supervising AI and doing code reviews and&nbsp; that's great. Certainly, self-reflection is a&nbsp;&nbsp; really effective way of improving the robustness&nbsp; of an AI system. But I do think if it doesn't&nbsp;&nbsp; matter how tedious it is to write the code,&nbsp; you could probably layer on some techniques&nbsp;&nbsp; that are out of fashion, like formal verification,&nbsp; unit testing, other things. And if you layer all&nbsp;&nbsp; these on, I'm thinking about it as, I as a...&nbsp; It's like the guy in the matrix with the green&nbsp;&nbsp; letters coming down, how can I make something so&nbsp; I as a operator of the code generating machine can&nbsp;&nbsp; produce incredibly complex scale software,&nbsp; incredibly quickly and know that it works?&nbsp; If you start with that as your design center,&nbsp; I think you'd probably changed the languages,&nbsp;&nbsp; you'd probably changed the systems, you'd&nbsp; probably change all these things and you're&nbsp;&nbsp; probably going to bring to bear a lot of things.&nbsp; And what's really fun about it is you can loosen&nbsp;&nbsp; a lot of constraints, like coding is free.&nbsp; Okay, so that's neat. With that in mind,&nbsp;&nbsp; what do you want to do? What would be best suited&nbsp; for the language, the compiler for testing,&nbsp;&nbsp; for self-reflection, for supervisor models,&nbsp; all these things. I think that's more of a&nbsp;&nbsp; programming system than a language, but I&nbsp; think when we create something like that,&nbsp;&nbsp; it can really enable creators, builders to create&nbsp; incredibly robust, incredibly complex systems.&nbsp; And I'm super excited about VibeCoding, but I&nbsp; don't know generating a prototype has been the&nbsp;&nbsp; limiting factor in software ever. It's actually&nbsp; building increasingly complex systems and actually&nbsp;&nbsp; changing them with agility. If you look at the&nbsp; famous Netscape one to Netscape two rewrite,&nbsp;&nbsp; somewhat, a lot of people attribute that&nbsp; to part of their failure against Internet&nbsp;&nbsp; Explorer. It's like making these things is not&nbsp; hard. Maintaining them is hard and ensuring&nbsp;&nbsp; they're robust is hard. And I think we're&nbsp; in the very early phases of defining what&nbsp;&nbsp; this new system for developing software looks&nbsp; like and I'm very excited to see what emerges. I feel like we're definitely living in the&nbsp; future when someone like you is suggesting&nbsp;&nbsp; that we build a matrix like experience and&nbsp; that's going to be potentially the future&nbsp;&nbsp; of coding and building. I can't wait for that. It&nbsp; feels like a great opportunity and a fun project.&nbsp; This episode is brought to you by&nbsp; Vanta and I'm very excited to have&nbsp;&nbsp; Christina Cacioppo CEO and co-founder Vanta&nbsp; joining me for this very short conversation. Great to be here. Big fan of&nbsp; the podcast and the newsletter. Vanta is a long time sponsor of the show,&nbsp;&nbsp; but for some of our newer listeners,&nbsp; what does Vanta do and who is it for? Sure. So we started Vanta in 2018 focused&nbsp; on founders helping them start to build out&nbsp;&nbsp; their security programs and get credit&nbsp; for all of that hard security work with&nbsp;&nbsp; compliance certifications like SOC 2 or ISO&nbsp; 2701. Today, we currently help over 9,000&nbsp;&nbsp; companies including some start-up household&nbsp; names like Atlassian Ramp and LangChain,&nbsp;&nbsp; start and scale their security programs&nbsp; and ultimately, build trust by automating&nbsp;&nbsp; compliance, centralizing GRC, and&nbsp; accelerating security reviews. That is awesome. I know from experience&nbsp; that these things take a lot of time and&nbsp;&nbsp; a lot of resources and nobody&nbsp; wants to spend time doing this. That is very much our experience, but&nbsp; before the company and to some extent,&nbsp;&nbsp; during it. But the idea is&nbsp; with automation, with AI,&nbsp;&nbsp; with software, we are helping customers&nbsp; build trust with prospects and customers&nbsp;&nbsp; in an efficient way. And our joke, we started&nbsp; this compliance company so you don't have to. We appreciate you for doing&nbsp; that. And you have a special&nbsp;&nbsp; discount for listeners. They can get&nbsp; $1,000 off Vanta at vanta.com/lenny.&nbsp;&nbsp; That's V-A-N-T-A .com/lenny for $1,000&nbsp; off Vanta. Thanks for that, Christina. Thank you. Okay. One more question along these lines and then&nbsp; I want to zoom out on just where AI is heading and&nbsp;&nbsp; something I love to ask folks like you that&nbsp; are at the cutting edge of AI is what you're&nbsp;&nbsp; teaching your kids. I know you have kids,&nbsp; I feel like the world is going to be very&nbsp;&nbsp; different when they grow up. What are you&nbsp; encouraging them to learn that you think is&nbsp;&nbsp; different maybe from previous generations to help&nbsp; them be successful in a world of AI abundance? I don't know if I'm teaching them&nbsp; differently, but I'm really trying&nbsp;&nbsp; to encourage them to make AI a part of&nbsp; their lives. I was reflecting actually&nbsp;&nbsp; when I took the AP calculus exams in '97, '98 AB&nbsp; and BC, I could use a graphing calculator. And&nbsp;&nbsp; I haven't done this research I was meaning to&nbsp; plug this into ChatGPT before our conversation,&nbsp;&nbsp; but I'll do it after. Did the calculus exam change&nbsp; before and after they allowed the calculator in&nbsp;&nbsp; the exam? I assume it did. But essentially,&nbsp; to when you allow the calculator in the exam,&nbsp;&nbsp; you need to make sure that none of the questions&nbsp; benefit people for having a calculator or not,&nbsp;&nbsp; which actually forces you to rethink the&nbsp; problems to test calculus knowledge that&nbsp;&nbsp; don't benefit from like road arithmetic or the&nbsp; other things you can do on a graphing calculator.&nbsp; I think that a lot of education doesn't&nbsp; presume you have a super intelligence in&nbsp;&nbsp; your pocket. And so, if you ask someone to&nbsp; write an essay on a book that they read,&nbsp;&nbsp; you could probably hallucinate one pretty easily&nbsp; from one of the big providers like ChatGPT. And&nbsp;&nbsp; maybe if you are skilled enough that prompting,&nbsp; maybe even your teacher won't know it's written&nbsp;&nbsp; by an AI. So what do you do? How do you teach kids&nbsp; differently? It's really hard for teachers right&nbsp;&nbsp; now because I think we haven't gone through the&nbsp; transition of adding calculators to the exams. So,&nbsp;&nbsp; I think a lot of the mechanisms we have to&nbsp; evaluate students are broken by the existence&nbsp;&nbsp; of ChatGPT and the like. So I think we're in&nbsp; a very awkward phase, but I think we can still&nbsp;&nbsp; both teach kids how to think and teach kids how to&nbsp; learn. And I think our education system can catch&nbsp;&nbsp; up and I actually think these models can be one of&nbsp; the most effective educational tools in history.&nbsp; I don't know if you're a visual learner or reading&nbsp; learner. I like to read. I didn't love going to&nbsp;&nbsp; lectures. I don't learn that well from them. I&nbsp; like to read the book and if you have a teacher&nbsp;&nbsp; who doesn't teach in your style, you can now&nbsp; go home and ask ChatGPT to teach you in another&nbsp;&nbsp; mechanism. My kids use ChatGPT to quiz them before&nbsp; a test. You can use audio mode or chat mode. It's&nbsp;&nbsp; better than cue cards. My daughter took home a&nbsp; Shakespeare book, she took a picture of a page she&nbsp;&nbsp; didn't understand and ChatGPT explained it to her&nbsp; way better than I would've as well. I think every&nbsp;&nbsp; child in this world has a personalized tutor that&nbsp; can teach them in the way that they best learn,&nbsp;&nbsp; visually, over audio, reading. We have a&nbsp; platform that can test you, that can quiz you.&nbsp;&nbsp; I think it's really an amplifier of agency. I think the kids who have agency, who have&nbsp;&nbsp; aspirations to learn something, I think you have&nbsp; what is the best combination of every teacher&nbsp;&nbsp; you've ever had and these models and you can use&nbsp; it. So with my kids, my oldest daughter learned&nbsp;&nbsp; how to code and she was making a website and every&nbsp; time she had a question for me, I would just make&nbsp;&nbsp; her use ChatGPT. Not because I was trying to&nbsp; be an obnoxious father, but I'm like she needs&nbsp;&nbsp; to learn to use this tool because it's amazing. So, I really am trying to have them learn how to&nbsp;&nbsp; use it constructively in their lives. But all&nbsp; that said, I just feel a ton of empathy for&nbsp;&nbsp; public school teachers right now. It's very hard&nbsp; because the technology is moving faster than our&nbsp;&nbsp; educational system. And I think particularly&nbsp; as it relates to evaluation, it's just really&nbsp;&nbsp; challenging for teachers right now. And I worry&nbsp; because these technologies amplify agency, the&nbsp;&nbsp; opposite can also be true. If you are a student&nbsp; trying to not learn something, I think these tools&nbsp;&nbsp; probably provide a lot of mechanisms to avoid&nbsp; it as well. And so, I think there's a challenge&nbsp;&nbsp; for parents and teachers and I think we're&nbsp; going to end up with a handful of years here.&nbsp; But I brought up the calculus AP exam because&nbsp; obviously, a graphing calculator is not ChatGPT,&nbsp;&nbsp; don't get me wrong. But I think we've been&nbsp; able to figure out a way to conform homework&nbsp;&nbsp; and in-class learning and tests around&nbsp; the technologies available to us fairly&nbsp;&nbsp; successfully to date. And I'm fairly confident&nbsp; we'll figure it out and I think it's going to...&nbsp;&nbsp; And on the much more positive side, I don't&nbsp; know, I went to public schools, I don't know&nbsp;&nbsp; if you did too. You end up with some pretty bad&nbsp; teachers at times and now, you have an outlet.&nbsp;&nbsp; You don't need to be the rich kid who can afford&nbsp; a tutor anymore to get tutoring. If you are a kid&nbsp;&nbsp; who excels in math and your school doesn't have&nbsp; advanced statistics classes, well, now you do.&nbsp; So I think this is just an incredibly&nbsp; democratizing force with kids who have&nbsp;&nbsp; agency and I think that's very exciting. I'm&nbsp; hopeful that there's a 11-year-old right now&nbsp;&nbsp; who's going to start a really amazing company&nbsp; 10 years from now whose ChatGPT is going to&nbsp;&nbsp; be their primary tutor that led to that&nbsp; outcome. And I think that's pretty cool. I have a two-year-old and it feels&nbsp; like there's a new milestone of,&nbsp;&nbsp; there's like when to give them a phone,&nbsp; when to give them, I don't know, Snapchat,&nbsp;&nbsp; whatever kids use these days and then&nbsp; it's like when to give them their first&nbsp;&nbsp; ChatGPT account. Well no, I wonder&nbsp; how soon that's supposed to happen. I think my personal take is, it's different than&nbsp; the former two. I don't think mobile phones are&nbsp;&nbsp; great in school or great for kids and I personally&nbsp; advocate for waiting a long time. But I think that&nbsp;&nbsp; ChatGPT is more like Google search and it's&nbsp; one thing to have a device in your pocket&nbsp;&nbsp; that's addictive and has push notifications, but&nbsp; it's another thing to use AI to learn. And so,&nbsp;&nbsp; I think the two are different. And I really think&nbsp; of AI fundamentally as a utility. I don't think a&nbsp;&nbsp; lot of parents before ChatGPT said, "When should I&nbsp; let my kid use Google search?" That's a different&nbsp;&nbsp; type of tool. I think thinking of it like that&nbsp; is the way I think about these technologies. Is the form factor for your kids like&nbsp; an iPad or a laptop or something? Yeah. They use the computer on the desk. Got it. All right. Good tips. This is good for me&nbsp; to learn all these things as my kid ages. Okay,&nbsp;&nbsp; I'm going to zoom out and let's talk about&nbsp; business strategy AI. One of the biggest questions&nbsp;&nbsp; a lot of founders think about these days is just&nbsp; where should I build? What will foundational model&nbsp;&nbsp; companies not squash and do themselves? Being&nbsp; someone building a very successful AI business&nbsp;&nbsp; and also being on the board of OpenAI, feel like&nbsp; you have a really unique perspective on what is&nbsp;&nbsp; probably a good idea and it's probably not a good&nbsp; idea. How do you think the AI market is going to&nbsp;&nbsp; play out and where do you think founders&nbsp; should focus and also just try to avoid? I think there's three segments of the AI market&nbsp; that will end up fairly meaningful markets and&nbsp;&nbsp; then I'll end with how I think it's going to&nbsp; play out. So first is the frontier model market&nbsp;&nbsp; or foundation model market. I think this will end&nbsp; up the small handful of hyperscalers and really&nbsp;&nbsp; big labs just like the cloud infrastructure&nbsp; as a service market. And the reason for that&nbsp;&nbsp; is that creating a frontier model is entirely&nbsp; a function of CapEx. And you need a company&nbsp;&nbsp; with huge amounts of CapEx capacity to build one&nbsp; of these models. All of the companies that were&nbsp;&nbsp; startups that tried to do this have already&nbsp; been consolidated or almost all of them,&nbsp;&nbsp; inflection, adapt, character and others. And&nbsp; I think there doesn't appear to be a viable&nbsp;&nbsp; business model for a startup because of the&nbsp; amount of CapEx required and there's just not&nbsp;&nbsp; enough fundraising runway to get to escape&nbsp; velocity. And also, the models deteriorate&nbsp;&nbsp; in value fairly quickly as an asset class. And so, you need just a lot of scale to make&nbsp;&nbsp; a return on the investment for a model that&nbsp; deteriorates in value so quickly. So, I think&nbsp;&nbsp; that's going to end up probably no entrepreneur&nbsp; should build a frontier model. That's my take. Unless you're Elon. Yeah. Oh, yeah. He's different. And he has the&nbsp; capacity to raise billions in capital and my&nbsp;&nbsp; guess is most of your other listeners don't, and&nbsp; then he is the greatest of all time for reason&nbsp;&nbsp; and he's different. You don't compare yourself to&nbsp; him. The other part of the market is the tooling,&nbsp;&nbsp; and I think there's a lot of folks selling&nbsp; pickaxes in the Gold Rush. This is data labeling,&nbsp;&nbsp; services. This is data platforms, it's eval tools.&nbsp; More specialized models like 11 Labs has a great&nbsp;&nbsp; set of voice models that a lot of companies use&nbsp; that are really high quality and it's like if&nbsp;&nbsp; you're trying to be successful in AI, what are&nbsp; the different tools and services that you need?&nbsp; There is some risk to the tooling market&nbsp; because it's pretty close to the sun. So,&nbsp;&nbsp; if you look at the infrastructure as a service&nbsp; market and the cloud tooling market like the&nbsp;&nbsp; Confluent and Databricks and Snowflake, a lot of&nbsp; the Amazon and Azure and others have competing&nbsp;&nbsp; products in those areas because they're very&nbsp; adjacent to the infrastructure itself and every&nbsp;&nbsp; infrastructure provider is trying to differentiate&nbsp; by moving up the stack and you're right there.&nbsp; So, there's some real meaningful companies as I&nbsp; mentioned, like Snowflake, Databricks, Confluent&nbsp;&nbsp; and others, but there's a lot of others that were&nbsp; obviated by technology from the infrastructure&nbsp;&nbsp; providers themselves. So those companies probably&nbsp; are the most at risk for a developer day from one&nbsp;&nbsp; of these big foundation model companies releasing&nbsp; exactly what they do. So there's probably a lot&nbsp;&nbsp; of people who need your tool, but the question&nbsp; will be if or when is probably the right way to&nbsp;&nbsp; think about it, one of these large infrastructure&nbsp; providers introduces a competitor, why will people&nbsp;&nbsp; continue to choose you? So it's a good market&nbsp; but it's a little bit close to the end as I said.&nbsp; Then there's the applied AI market. I think this&nbsp; will play out for companies who build agents. I&nbsp;&nbsp; think agent is the new app. I think that's going&nbsp; to be the product form factor. There's companies&nbsp;&nbsp; like Sierra, we help companies build agents to&nbsp; answer the phone or answer the chat for customer&nbsp;&nbsp; experience and customer service. There's companies&nbsp; like Harvey that make agents for both a legal,&nbsp;&nbsp; paralegal profession, anti-trust reviews,&nbsp; reviewing contracts etc, etc. There's companies&nbsp;&nbsp; that do content marketing. There's companies that&nbsp; do supply chain analysis. I think this is like&nbsp;&nbsp; the software as a service market. They'll probably&nbsp; be higher margin companies because you're selling&nbsp;&nbsp; something that achieves a business outcome&nbsp; as opposed to being a byproduct of the models&nbsp;&nbsp; themselves. They will almost certainly pay taxes&nbsp; down to the model providers, which is why those&nbsp;&nbsp; model providers will end up extremely large scale&nbsp; but probably slightly lower margin and I think the&nbsp;&nbsp; market for them will be probably less technical. If you think about the purest form of software as&nbsp;&nbsp; a service, it's not like you ask what database&nbsp; do you use? It's really about the feature and&nbsp;&nbsp; function. I think that's where agents will go. I&nbsp; think it's going to be more about product than it&nbsp;&nbsp; is about technology over time. Just going back to&nbsp; my metaphor, in 1998 when Mark and Parker started&nbsp;&nbsp; Salesforce, just getting that database running&nbsp; in the cloud was like a technical achievement.&nbsp;&nbsp; Nowadays, no one asks about that because you can&nbsp; just spin up a database in AWS or Azure and it's&nbsp;&nbsp; like no problem. I think today, orchestrating&nbsp; an agentic process on top of the models,&nbsp;&nbsp; sounds really fancy and it's really hard and all&nbsp; that stuff. I'm pretty sure that's going to be&nbsp;&nbsp; easy in three or four years. It's just like&nbsp; just as the technology improves. And so,&nbsp;&nbsp; over time you say, what is an agent&nbsp; company? Well, it looks a little bit&nbsp;&nbsp; like [inaudible 00:57:30] as a service. You talk a little bit less about how you&nbsp;&nbsp; deal with the models in the same way modern&nbsp; SaaS, few people ask what database you use,&nbsp;&nbsp; but you'll probably ask a lot about the&nbsp; workflows and what business outcomes that&nbsp;&nbsp; you're driving. Are you generating leads for a&nbsp; sales team? Are you minimizing your procurement&nbsp;&nbsp; spend? Whatever value you're providing,&nbsp; it's going to slowly evolve towards that.&nbsp; I'm very excited. I don't think startups&nbsp; should probably build foundation models.&nbsp;&nbsp; But you can shoot your shot if you have&nbsp; a vision for the future, go for it. But I&nbsp;&nbsp; think it's probably a challenging market that's&nbsp; already consolidated. I'm very excited about the&nbsp;&nbsp; other two markets. I'm particularly excited as&nbsp; building agents becomes easier, to see a lot of&nbsp;&nbsp; long tail agent companies come out. I was looking&nbsp; at a website for the top 50 software companies in&nbsp;&nbsp; the stock market and obviously, the top five are&nbsp; the big, big boom ones like Microsoft, Amazon,&nbsp;&nbsp; Google, all that, but the next 50 are all SaaS&nbsp; companies and some of them are very exciting,&nbsp;&nbsp; some of them are super boring, but this is how&nbsp; the software market has evolved and I think we're&nbsp;&nbsp; going to see something similar with agents. It's not just going to be these huge markets&nbsp;&nbsp; like we're in customer service and software&nbsp; engineering. It's going to be a lot of things&nbsp;&nbsp; where people are spending a lot of time&nbsp; and resources that an agent can just solve,&nbsp;&nbsp; but it requires an entrepreneur who actually&nbsp; understands that business problem, and deeply,&nbsp;&nbsp; and I think that's where a lot of the value&nbsp; is going to be unlocked in the AI market. That is incredibly helpful. This makes me&nbsp; think about, I had Marc Benioff on the podcast,&nbsp;&nbsp; you guys were co-CEOs and he was extremely&nbsp; agent-pilled. All he wanted to talk about&nbsp;&nbsp; was Agentforce. Clearly you're also&nbsp; very agent-pilled. What is it that- I've never heard the term&nbsp; agent-pilled [inaudible 00:59:18]. Clearly you guys saw something that was&nbsp; just like, okay, we need to go all in on&nbsp;&nbsp; agents. This is the future. What is it you&nbsp; think people are missing about just why this&nbsp;&nbsp; is such a critical change in the way software&nbsp; is going to work? What are people not seeing? If you talk to an economist like Larry Summers&nbsp; who, on the OpenAI board with me, they'll talk&nbsp;&nbsp; about what is the value of technology? Will&nbsp; it help strive productivity in the economy.&nbsp;&nbsp; And if you look at one of the big jumps in&nbsp; productivity in the economy was in the '90s,&nbsp;&nbsp; and I think a lot of folks I talked to think it&nbsp; was actually that very first wave of computing&nbsp;&nbsp; where people made ERP systems and just put&nbsp; accounting into computers and databases,&nbsp;&nbsp; even mainframes, we're talking like the PC&nbsp; era. Because it was such a huge step-up,&nbsp;&nbsp; just imagine the ledgers of numbers that you'd&nbsp; have for a large multinational company before&nbsp;&nbsp; and it truly just transformed departments. I'll give you a little toy example. My dad&nbsp;&nbsp; just retired. He was a mechanical engineer and&nbsp; he was talking about when he first started his&nbsp;&nbsp; career in the late '70s and he went into a&nbsp; mechanical engineering firm, the majority of&nbsp;&nbsp; the firm were drafts people. So basically, you&nbsp; take an engineering design but you needed to do&nbsp;&nbsp; all the different vantage points and for all the&nbsp; different floors and to give to the contractor to&nbsp;&nbsp; do the thing. Now, there are zero drafts people&nbsp; at his company. You just make the design in first&nbsp;&nbsp; AutoCAD and now Revit and it's a 3D model and&nbsp; the drafting has actually been eliminated. It's&nbsp;&nbsp; just not a thing one needs to do anymore. The&nbsp; actual design and drafting, drafting is not a&nbsp;&nbsp; thing that exists. It's just a design. That's&nbsp; true productivity gains, right? It's like the&nbsp;&nbsp; job of the mechanical engineering firm was to do&nbsp; a design. The drafting was this necessary output&nbsp;&nbsp; for the contractor, but it wasn't really adding&nbsp; value. It was just like the supply chain change.&nbsp; If you look at the history of the software&nbsp; industry from the PC on, there's been meaningful&nbsp;&nbsp; productivity gains but just not nearly as&nbsp; meaningful as that first huge jump. And I'm&nbsp;&nbsp; not smart enough to know exactly why, but it&nbsp; is interesting, the promise of productivity&nbsp;&nbsp; gains from technology hasn't been as realized&nbsp; I think as some people thought. I think agents&nbsp;&nbsp; will truly start to bend the curve again like we&nbsp; did in the very early days of computing because&nbsp;&nbsp; software is going from helping an individual be&nbsp; slightly more productive to actually accomplishing&nbsp;&nbsp; a job autonomously. And as a consequence,&nbsp; just like you don't need drafts people in a&nbsp;&nbsp; mechanical engineering firm, you just won't need&nbsp; someone doing that thing anymore. It means they&nbsp;&nbsp; can do something else that's higher leverage&nbsp; and more productive and you can actually...&nbsp;&nbsp; A smaller group of people can accomplish more and&nbsp; truly drive productivity gains in the economy.&nbsp; And I think if you've ever sold enterprise&nbsp; software, you end up in these discussions as a&nbsp;&nbsp; vendor with the customer where you'll have a value&nbsp; discussion and you'll do these somewhat convoluted&nbsp;&nbsp; things like okay, it's like you're selling a&nbsp; sales thing. Okay, well, if every salesperson&nbsp;&nbsp; sells 5% more... And you should pay us a million&nbsp; dollars. And it's roughly that conversation and&nbsp;&nbsp; it's so unattributable especially... And it's&nbsp; why it's so hard to sell productivity software,&nbsp;&nbsp; which I learned the hard way, it's just hard&nbsp; to know what's the value of making everyone 10%&nbsp;&nbsp; more productive? Did you actually make them 10%&nbsp; more productive or did something else change? You&nbsp;&nbsp; don't really know all these things. But now&nbsp; with an agent actually accomplishing a job,&nbsp;&nbsp; not only is it actually truly driving productivity&nbsp; in a very real way, but it's measurable as well.&nbsp; So all those things combined means I think&nbsp; this is actually a step change in how we&nbsp;&nbsp; think about software because it does a job&nbsp; autonomously, which is more self-evident,&nbsp;&nbsp; a productivity driver. It's measurable so people&nbsp; value it differently as well, which is why I also&nbsp;&nbsp; believe in outcomes-based pricing for software. And all of that combined to me, it feels like&nbsp;&nbsp; as significant as the cloud or I think more&nbsp; technologically, but just in terms of how it&nbsp;&nbsp; transforms the business model of the software&nbsp; industry where there's going to be a before&nbsp;&nbsp; and after. I don't know how many people still&nbsp; sell perpetually licensed on premises software,&nbsp;&nbsp; but it's de minimis at this point. I think we're&nbsp; going to go through a similar transition. The&nbsp;&nbsp; whole market is going to go towards agents. I&nbsp; think the whole market is going to go towards&nbsp;&nbsp; outcomes-based pricing, not because it's the&nbsp; only way, but the market is going to pull&nbsp;&nbsp; everyone there because it's just so obviously&nbsp; the correct way to build and sell software. Let me pull on that last thread. So we&nbsp; had Madhavan on the podcast recently,&nbsp;&nbsp; pricing expert, legend, monetizing innovation&nbsp; author and he talked about pricing strategy&nbsp;&nbsp; for AI companies and he was very much in your&nbsp; camp of, if you can, you need to price your&nbsp;&nbsp; product as an outcome-based product and&nbsp; the access uses exactly what you shared,&nbsp;&nbsp; which is, you can do that if you can attribute&nbsp; the impact and it's autonomous, it's running on&nbsp;&nbsp; its own. And he actually used Sierra as one of&nbsp; the shining examples of this being successful.&nbsp;&nbsp; Can you just briefly just explain a little bit&nbsp; what is outcome-based pricing for people that&nbsp;&nbsp; haven't heard this term before and then just&nbsp; how does it work for Sierra to give an example? Yeah, I'll start with the example and&nbsp; then I'll broaden it. So at Sierra,&nbsp;&nbsp; we help companies make customer facing AI agents&nbsp; primarily for customer service, but more broadly,&nbsp;&nbsp; for customer experience. So if you have a problem&nbsp; with your [inaudible 01:04:58], you'll call or&nbsp;&nbsp; chat with Harmony, who's their AI agent. If&nbsp; you have ADT home security and your alarm&nbsp;&nbsp; doesn't work, you can chat with their AI&nbsp; agent. Sonos speakers, a lot of different&nbsp;&nbsp; consumer brands. And if you think about running a&nbsp; call center, there's a cost for every phone call&nbsp;&nbsp; that you take. Most of it is labor costs,&nbsp; but if you have, let's just say a typical&nbsp;&nbsp; phone call is anywhere between 10 and $20 USD.&nbsp; Some of it's software, some of it's telephony,&nbsp;&nbsp; but a lot of it is just like the hourly&nbsp; wage of the person answering the phone.&nbsp; So if an AI agent can take that call and solve&nbsp; it, that is in the industry often called a call&nbsp;&nbsp; deflection or a containment. And that essentially&nbsp; means you saved, call it $15 because you didn't&nbsp;&nbsp; have to have someone pick up the phone. So in&nbsp; our industry, basically we say, "Hey, if the&nbsp;&nbsp; AI agent solves the customer's problem, they're&nbsp; happy with it and you didn't have to pick up the&nbsp;&nbsp; phone," there's a pre-negotiated rate for that&nbsp; and we call it resolution based. There are other&nbsp;&nbsp; outcomes as well. We have some sales agents being&nbsp; paid a sales commission, believe it or not. We do.&nbsp;&nbsp; We really think of our agents as truly customer&nbsp; experience like the concierge for your brand and&nbsp;&nbsp; we want to make sure that our business model&nbsp; is aligned with our customer's business model.&nbsp; As you said, these agents need to be&nbsp; autonomous and the outcome has to be&nbsp;&nbsp; measurable. That's not always possible, but I&nbsp; think it's broadly possible. And what's really&nbsp;&nbsp; neat about it is if you talk to any CFO or&nbsp; head of procurement with their big vendors,&nbsp;&nbsp; they look at the bill of materials and it's&nbsp; overwhelming and it's impossible to know if&nbsp;&nbsp; you're getting the value that you hoped from that&nbsp; contract. I think consumption based, which was&nbsp;&nbsp; popular particularly in the infrastructure&nbsp; space is closer to it. But I'm not sure a&nbsp;&nbsp; token is actually a good measure of value from AI&nbsp; either. I always use the analogy, like right now,&nbsp;&nbsp; most of the coding agents are priced per token or&nbsp; per utilization, but there's this famous story of&nbsp;&nbsp; an Apple engineer who had a bad manager who's&nbsp; like had you report how many lines of code you&nbsp;&nbsp; wrote every day? Which every engineer in the world&nbsp; knows is an idiotic way to measure productivity.&nbsp; He famously went in with a report that had a&nbsp; negative number because I think he did a big&nbsp;&nbsp; refactoring, deleted a bunch and it was his&nbsp; way of saying like, fuck you to the man. I&nbsp;&nbsp; think tokens are similar. Yeah, you used a lot&nbsp; of tokens, like good for you, did it produce a&nbsp;&nbsp; pull request that was good? And I think that's&nbsp; the whole point of all this. I think there's&nbsp;&nbsp; a huge difference between outcomes-based pricing&nbsp; and usage based pricing because especially in AI,&nbsp;&nbsp; they're not necessarily even correlated and you&nbsp; could have a long phone call and not solve the&nbsp;&nbsp; customer's problem and they give you a negative&nbsp; review online and call the call center again,&nbsp;&nbsp; all that effort was for nothing. In fact,&nbsp; you might've added negative value. And so,&nbsp;&nbsp; I am a huge believer in this. And what's fun about it is it&nbsp;&nbsp; really just aligns... I think every technology&nbsp; company aspires to be a partner, not a vendor.&nbsp;&nbsp; And I think at Sierra, we are truly a partner&nbsp; to every single one of our customers because&nbsp;&nbsp; we're all aligned on what we want to achieve. And&nbsp; I think that is really where the software industry&nbsp;&nbsp; should go. It requires a lot of different shape&nbsp; of a company. You have to be able to help your&nbsp;&nbsp; customers achieve those outcomes. You can't just&nbsp; throw software at the wall because you'll never&nbsp;&nbsp; get paid if it doesn't. Your orientation becomes&nbsp; so extremely customer-centric when you do this the&nbsp;&nbsp; right way. I think it's just a better version of&nbsp; the software industry. So I think it's right from&nbsp;&nbsp; first principles, it's right for procurement&nbsp; partners and I think it's right for the world. We've been chatting a little&nbsp; bit about productivity gains.&nbsp;&nbsp; There's a lot of skepticism in the headlines&nbsp; these days of just like what is AI actually&nbsp;&nbsp; doing? Is it actually helping people be more&nbsp; productive? There was a recent study actually,&nbsp;&nbsp; I don't know if you saw, where they&nbsp; showed engineers were less productive&nbsp;&nbsp; with AI because it was just putting them in&nbsp; different directions. They had to research&nbsp;&nbsp; all what's going wrong here? So I think CX is&nbsp; a really good example where you clearly are&nbsp;&nbsp; seeing gains. Are you seeing actual gains at your&nbsp; company or any other company you work with outside&nbsp;&nbsp; of CX in terms of productivity that is like&nbsp; clearly yes, this is working and a huge deal? I'm extremely bullish on the productivity gains&nbsp; from AI, but I do think the tools and products&nbsp;&nbsp; right now are somewhat immature and it's quite&nbsp; counterintuitive. So, for example, almost every&nbsp;&nbsp; software engineering firm I know uses something&nbsp; like Cursor to help their software engineers.&nbsp;&nbsp; Most people use Cursor right now as a coding&nbsp; autocomplete, though they have a lot of agentic&nbsp;&nbsp; solutions and there's a lot of... OpenAI has Codex&nbsp; and Cloud has... I can't remember the Anthropic&nbsp;&nbsp; products. So there's lots of agentic agents&nbsp; coming as well. One of the interesting things&nbsp;&nbsp; because the technology is immature, the code it&nbsp; produces often has problems. There's a lot of&nbsp;&nbsp; people approaching this to actually realize those&nbsp; productivity gains because as any engineer who's&nbsp;&nbsp; written a lot of code will tell you, it's pretty&nbsp; easy to look at and edit and fix code you wrote.&nbsp; Reviewing other people's code or particularly&nbsp; finding a subtle logical error in someone else's&nbsp;&nbsp; code is actually really hard. It's actually much&nbsp; harder than editing code that you wrote yourself.&nbsp;&nbsp; So if the code produced by a coding agent is often&nbsp; incorrect, it actually can take a lot of cognitive&nbsp;&nbsp; load and time to fix it. And in fact, if you end&nbsp; up producing lots of issues with your customers,&nbsp;&nbsp; you could end up producing a lot of features,&nbsp; but actually, is like mucking up the machine&nbsp;&nbsp; a little bit and having something that's not&nbsp; ideal. There's a couple of techniques that I&nbsp;&nbsp; think are interesting. First, I think there's a&nbsp; lot of AI starts now working on things like code&nbsp;&nbsp; reviews. I think this idea of self-reflection in&nbsp; agents is really important. Having AI supervise&nbsp;&nbsp; the AI is actually very effective. Just think&nbsp; about it this way, if you produce an AI agent&nbsp;&nbsp; that's right 90% of the time, that's not that&nbsp; great, but how hard would it be to make another&nbsp;&nbsp; AI agent to find the errors the other 10% of&nbsp; the time? That might be a tractable problem.&nbsp; And if that thing's right 90% of the time, just&nbsp; for argument's sake, you can wire those things&nbsp;&nbsp; together and have something that's right 99%&nbsp; of the time. So it's just a math problem and&nbsp;&nbsp; it turns out that you can make something&nbsp; to generate code, you can make something&nbsp;&nbsp; to review code and you're essentially using&nbsp; compute for cognitive capacity and you can&nbsp;&nbsp; layer on more layers of cognition and thinking&nbsp; and reasoning and produce things increasingly&nbsp;&nbsp; robust. So I'm very excited about that. The other&nbsp; thing though is root cause analysis. So we have an&nbsp;&nbsp; engineer at Sierra who exclusively focuses on the&nbsp; model context protocol server serving our cursor&nbsp;&nbsp; instance. And our whole philosophy is, if cursor&nbsp; generated something incorrect, rather than just&nbsp;&nbsp; fixing it, try to root cause it. Try to get it so&nbsp; the next time Cursor will produce the correct code&nbsp;&nbsp; and essentially, is context engineering. What context did Cursor not have that would've&nbsp;&nbsp; been necessary to produce the right outcome? So&nbsp; I think people who are trying to get productivity&nbsp;&nbsp; gains in departments like software engineering&nbsp; need to stop waiting for the models to magically&nbsp;&nbsp; work if they want to see the gains now. And you&nbsp; really have to create root cause analysis and&nbsp;&nbsp; systems and say, how do we go root cause every bad&nbsp; line of code and actually give the right context&nbsp;&nbsp; and produce the right system so the models can&nbsp; do it today? Over time that'll probably be less&nbsp;&nbsp; necessary and you'll have less context engineering&nbsp; necessary to do it, but you really have to think&nbsp;&nbsp; of this as a system and I think people are waiting&nbsp; for the models to just magically get better. And&nbsp;&nbsp; I'm like, well that will happen eventually, but if&nbsp; you want the gains now you got to put in the work.&nbsp;&nbsp; That's essentially why applied AI companies exist. And the work is non-trivial, but you can do it.&nbsp;&nbsp; And so, for customers using platforms like Sierra,&nbsp; yeah, AI agents aren't perfect, but we're creating&nbsp;&nbsp; a system that lets customers create a virtuous&nbsp; cycle of improvement. If you want to go from a&nbsp;&nbsp; 65% automated resolution rate to 75%, we have&nbsp; a billion tools to let AI help you do that,&nbsp;&nbsp; identify opportunities for improvement, figure out&nbsp; why people are frustrated, what new capabilities&nbsp;&nbsp; can we add to our agent to improve the resolution&nbsp; rate? And you let AI put the needles at the&nbsp;&nbsp; top of the haystack on your behalf and I think&nbsp; that's really the way to optimize these systems. I've never heard of this technique of&nbsp; improving Cursor by adding additional&nbsp;&nbsp; context. What's the actual way of doing that?&nbsp; You build an MCP server that everything runs&nbsp;&nbsp; through or is it like you add Cursor&nbsp; rules? What's the actual approach there? I'm probably out of my depth here, but it's&nbsp; essentially MCP because that's how you provide&nbsp;&nbsp; context to Cursor. And I think that almost always&nbsp; when you have a model making a poor decision,&nbsp;&nbsp; if it's a good model, it's lack of context. And&nbsp; so, you really want to find the intersection of&nbsp;&nbsp; your particular product and code base with&nbsp; the context available to these coding agents&nbsp;&nbsp; and systems and fix it at the&nbsp; root is the principle here. Got it. That is very cool. I hadn't heard of&nbsp; people doing that, model context protocol,&nbsp;&nbsp; makes sense. We've talked about productivity gains&nbsp; outside TX. Just to give you a chance to share&nbsp;&nbsp; how amazing what you've built is, what are some&nbsp; of the gains you see from people using Sierra? Yeah, our customers see anywhere between 50&nbsp; and 90% of their customer service interactions&nbsp;&nbsp; completely automated, which I think is really&nbsp; exciting. And we serve just a really, really&nbsp;&nbsp; broad range of customers. We serve the health&nbsp; insurance industry, the healthcare provider space,&nbsp;&nbsp; banks. You can actually refinance your home&nbsp; using an agent. One of our customers built on&nbsp;&nbsp; our platform to the telecommunications industry,&nbsp; DIRECTV, SiriusXM to a lot of retailers as well,&nbsp;&nbsp; which is really fun. Everyone from Wayfair to&nbsp; clothing retailers like OluKai and Chubbies&nbsp;&nbsp; Shorts. What's really neat about it is it's&nbsp; a pretty diverse range of use cases and it's&nbsp;&nbsp; everything from helping you sign up for... We&nbsp; have an agent that helps with customer support in&nbsp;&nbsp; one of the big dating applications to helping you&nbsp; upgrade or downgrade your SiriusXM plan. Actually,&nbsp;&nbsp; it's really funny, we do technical support&nbsp; from everything from home alarm systems&nbsp;&nbsp; to sonar speakers to more recently, CAT&nbsp; scan machines, which I think is amazing.&nbsp; So technicians going in and fixing the CAT&nbsp; scan machine can chat with an AI agent to help&nbsp;&nbsp; them guide them through that process. We're the&nbsp; leader in the space, we're trying to enable every&nbsp;&nbsp; company in the world to create their agent with&nbsp; their brand at the top that I think will become&nbsp;&nbsp; as meaningful of a digital touch point as their&nbsp; website or their mobile app. In the short term,&nbsp;&nbsp; it can really transform the costs of running a&nbsp; customer service team. And what's remarkable is&nbsp;&nbsp; do so with really high customer satisfaction&nbsp; scores. That Weight Watchers agent, I believe&nbsp;&nbsp; has a customer satisfaction score of 4.6 out&nbsp; of five, which is pretty amazing. And what's&nbsp;&nbsp; interesting about service too, it's often people&nbsp; having a problem. And so, when you have a clear,&nbsp;&nbsp; I don't know if you use them in the airport, I&nbsp; think that agent has a CSAT score of 4.7 out of&nbsp;&nbsp; five people are coming in with a problem&nbsp; and [inaudible 01:16:19] delighted. And&nbsp;&nbsp; I think that's really the opportunity here. And our whole vision is that we're going to&nbsp;&nbsp; move towards a world where every single one of the&nbsp; interactions with your customers can be instant.&nbsp;&nbsp; It can be multilingual, it can be over audio, it&nbsp; can be over chat, it can be digital, it can be&nbsp;&nbsp; over the phone and it can be very personalized.&nbsp; And I think that's really, really exciting.&nbsp;&nbsp; And if you think about all the best moments you've&nbsp; had with a brand, it's like that store associate&nbsp;&nbsp; who you know, and it's like for me, it's like the&nbsp; butcher at the grocery store. I love to cook, he&nbsp;&nbsp; knows me. We talk. Can you actually produce that&nbsp; at scale for a company with 100 million customers&nbsp;&nbsp; and can you do it in a really personal way? And I&nbsp; think we're really on the cusp of enabling that. Let me ask you one more question before we get to&nbsp; a very exciting lighting round. There's a lot of&nbsp;&nbsp; founders struggling with go-to-market in AI with&nbsp; their AI apps. There's so many apps these days,&nbsp;&nbsp; so many products, so many things coming&nbsp; at buyers, at large B2B companies. Clearly&nbsp;&nbsp; you guys have figured something out. I&nbsp; imagine your name helps, investors help,&nbsp;&nbsp; but what have you learned about just how to&nbsp; successfully do go-to-market with an AI product,&nbsp;&nbsp; say an agent-specific product that you think would&nbsp; be helpful for folks trying to do this better? I think there's a small handful of go-to-market&nbsp; models that have been proven to work, and I think&nbsp;&nbsp; it's important to choose the right one for the&nbsp; product category you're going after. One category&nbsp;&nbsp; I would say is developer-led. This is somewhere&nbsp; famously Stripe and Twilio where probably two&nbsp;&nbsp; of the original that did this exceptionally. And&nbsp; essentially, the go-to-market motion there is to&nbsp;&nbsp; appeal to an individual engineer often within the&nbsp; department of the CTO who have accountability and&nbsp;&nbsp; a fair amount of latitude to choose a solution.&nbsp; This works if your product is a platform product.&nbsp;&nbsp; It doesn't work, for example, if your product&nbsp; is trying to help a line of business because&nbsp;&nbsp; lines of business typically don't have dedicated&nbsp; engineering teams or let alone, the latitude to&nbsp;&nbsp; just go download a new library or start using a&nbsp; web service like that. It particularly works well&nbsp;&nbsp; if you sell to startups just because startups&nbsp; tend to have engineering teams with quite a&nbsp;&nbsp; bit of latitude to choose services to help&nbsp; them solve the problem given by the founder.&nbsp; Then there's product-led growth. It's a broad&nbsp; term, obviously every company's product matters,&nbsp;&nbsp; but product-led growth more specifically&nbsp; means users can sign up from the website,&nbsp;&nbsp; often get put on a trial. Often you can buy a&nbsp; couple of seats with a credit card and those&nbsp;&nbsp; work where your user and your buyer are the&nbsp; same person. So it works for small business&nbsp;&nbsp; software almost always because sole proprietors do&nbsp; everything. And so you're selling small business&nbsp;&nbsp; software like Shopify in the early days and&nbsp; there's a lot of other products like that&nbsp;&nbsp; where you're trying to sell to small merchants.&nbsp; That's great. It doesn't work well when your&nbsp;&nbsp; buyer and the user of the software are different.&nbsp; So I'll use the example of something like expense&nbsp;&nbsp; reporting software. The user of that software&nbsp; is an individual employee, but the buyer is&nbsp;&nbsp; often a finance department. And so having sign&nbsp; up and buy with your credit card doesn't make&nbsp;&nbsp; sense because the person using is not the person&nbsp; with the credit card and it just doesn't work.&nbsp; And then there's direct sales. And direct sales&nbsp; had gone, I don't want to say out of fashion,&nbsp;&nbsp; but if I think of the best direct sales companies,&nbsp; probably there's a lot of lineage from Oracle,&nbsp;&nbsp; but you think SAP, Oracle, ServiceNow, Salesforce,&nbsp; Adobe perhaps, and there's others as well. And&nbsp;&nbsp; these were companies that sold into large lines of&nbsp; business in a relatively traditional sales motion.&nbsp;&nbsp; I think because product-led growth became very&nbsp; popular. I think a lot companies use that, which&nbsp;&nbsp; is great, that motion produces great products,&nbsp; but if PLG means that you aren't actually engaging&nbsp;&nbsp; with the buyer of your software, you're not going&nbsp; to grow. And so, I've actually seen more recently,&nbsp;&nbsp; with a lot of AI companies, direct sales come&nbsp; a little bit more back into fashion because I&nbsp;&nbsp; think so many of the opportunities in AI actually&nbsp; meet that qualification where the buyer and the&nbsp;&nbsp; user are not necessarily the same person and&nbsp; it really requires that go-to-market motion.&nbsp; Where I see entrepreneurs stumble is they'll&nbsp; choose a go-to-market motion without thinking&nbsp;&nbsp; through what is the process of purchasing this&nbsp; software? What is the process of evaluating the&nbsp;&nbsp; value of this software? And I think people&nbsp; just need to be much more first principles&nbsp;&nbsp; about it and much more thoughtful about it.&nbsp; And candidly, I think a lot of companies&nbsp;&nbsp; should leverage direct sales more than&nbsp; they do. And even though because of the&nbsp;&nbsp; sometimes justified reputation of the quality of&nbsp; products of some of these direct sales companies,&nbsp;&nbsp; it had gotten a bad name. And I think I'm thankful&nbsp; to see it coming back in a lot of the AI market. I feel like this message is something a&nbsp; lot of founders need to hear, especially&nbsp;&nbsp; founders that aren't from a business&nbsp; background that sales turns them off,&nbsp;&nbsp; they don't think they're going to be great at&nbsp; sales. Just this push of this might be what you&nbsp;&nbsp; have to get really good at and this is how you win&nbsp; and you can't just rely on product like growth. Yeah. Bret, is there anything else that you wanted to&nbsp; share? Any last nugget of wisdom? Anything you&nbsp;&nbsp; want to double click on before we get&nbsp; to our very exciting lightning round? No, go ahead. Okay, let's do it. Here we go. Welcome&nbsp; to our very exciting lightning round.&nbsp;&nbsp; I've got five questions for you. Are you ready? Yeah, go ahead. What are two or three books that you find&nbsp; yourself recommending most to other people? I don't read a lot of nonfiction, but probably&nbsp; if I had to pick one in the area of the topics&nbsp;&nbsp; we talked about, Competing Against Luck, which&nbsp; was the book that produced Jobs to be Done,&nbsp;&nbsp; which is a framework I really believe in.&nbsp; My only critique is I think most of these&nbsp;&nbsp; business books should be like an article. So&nbsp; maybe buy the book and punch it into ChatGPT&nbsp;&nbsp; and get the summary. But buy the book&nbsp; it's Clayton Christensen talked about it,&nbsp;&nbsp; but it's a really good framework for thinking&nbsp; about delivering value with your products.&nbsp;&nbsp; And I think it definitely influenced me. Actually one book I do recommend is Endurance,&nbsp;&nbsp; which is the story of Shackleton's trip&nbsp; to go to the South Pole. Half the book&nbsp;&nbsp; is him starving to death and eating seal meat&nbsp; with his crew of people frozen in their boat.&nbsp;&nbsp; I've never seen a better story of grit in&nbsp; my entire life. It's remarkable that it's a&nbsp;&nbsp; true story and if you're an entrepreneur going&nbsp; through a hard time, read that, you'd be like,&nbsp;&nbsp; okay, it could be worse. It's a great book too.&nbsp; It's just remarkable that it's a true story. And one thing he did a great job at is setting&nbsp;&nbsp; expectations for folks that&nbsp; joined that famous newspaper- That ad. That newspaper ad. I don't know if&nbsp; that's true. It's remarkable if that's true. Oh, it might not be true. I don't know. The internet. Who knows? Goddam. Deep fakes even back then. Okay. Do you&nbsp;&nbsp; have a favorite recent movie or TV&nbsp; show that you've really enjoyed? I haven't gone to any new TV&nbsp; shows recently? We just watched&nbsp;&nbsp; Inception with the kids and&nbsp; they loved it and made me&nbsp;&nbsp; appreciate Christopher Nolan and what a cool&nbsp; movie. It's the type of movie when you watch&nbsp;&nbsp; the film and you can a conversations for two&nbsp; days afterwards about it. So, just a great film. I saw someone using I think VO 3 to create&nbsp; their own Inception videos where the worlds&nbsp;&nbsp; wrapping in on each other. Oh, man.&nbsp; Okay. Do you have a favorite product&nbsp;&nbsp; that you have recently discovered that you&nbsp; love or one you've loved for a long time? I'm really a big fan of Cursor. I think&nbsp; it's changed. I love creating software&nbsp;&nbsp; and I'm excited though for agents. I've&nbsp; been really excited. I was very excited&nbsp;&nbsp; to see Codex from OpenAI and others. So I&nbsp; think Cursor will be in its current form,&nbsp;&nbsp; is a transition product. And I know they're&nbsp; working on agents as well, but I really enjoyed&nbsp;&nbsp; taking something I love and it's been my life's&nbsp; passion and really diving into this AI tool and&nbsp;&nbsp; seeing how it transforms how I create software.&nbsp; So I've just been spending a lot of time with&nbsp;&nbsp; the product just because it's so core to what I&nbsp; love to do and it's a really well crafted product. I think that's the first time someone's&nbsp; actually mentioned Cursor in this answer,&nbsp;&nbsp; so might be the beginning of a trend. Michael&nbsp; Trell was on the podcast and he actually&nbsp;&nbsp; had a very similar message as you had at the&nbsp; beginning of this chat about the future of code,&nbsp;&nbsp; what comes after code and this concept that&nbsp; there's going to be this additional pseudo code&nbsp;&nbsp; layer on top of code. Very aligned with&nbsp; your thinking. Do you have a favorite&nbsp;&nbsp; life motto that you often come back&nbsp; to and find useful in work or in life? The best way to predict the future is to&nbsp; invent it, which I think I attribute to Alan&nbsp;&nbsp; Kay of Xerox PARC. He invented a lot of the core&nbsp; abstractions that we use in computing today. I'm&nbsp;&nbsp; an entrepreneur, it's why I love to build&nbsp; things and it's definitely a life motto for me. I feel like many people say this, I&nbsp; feel like you've actually done this&nbsp;&nbsp; so many times. You're really living this&nbsp; motto. Final question. We talked about you&nbsp;&nbsp; inventing the like button at FriendFeed. Were&nbsp; there other thoughts of what they would call&nbsp;&nbsp; it other than like? Was it just obviously&nbsp; like? Or was there other thinking there? This was before emoji. So, if you read the&nbsp; comments on FriendFeed posts, at least 70%&nbsp;&nbsp; of them are cool or wow or yeah or neat. And one&nbsp; of the principle uses of FriendFeed was to have&nbsp;&nbsp; discussions about things. So you'd have a post&nbsp; and then a pretty fulsome discussion underneath.&nbsp;&nbsp; And compared to Twitter and others, it was a&nbsp; great place to have those discussions. And so,&nbsp;&nbsp; the product problem we were trying to solve is&nbsp; get all the one word answers out so that the&nbsp;&nbsp; discussion was actually actual comments as opposed&nbsp; to acknowledgements that you read the thing.&nbsp; So, the original framing was one click comment.&nbsp; That was how we thought about it. And so,&nbsp;&nbsp; the first version that I made had a heart, and she&nbsp; denies remembering this, but Anna Yang, now Anna&nbsp;&nbsp; Muller who has worked at the company, she hated&nbsp; it. She said, "If I look at hearts on every post,&nbsp;&nbsp; I'm going to vomit. It's too much." And it also&nbsp; was interesting, we were simulating, it was like&nbsp;&nbsp; an article about a tragedy or something. A heart&nbsp; was just not the right thing. Like which actually&nbsp;&nbsp; turned out to be really hard to translate&nbsp; was just a much more neutral sentiment,&nbsp;&nbsp; and that's why it was hard to translate because it&nbsp; was subtle. So that's how we ended up with this.&nbsp; We started with a heart, and I don't know if&nbsp; we ever heard the word love, but we definitely&nbsp;&nbsp; started off with the iconography and then like,&nbsp; which just felt like this positive yet as neutral&nbsp;&nbsp; as possible within the realm of positive so&nbsp; that it could work for a more complex story.&nbsp;&nbsp; But it was all because we needed a one-click&nbsp; comment. That's where the concept came from. Wow. I've never heard the story&nbsp; before. It makes me think about&nbsp;&nbsp; LinkedIn now. They're basically trying&nbsp; to solve that same problem. They have&nbsp;&nbsp; all these auto-reply pill tag things. I&nbsp; don't think people like those very much. Yeah. They have a lot of features. So many AI features. Bret, this was incredible.&nbsp; This was an honor. I so appreciate you coming&nbsp;&nbsp; on this podcast. Two final questions, where can&nbsp; folks find you online if they want to reach out,&nbsp;&nbsp; maybe go see if they want to work at Sierra&nbsp; and how can listeners be useful to you? If you want an AI agent to&nbsp; help with customer service,&nbsp;&nbsp; go to sierra.ai. If you want to&nbsp; apply here, sierra.ai/careers where&nbsp;&nbsp; we have offices in San Francisco and New&nbsp; York, Atlanta and London and are hiring&nbsp;&nbsp; pretty aggressively in every department.&nbsp; So please reach out if you're interested. And how can listeners be useful to you?&nbsp; Is it tryout Sierra, anything else there? Yeah, tryout Sierra. I'm a single issue voter. [inaudible 01:28:26] message. I love it. Yeah. Bret, thank you so much for being here. Yeah, thanks for having me. Bye, everyone. Thank you so much&nbsp;&nbsp; for listening. If you found this valuable, you&nbsp; can subscribe to the show on Apple Podcasts,&nbsp;&nbsp; Spotify, or your favorite podcast app.&nbsp; Also, please consider giving us a rating&nbsp;&nbsp; or leaving a review as that really helps other&nbsp; listeners find the podcast. You can find all&nbsp;&nbsp; past episodes or learn more about the show at&nbsp; Lennyspodcast.com. See you in the next episode.