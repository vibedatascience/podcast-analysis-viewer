================================================================================
YOUTUBE VIDEO EXTRACTION
================================================================================
VIDEO_ID: eAODQUKqDiU
URL: https://www.youtube.com/watch?v=eAODQUKqDiU
TITLE: Faster Science, Better Drugs
CHANNEL: a16z
PUBLISHED: 2025-09-15
DURATION: 55m 39s
VIEWS: 3,697
LIKES: 0
COMMENTS: 4
TAGS: a16z, andreessen horowitz

DESCRIPTION:
----------------------------------------
Can we make science as fast as software?

In this episode, Erik Torenberg talks with Patrick Hsu (cofounder of Arc Institute) and a16z general partner Jorge Conde about Arc’s “virtual cells” moonshot, which uses foundation models to simulate biology and guide experiments. 

They discuss why research is slow, what an AlphaFold-style moment for cell biology could look like, and how AI might improve drug discovery. The conversation also covers hype versus substance in AI for biology, clinical bottlenecks, capital intensity, and how breakthroughs like GLP-1s show the path from science to major business and health impact.

Timecodes:
00:00 Introduction to Accelerating Science
00:35 Welcome to the Podcast
00:45 The Moonshot: Virtual Cells and Human Biology
01:57 Challenges in Scientific Progress
02:58 Interdisciplinary Collaboration at Arc Institute
05:11 The Role of AI in Biology
10:18 Understanding Virtual Cells
22:13 Biotech and Pharma Industry Insights
27:39 Challenges in Clinical Trials
... [truncated]

SUBTITLE AVAILABILITY:
----------------------------------------
Total languages: 157
English available: True (auto)

EXTRACTED CAPTIONS:
----------------------------------------
Method: easysub-api
Language: en
Word count: 10,569

TRANSCRIPT:
----------------------------------------
I want to make science faster. Our moonshot is really to make virtual cells at Ark and simulate human biology with foundation models. Why are we so worried about modeling entire bodies over time when we can't do it for an individual cell? >> We can figure out how to model the fundamental unit of biology, the cell, then from that we should be able to build. >> My goal is to really try to figure out ways that we can improve the human experience in our lifetime. There are a few things that if we get them right in our lifetime will fundamentally change the world. >> Patrick, welcome to the podcast. Thanks for joining. >> Thanks for having me on. >> I've been trying to have you on for years, but finally I could get your time. >> Here I am. I'm excited to do it. It's going to be great. >> For some of the audience who aren't familiar with you and your work at at Arc and Beyond, how do you describe what's your moonshot? What what is what you're trying to do? I want to make science faster, right? You know, we can frame this in high level philosophical goals like accelerating scientific progress. Maybe that's not so tangible for people. I think the most important thing is science happens in the real world. If it's not AI research, which moves as quickly as you can iterate on GPUs, right? You have to actually move things around. Atoms clear liquids from tube to tube to actually make life-changing medicines. And these are things that take place in real time. you have to actually grow cells, tissues, and animals. And I think the promise of what we're doing today with machine learning in biology is that we could actually accelerate and massively uh massively paralyze this. And so our moonshot is really to make virtual cells at ARC and simulate human biology with foundation models. And you know, we'd like to figure out something that feels useful for experimentalists, people who are skeptical about technology. you know, they just want to see the data and see the results that it's actually the default tool that they go to use when they want to do something with cell biology. >> Okay. Well, hold on. Let's back up. Why is science so slow in the first place? Like, whose fault is that? >> Whose fault is that? Now, that is a long one. We should get into it. It's really multiffactorial. >> Okay. >> Right. It's this weird Gordian knot that ultimately comes down to incentives, right? comes down to, you know, people talk a lot about science funding and how science funding can be better, but it's it's also about how, you know, the training system works, right? How we incentivize long-term career growth, how we, you know, try to separate, you know, basic science work from, you know, commercially viable work and generally the space of problems that people are able to work on today. Um, I think things are increasingly multi-disiplinary. It's very hard for individual research groups or individual companies to be good at more than two things, right? You might be able to do, you know, computational biology and genomics, right? Or, you know, like chemical biology and molecular glues, but, you know, how do you do five things at once is is increasingly hard. And we really built ARC as an organizational experiment to try to see what happens when you bring together neuroscience and immunology and machine learning and chemical biology and genomics all under one physical roof. Right? If you increase the collision frequency across these five distinct domains, there would hopefully be a huge space of problems that you could work on that you wouldn't be able to. Now obviously in any university or any kind of geographical region you have all of these individual fields represented at large right across these different campuses but you know people are distributed and you want everyone together. Yeah. >> Okay. But if I may so a UN I would have thought a university was an attempt to bring in multiple disciplines under one roof. You're saying it's not. It's too diffuse. >> It's across an entire campus. >> Okay. So the physic like literally the physical distance uh creates inefficiency. >> That's part of it. And I think the other part is folks have their own incentive structures, right? They need to publish their own papers. They need to do their own thing and you know make their own discovery. And you're not really incentivized to work together. I think in many ways in the current academic system and a lot of what we've done is to try to have people work on bigger flagship projects that require much more than any individual person or group or idea. >> Yeah, that's cool. So like sort of the original hypothesis for the arc institute is if you can bring u multiple disciplines together to increase the collision frequency as you said and if if one could remove some of the the cross incentives that may exist in sort of traditional structures the combination of those two things will make science faster. Yeah, these are these are absolutely part of it, right? We have two flagship projects. One trying to find Alzheimer's disease drug targets. The other two make these virtual cells and the I think it's not just the people and the infrastructure but also the models will hopefully literally make science faster that you could you know do experiments at the speed of forward passes of a neural network if these models could become accurate and useful. >> Mhm. Yeah. So that that will be one thing that solves the length of discovery is you compress the time discovery takes naturally by just throwing technology at the problem at the risk of oversimplifying. >> Well, we're we're techn optimists here though. >> We are. >> Yeah. >> Why has AI progressed so much faster in um sort of image generation and language models than than biology? And and if we could wave a wand, like where are we excited to to speed certain things up? >> To be honest, it's a lot easier, right? Maybe that's a hot take, right? But uh >> mean technology is easier than biology. >> Uh natural language and video modeling is easier than modeling biology. Correct. Right. And to some degree like if you understand and learn machine learning, right? And how to train these models, you have already learned how to speak, you already know how to look at pictures. And so your ability to evaluate the generations or predictions of these models are very native, right? We we don't speak the language of biology, right? you know at very best with an incredibly thick accent, right? So when you you're training these DNA foundation models, I don't speak DNA natively. So I only have a sense of the types of tokens that I'm feeding into the model and what's actually coming out, right? Similarly, these virtual cell models, you know, I think a lot of the goal is to figure out ways that you can actually interpret the weird fuzzy outputs that the model is giving you. And I think that's what slows down the iteration cycle is you have to do these lab in the loop things where you have to run actual experiments to actually test with experimental ground truth. And you know I think increasing the speed and dimensionality of that is going to be really important. Yeah. >> How much of this is the fact that like you know you talk about you know we speak biology poorly or with a very thick accent. How much of this is like if you're training on an image, we can see the image and so we can see how, you know, how good the output is. >> What about all the things in biology that we can't see or don't even know exist yet? Like how how can we create a virtual cell? And maybe we should come back to the what a virtual cell model is, by the way, for the lay audience, but like how can we create a virtual cell model when we're not even sure if we understand all of the components that are in a cell and how they function? People talked a lot about this in NLP as well. There's this long academic tradition in natural language processing, right? And then it was just weird and unintuitive and intensely controversial that you could just feed all this unstructured data into a transformer and it would just work. Now, we're not saying this will just work in all the other domains including in biology, but I think there is this, you know, controversy around what does it mean to be an accurate biological simulator? What does it mean to be a virtual cell? It's true. We can't measure everything, right? We can't measure I think things like metabolites and really high throughput with spatial resolution and there are going to be different phases of capability where initially they model individual cells then they model pairs of cells then they model cells in a tissue and then in a broader physiologically intact animal environment and those are length scales and uh kind of layers of complexity that will aggregate and you know improve upon over time and I think the other kind of non-intuitive in many ways are the scaling laws that you get in data and in modeling. I'll give you an example, right? There's a lot of discussion in molecular biology about how, you know, RNAs, you know, don't reflect protein and protein function, right? Um, and so, well, we don't have, you know, proteomic measurement technologies that are nearly as scalable as transcripttoic measurement technologies today, like that's the single cell resolution certainly, but we're getting there. And you can layer on certain nodes of protein information that you can add on top of the RNA information. But in many ways, the RNA representation is a mirror, right? Uh it might be a lower resolution mirror for what's happening at the protein layer, but eventually what is happening in protein signaling will get reflected in a transcriptional state, right? And so for an individual cell, this may not be very accurate, but when you imagine the massive data scale that we're generating in genomics and functional genomics, right, you start to gather tremendous amounts of RNA data that will read in kind of like what's happening at the protein level at some at some sort of mirror echo, right? And then that can, you know, be the case for metabolic uh metabolic information as well and so on. >> So it's a low pixel image, but if we can get sort of zoomed out far enough, we'll get a sense of what's going on. You have to bet on what you can scale today, right? We're able to, you know, scale single cell and transcriptional information today. We're able to add on, you know, protein level information over time. We'll need spatial information, spatial tokens, and we'll need temporal dynamics as well. And we'll, you know, I kind of uh bucket things into three tiers. There's invention, engineering, and scaling. And there are certain things today biotechnologically that are scale ready. And then there are things that we still need to invent, right? And that's part of why we felt like we needed a research institute to be able to tackle these types of problems. That we weren't just going to be an engineering shop that's just trying to scale single cell perturbation screens, right? That, you know, would be interesting, but in 3 years would feel very dated, I think. Right. And so there's a lot of novel technology investment that we're making that we think will bear fruit over time. >> Yeah. >> Can we flesh out the virtual cell concept? Why that's the ambition we we we've landed on and what it's going to take to get there or what are the bottlenecks? I I would say the most kind of famous success of ML and biology is alpha fold right and this solved the protein folding problem of you know when you take a sequence of any amino acid what is the protein look like right and you know it's pretty good it's not perfect it certainly doesn't simulate the biopysics and the molecular dynamics but it gives you a sense of what the end state is with 90% plus accuracy right and that's the alphaold moment that people talk about right where anytime you want to, you know, work with a protein, you're if you don't have an experimentally solved structure, you're just going to fold it with this with this algorithm. And we kind of want to get to that point with virtual cells as well. And the way that at ARC we're operationalizing this is to do perturbation prediction, right? Where the idea is you have some manifold of cell types and cell states, right? Um that can be a heart cell, a blood cell, a lung cell, and so on. And you know that you can kind of move cells across this manifold, right? Sometimes they become inflamed, sometimes they become apoptoic, sometimes they become cell cycle rested, they become stressed, they're metabolically starved, they're hungry in some way. And so if you have this sort of this representation of universal sort of cell space, right? Can you figure out what are the perturbations that you need to move cells around this manifold? And this is fundamentally what we do in making drugs, right? Whether we have small molecules which started out as natural products from, you know, boiling leaves or antibodies when we injected proteins into cows and rabbits and sheep and took their blood to to get those antibodies where we were basically trying to get to more and more specific probes, right? And we had experimental ways to kind of cook these up. Now we have computational ways to do zero shot these binders. But ultimately what you're trying to do with these binders is to inhibit something and then by doing so kind of click and drag it from a kind of toxic gain of function disease-causing state to a more quiescent homeostatic healthy one, right? And the thing that is very clear in complex diseases, right, where you don't have a single cause of that disease is there's some complex set of changes. There's a combination of perturbations, if you will, that you would want to make to be able to move things around. Now, you know, people talk about this classically as things like polypharmarmacology, right? But, you know, I think we're moving from a, oh, this thing happens to have, you know, a whole bunch of different targets um kind of by accident uh to we have the ability to manipulate these things commentorially in a purposeful way, right? that to go from cell state A to cell state B, there are these three changes I need to make first, then these two changes, and then these six changes, right, over time, right? And we kind of want models to be able to suggest this. And the reason why we scoped virtual cell this way is because we felt it was just experimentally very practical. You want something that's going to be a co-pilot for a wet lab biologist to decide what am I going to do in the lab, right? We're not trying to do something that's like a theory paper that's really interesting to read where, you know, the numbers go up on a ML benchmark, but you know, you practically can decide what are the 12 things that you're going to do in the lab in 12 different conditions, right? And actually just test them, right? And then that's how we kind of enter the the kind of the lab in the loop aspect of model predictions to experimental measurements to you know you know kind of improved or RL or whatever model kind of predictions again and the goal is to be able to do in silicone target ID where you can basically figure out new drug targets figure out then the compositions the drug compositions you would need to actually make those changes. I think if we could do that, we could make a new AI like vertically integrated AI enabled pharma company, right? Which um you know, I think is obviously a very exciting idea today, but I think in many ways the kind of pitch and the framing of these companies precedes the fundamental research capability breakthroughs. And that's what we're really invested in at ARC is just kind of just making that happen along with many other amazing colleagues in the field to just make this possible for you know the community. So if the goal is I'm to oversimplify it for you like if we wanted to get to the alpha fold moment where you know it kind of gives you a useful structure folded structure 90% of the time to use your your data point we wanted to take that uh comparison in the in the virtual cell model and we said okay 90% of the time if I ask the model I want to shift the cell from cell from cell state A to cell state B and it's going to give me a list of perturbations and let's say that at 90% of the time those perturbations in fact result in the shifting experimentally in the shifting from cell state A to cell state B. >> How far away are we from that alphafold moment for virtual cells? >> I find it helpful to frame these in terms of like GPT 1 2 3 4 5 capabilities, right? And I think most people would agree where somewhere between GPT 1 and two, right? A lot of the excitement was that we could achieve GPT1 in the first place that you could see a path with scaling laws of some kind to kind of make successive generations where capabilities would improve. But you know these are you know with like our EVO kind of uh DNA foundation models that we developed at ARC with uh Brian He right one of the things that we've seen is that you know these are really kind of these genome generations are like quote unquote blurry pictures of life right we don't think if you synthesize these novel genomes they would be alive but you know we we don't think that's actually also impossibly far away. we'll just have to kind of follow these capabilities. We're generating uh we're taking a very integrated approach to attack this problem, right? Where you need to curate public data, you need to generate massive amounts of internal private data, build the benchmarks and train the new uh train new models and build uh sort of architectures and kind of doing these things full stack and we'll just kind of attack this um hill climb over time. >> What's the GPT I'll say GP3 moment going to look like? And by that I mean sort of a public release that alters the public's conception of just what's possible here from a capabilities perspective and also inspires a whole new generation of talent to like rush into into into into biology. >> Well the good thing with biology is we have a lot of ground truth right there are entire textbooks right that describe cell signaling and cell biology and how these things work. And so you know even without a virtual cell model at all right if you went into chachi BT or claude and you basically you know you asked it some question about you know like receptor tyroscene kynise signaling it would have an opinion on how that works right and so I think you would want the model to be able to predict perturbations that are kind of famous canonical examples of biological discovery so I'll give you an example if you loaded into the model an iPSC kind of an induced potent stem cell stay or human embriionic stem cell state and a fibroblast cell state, right? Could it predict that the four Yamanaka factors would reprogram the fibroblast into a stem-like state, right? And essentially rediscover from the model, something that won the Nobel Prize in 2009, right? That that would be sort of one really kind of classic example. And then you could go do the inverse. If you have a stem cell, can it discover neurogenine 2, ASCL1, myod, can it find differentiation factors will turn that into a neuron or into a muscle cell or or so on. And you know, these are kind of classic examples in developmental biology, but you could also use this to try to discover or kind of recapitulate the mechanism of action of FDA approved drugs, right? And so you could say for example we know if you kind of inhibit her too in you know breast cancer you know cell states right it would become you know you would get this type of response or it could predict the you know certain clones that you know will be able to kind of be more metastatic or you know they'll be more resistance and they'll lead to minimal residual disease there I think lots of kind of biological evals that you can kind of add onto these models over time that are really tangible textbook examples as opposed to I think what the kind of early generation of models do today which is you know very quantitative things like mean absolute error over like you know the differential express genes and stuff like that you know um that's those are ML benchmarks and we want to increase the sophistication into something that you could explain to an old professor who has you know never touched a terminal in their life. >> By the way, you talk about textbooks as ground truth. Do you think we're going to find that a lot of the textbooks are wrong? >> I would say textbooks are compressed, right? So, for example, when you you look at these kind of classic cell signaling diagrams of A signals to B, which inhibits C, right? That's a very kind of two-dimensional representation >> of our understanding of a complex system. >> Right. Right. Right. >> I mean, yes, textbooks are what they are. They represent the corpus of reliable knowledge, but everyone knows that there are incredible number of exceptions. And part of what discovery is is to find new exceptions, right? >> Why don't you talk about the difference between simulation of biology and and the actual understanding and and what would it would it take to actually be able to model the extremely complex human body? >> You know, some people don't like the phrase virtual cells because it sounds too media friendly. It's not rigorous enough, right? But I I've always um found it funny that you know but you know many people are okay with like digital twins and digital avatars which you know talks about modeling biology at a way higher level of abstraction. You know I think virtual cells if anything is actually way more scoped and rigorous uh than modeling a digital twin or avatar. But you know I think these are useful words because they describe the goal and the ambition right that no in the long run we don't care about predicting the you know kind of pertivation responses of an individual cell at all actually right obviously we want to be able to predict drug toxicity we want to be able to predict aging we want to be able to predict why a liver cell becomes serotic when you repeatedly challenge it with ethanol molecules or whatever, right? And you know, the these sort of chemical or environmental perturbations should be predictable. I think you just kind of have to layer on the complexity, right? Like why are we so worried about modeling entire bodies over time when we can't do it for an individual cell, right? where we sort of you know accept or broadly believe that this is a kind of you know fundamental unit of biological you know computation if you will right and let's just kind of start there right just like you kind of have to start with you know things like math and code and language modeling right and things that are just sort of easier to check you can build to super intelligence over time yeah >> yeah I think that makes sense right that that's that's a very sort of laudable ambitious goal that we can figure out how to model the fundamental unit of biology the cell then from that we should be able to build >> like in early AI we just started with like language translation just you know basic NLP tasks right this is long before you know the the tremendous ambitious scope that we have today and I think we we hopefully can mirror that type of trajectory if we're lucky >> it seems that biotech and pharma has has been a shrinking um in certain the rate of growth what's it going to take for these um innovations in in in the science to reflect themselves in in business models and in in growth for the industry. A lot of these biotech startups would try to initially sell software to pharma companies and then they would kind of realize, oh wow, we're like competing for SAS budgets um which aren't very large and then you know now they're realizing oh we have to compete for R&D budgets right and I think you know there's this narrative from the current generation these companies that oh our biological agents will compete for R&D budgets and replace headcount or something like that right just like we're seeing in you agents across different verticals, right? Whether or not that will, I think, pan out, I think, depends on just whether or not these things meaningfully allow us to, you know, build drugs more effectively in the pharma context, right? And I think that's just sort of the most important thing um in in in this industry. And so I think we believe in virtual cells not just because we think it will be a fountain of fundamental mechanistic insights for discovery but also because if in the case of success it could be industrially really useful right but you know we'll we'll we'll we'll have to see over time right if we have 90% of drugs failing in clinical trials right that kind of means two things and you're not sure what percent of which right one is we're targeting the wrong target in the first place. The second is the composition. The drug matter that we're using doesn't do the job, right? It's not clear for each individual failure which one it is or if it's both or what proportion of each and you know we'll have to kind of sort that out over time. Like you can imagine even in the case of success when we had 90% accurate virtual cells you'll probably end up with suggestions like okay now you need to target you know this GPCR only in heart but not in literally any other tissue right we don't have the drug matter that can do that today and so that's also why again you probably need research to figure out novel chemical biology matter that allows you to drug pyotropic you know targets um in tissue or cell type specific way, right? And so, you know, I think, you know, part of why biology is slow is because there's just this Russian nesting doll of complexity um in terms of understanding, in terms of perturbation, in terms of safety. And you know, the the the crazy thing is the progress in just the short time that I've been doing this is insane, right? like I did my you know PhD at the Broad Institute in the heyday of developing single cell genomics, human genetics, crisper gene editing um you know and uh you know so many other things and I think the kind of early 2010s papers on single cell sequencing would have like 20 cells >> or 40 cells right and and at arc in the next you know kind of n like I don't know relatively short amount of time we're going to generate a billion perturb single cells, right? That's like I mean, how's how's that for a M's law? >> Yeah, that's remarkable. >> Yeah. >> Yeah. Cory, I want to hear your answers a couple of these questions too as as lead of of our bio practice, both on the GPT3 moment, what what that could look like and also um like I'm curious if you think it's G1's or sort of building off that or if it's going to be something different and also what's it going to take for the for the science to kind of reflect itself in in the business for the industry to grow. >> Yeah. So, I'll take the the second one first if I could. So I think you know in terms of of where the industry is right now I think one of the big challenges we have is as Patrick describes very nicely like you know discovery is hard and it takes time and you know the fail modes are exactly as you described often times when drugs fail which they do 90% of the time in clinical trials it's because we're going after the wrong thing or we made the wrong thing to go after the right thing right like those are the two fail modes and that happens uh all too often and so I think a lot of the stuff that Patrick is describing is going to basically improve improve our hit rate or our batting average on figuring out what to go after and then making the right thing to go after set thing. Um the challenge we have I think in the industry is that the bottlenecks still are the bottlenecks and the biggest bottleneck we have which is you know a necessary one is we have to prove that whatever we make that we have the right thing to go after the right thing so to speak and that we when we have it that it's going to be as you know d-risisked as possible before you put it into humans >> and we have to be good at making them in the first place. >> And we got to make them too. Yeah. Exactly. And so that bottleneck is a necessarily important one. we that bottleneck should exist. I'm not suggesting we've got to remove it, but are there ways to reduce the cost and time associated with getting through the bottleneck of human clinical trials? Um, and you know, it's it's interesting because, you know, we talk about, you know, uh, all of the various stakeholders when you're making a drug. uh there are the companies, there's of course the science that supported um the the company that's trying to commercialize uh a product and there are the regulatory agencies, you know, and everyone is trying to ensure again that uh what's you know, first and foremost is the ability to um uh discover and commercialize drugs that are safe and effective for humans. That middle part part of actually getting through that bottleneck is hard to speed up in a very obvious way. Like you can increase the rate the way you enroll clinical trials. You can use better technology to change the way we design these clinical trials so maybe they can be faster or shorter etc. But some of them just have a natural timeline you have to go through like if you want to demonstrate that a cancer drug uh promotes survival guess what you're going to have it's going to take some time to demonstrate a survival benefit or if you know you want to do a longevity drug that by definition is a lifetime you know of of a trial in terms of length. So there's a lot of these bottlenecks are really hard to get through. So what helps the industry? I think there are a couple of things that uh help the industry. One is um capital intensity uh will hopefully at some point go down over time as technology gets better. Capital intensity is something that our industry faces. In some ways it looks a little bit like AI now, right? In terms of the cost of training these models, but the capital intensity is very very high. That has not come down. So um we got to get the success rates up to impact capital intensity to get it down. The second thing is can where can we compress time? So good models can help us compress early discovery time. We still haven't seen uh and I think it's coming but it hasn't happened yet. We haven't seen artificial intelligence or other technologies massively compress the amount of time it takes us to do the clinical development, the clinical trials, the enrollment of patients, all of those things. We're seeing some interesting things coming. We haven't seen sort of the the payoff there yet. Um and the third thing is if we can make better drugs going after better things you the effect size should be higher so therefore the answer should be obvious sooner. If we can get those three things right, reduce capital intensity, compress timelines and effectively increase effect size in in some very tough um sort of uh intractable diseases, that is what I think fixes the industry. And from where we sit at the early stage um uh at the early stage in terms of being early stage investors, the reason why that helps us is if the capital intensity goes down and the value creation goes up, it becomes easier to invest in these companies in the early days because you get rewarded for coming in early. The problem we have right now is that most companies aren't you're not seeing uh rewards happening when there's value inflection. So you come in early, you bear the brunt of the capital intensity, and even if a company's successful, that success isn't reflected in the valuation. So we're not seeing the step ups that you see in other parts of the industry. And that's just really, really hard from a from an investing standpoint. So I think we need to see those various factors addressed for this space to really get, you know, fixed, to use your word. >> Yeah, that was great. I I have a lot to add on to this. >> Please add away. >> You know, just, you know, one a few simple observations, right? The the first is the amount of market cap added to Lily and Novo um based on the you know development of GLP1s um is like over a trillion dollars is is or you know I mean no stock has decreased a lot so um you know trillion dollars let's say is more than the market cap of all biotech companies combined over the last 40 years have been started right and I think you know one one of the kind of interesting kind of corlaries of this is that you know when we have a 10% uh kind of clinical trial success rate for kind of pre-clinical drug matter, right? You tend to circle the wagons a bit and try to manage your risk, right? And so the way that you do this is you try to go after really wellestablished disease mechanisms where if I developed new drugs that go after well understood biology, it should work the way that I hope it will in the trial. um which is you know really really expensive and costs a lot more in many ways than the the pre-clinical research right um the problem with this is you go after very well validated disease mechanisms but with really small patient populations right so then the expected value of this actually is relatively low one of the kind of things that we've seen with uh GLP1s is the just the kind of value that you can create when you go after really large patient populations and I think that has culturally really net increased the ambition of the industry both from the investor and from the drug developer side and I think you know that's something that we should keep our foot on the gas for. Yeah. >> Yeah. And look I think the trend on that is posit I would argue the trend on that is positive. You're absolutely right like the the demonstration of uh the value that has been created uh with the the use increasing use of GLP1s and the value transfer that's gone to companies like Lily and who I would argue is like very merited right because they've cracked an endemic social problem um in terms of managing diab diabetes and eventually helping manage obesity and so I think that's remarkable and there's a lot of value that goes to that because they tackled they cracked a very very um challenging problem for society beyond just science. So that's great and I agree with you like the the the prize the juice needs to be worth the squeeze, right? You're right. A lot of biotech has been around like go after the lowhanging fruit because it's low risk and we got to eat today, >> right? So you go get it, you know, and you sort of you push off the big the big ambitious indication, the large population or the the really uh tough to crack disease. But, you know, I do think we're seeing more and more of that. And by the way, like we can get into some of these genetic medicines, but some of these genetic medicines are going after some of the hardest problems. The things that you quite literally couldn't address but for editing, you know, DNA and, you know, I think that's incredibly, you know, remarkable and laudable and and and frankly inspiring. >> Yeah. >> But the fundamental um elements of the industry have to work. So the capital formation is there to support those kinds of things. And right now it's hard, right? Because of the the issues we talked about before. 15 years from now, we're back in this room. we've barely escaped being part of the permanent underclass. Um, and we're reflecting on the on sort of the GBT3 moment or or maybe the legacy of GLP once um sort of beyond where they are now. Um, what do you think it could be or or I'm curious to get your take on what do you think is going to be the technological breakthrough that we're going to point back to and say, "Oh, this is really what what set it all or do you think it's going to be sort of, you know, multiffactor combination?" Yeah, I look I think um it's it's going to go back to sort of where we started this conversation conversation, excuse me. Uh GP1s uh as a drug are you know what is four decades in the making or something like that. You know these are these are not overnight successes. Um uh but I do think what we are going to see more of and and our hope is that when you combine the fact that we're getting better at uh understanding what to target, getting better at designing medicines to hit those targets. by the way in a whole array of new creative ways. So we have small molecules the natural products that we got from boiling leaves as you said earlier like those have gotten you know we're getting really good at designing smarter and better smaller molecu small molecules that do new things that function in ways that they didn't before. Um we've gotten quite good at designing uh biologics or proteins with a lot of help from things like alphafold that help us understand how proteins fold. we're going to get a lot better at designing some of the more complex uh modalities like the gene therapies of the world or the gene editors of the world. And when you can do that and combine that with our ability to hopefully use things like virtual cell models to really understand what to go after, like we're going to have drugs we I would hope and I would expect that the industry will continue to bring forward drugs that have very large effect size for very difficult diseases that hopefully affect a lot of patients. If that's true, then we'll start to see some of these really, really difficult um diseases that affect all of society get tackled hopefully, you know, one by one by one by one. And so we have obesity, we have metabolic disorder, we're dealing with cardio metabolic disease, we're starting to see interesting promising things happening in like neurogenerative diseases. um you know if we can you know tackle cancer or at least you know several cancers that now have begun to be treated more like a chronic condition than a death sentence that they were in the past. The more we see of that like I think that value to society will accrete over time and I think this should be an industry that is extraordinarily uh valued by society and candidly by the markets. we have to deliver >> if we play this out right and let's say these AI models work right and you can make a trillion binders in silicone that will you know exquisite drug matter right we still need to make these things physically and test them in animals and hopefully predictive models and then actually in people right and I think you know that will increasingly be the the the bottleneck in many ways right You know, my my friend Dan Wang recently released a book called Breakneck, which talks about um you know, kind of like the US and China and the difference between the two countries and their philosophy, the way they approach markets. >> We're a country of lawyers or a country of engineers. >> That's right. Right. China is an engineering state, right? It's kind of polit, you know, folks who have engineering degrees. you know, you need to build bridges and roads and buildings and these are the ways that we solve our problems. Whereas, I think from, you know, the first 13 American presidents, 10 of them practice law. From 1980 to 2020, all Democratic presidential candidates uh uh both VP and president uh went to law school, right? And so you kind of see the echoes of that in the FDA and the regulatory regime and you know all the kind of the the bottlenecks that people talk about developing drugs state side and increasingly you see folks thinking about how we can run phase ones overseas right build data packages that we can you know bring back domestically for phase 2 efficacy trials. I think that's interesting directionally, but it's not enough, right? And you know, I think we need to kind of figure out these two bottl and the testing. >> Yeah. >> Even if we can solve the designing part. >> Oh, I agree. Yeah. Yeah. That that's the bottleneck. You know, we we joke about it. You have to do is you have to get a molecule >> that can go, you know, first in mice and then in muts and then in monkeys and then in man. like there's, you know, it takes a long time and it's so hard to compress that. Um, and so when you do, you you should make the journey worth, you know, make the journey worth it, right? So when you fail on the other end of that, like that's obviously horrible. >> And so finding ways to make sure that when you when you walk that path that it'll be a successful journey as often as possible >> is what this industry desperately needs. >> Mhm. >> Alphold solved a protein folding problem, but what didn't it solve? judge drug judge discovery or more broadly what would it take to to get a drug discover what is sort of the the bottleneck on on the on the tech side at least >> on the tax side >> yeah maybe another way to ask the question is that because I always ask the founders a version of this question like the AI ones >> um that are like oh we're going to do AI for life for drug discovery and so my my question that I always like to ask founders is >> give me examples where you think AI is hyped >> potentially overly hyped >> um where there's real hope like the sort of what do we expect what's next >> and where we already see real heft >> so like if I asked you like in AI you know where is there hype where is there hope and where are we seeing heft today >> I would say there's hype in toxicity prediction models >> okay so that's the idea that we will say >> um I'm going to show you a molecule and you're going to tell me the model is going to tell me if it's going to be toxic or not >> that's right >> right there's have to anything to do with proteins right obviously ly protein binding but increasingly in protein design right I think there's real heft there and then you know where there's hype is um in multimodal biological models whatever that means right and I think you know pick your favorite layers it could be you know molecular layers it could be spatial layers it could be you know I I mean actually I would say there's also heft in the pathology AI prediction models you know like you know automating the work of pathologists and radiologists. That's that's >> a powerful use case. Sure. >> Yeah. And there's a lot of stuff where you don't have to train, you know, weird biology foundation models and you can write, you know, regulatory filings and reports and things like that. Um, that's impactful and important. Yeah. >> So, now go back to Eric's question is why don't why hasn't AI turned out drugs yet? I think that was your question, right? You know, AI for drugs is one of these weird things where everyone who works in the industry is trying to claim that their drug is like the first AI design molecule, right? Um I feel like in yeah I mean increasingly in just a few years this will just be a native part of the stack, right? Just like we use, you know, the internet and we use phones, we're going to have AI in all parts of the stack, right? And so it's just going to become a native part of everything that we do. And so, you know, like why hasn't it worked yet? Is this long multiffactorial process that we've been talking about today? There's designing, there's the making, there's the testing, there's the approvals side of it. And you know, I think the I I do think safety and efficacy as the kind of two pillars in the industry are the two things that we need to get right. Right. We need to be able to figure out faster ways that we can predict whether or not molecule will work and if it's going to be safe or not. And there are like ways that AI can operationalize this. If you designed a small molecule, right? You could now computationally dock it to every protein in the proteium and see if it's likely to bind to offtarget molecules. You can use this to tune binding selectivity and affinity that might be ways to predict, you know, safety and efficacy, right? And you know, how well will that work? Well, that's a feedback loop that we'll have to actually test in the lab. And that's part of what's slow is the testing um you know, takes real hours, days, months, right, years. And you know that that and that's really why we've picked at ARC the virtual cell models as our initial wedge because we think it can integrate a lot of these different pieces. In Daario Amade's essay, Machines of Loving Grace, he predicts, among other things, the prevention of of of many infectious diseases and the doubling of lifespans perhaps in as soon as the next decade. What's your reaction to his his essay's bullishness and some of his predictions? >> I think the core intuition that Daru had was the idea that like important scientific discoveries are independent, right? or they're largely independent. And if they are, you know, statistically independent, then it would stand to reason that we could multi-parallelize. And so we had models that were sufficiently predictive and useful. You could have not just a hundred of them but millions billions of these discovery agents or processes running at a time which should compress the timeline to new discoveries um and turn it into a computation problem. Right? I think that is a very futuristic framing for something that is actually very tangible today. Right? Um, and if we can have virtual cell models at work, for example, that can start to do these kinds of things that we've been talking about, help us, you know, we can have, you know, molecular design models. We can have docking models. We can then have, you know, when you bind to this thing in this cell versus all the other offtarget proteins, will a cell kind of be corrected in the right way? Right? these kind of layers of abstraction and complexity start to get to things that feel very tangible through drug discovery. If you could actually traverse these steps reliably and in sequence, you could start to see how you can get the compression right and and so I think in the long run of time this should be possible. >> One of the core positions in building a good virtual cell model is that we are feeding it all the relevant data. >> The right data. Yeah, >> the right data. >> Um, and so we'll work to, you know, it's gene expression data or it's DNA data or, you know, any any number of factors, protein and protein interactions, all the things you described. >> Um, >> what if we're missing a core element? Like what if we just haven't discovered the quirk or whatever, like we just don't know what we don't know and therefore the what we're feeding the model is fundamentally or importantly incomplete. >> I think that's almost certainly true, right? Like it's seems almost obvious that we're not measuring many of the most important things in biology, right? And you can of course find many important exceptions for any of these measurement technologies. Like in biology, we ultimately have two ways to study it in high throughput. It's imaging and sequencing, right? But there are so many other types of things that you would care about that those things aren't necessarily going to do at scale, right? And that's really why I think the stuff that we're talking about of the RNA layer as a mirror for other layers of biology is one that we've spent a lot of time thinking about. Um, and there's a difference between a mechanistic model and a meteorological simulation type of model. So for example, if you want to predict the weather, right, you can build AI models that will predict whether or not it will rain next Tuesday. It won't explain physically or geologically or whatever why and how that happens. But as long as it knows if it's going to rain next Tuesday, you're probably happy, right? And I would say similarly with a virtual cell model, it may not tell me literally why. Just like a alpha fold doesn't tell me literally why did the protein fold this way and how, but it just told me the end state and it was reasonably accurate. I think that would already be very important. Shifting gears a little bit, we've been talking about science and and biotech, but you're in addition, you're an elite AI investor more broadly. So, so I want to talk about um h how you're I want to talk about where your investment focus is right now just as it relates to AM more broadly. Where are you excited? Where are you spending time? Where are you, you know, looking forward to? >> Oh, yeah. My my goal is to really try to figure out ways that we can improve the human experience in our lifetime. I kind of think of like if I think about the future that we're going to leave to our children, right? There are a few things that if we get them right in our lifetime will fundamentally change the world, right? And you know how we live in it. I think synthetic biology um is obviously one, right? You know, think you know GLP1s, right? Things that improve uh sleep, right? Things that can, you know, improve longevity, right? These are these are all things that are kind of you know easy to get excited about. I do I I think um brain computer interfaces um is another area where um we're going to see really important breakthroughs over the decades to come. And then I think the third is in uh is in robotics both industrial and consumer robotics right um that allow us to basically like scale physical like labor right in in in interesting ways. And you know, you can kind of see how each of these three things, even in the sort of medium cases of success really kind of changed the world. And so I'm very interested in helping make these kinds of things possible, right? And so there are sort of, you know, in the kind of techno optimist sort of vision of the world, right? There's a few different types of scarcity, right? There's, you know, it's very easy when you do research to come up with important ideas. The hard thing is to tackle them in the right time frame, right? It's like, you know, writing futuristic sci-fi things is not that hard. Being able to actually execute on it in the next 5 years or eight years, um, much much harder, right? And I would say, you know, academic discovery is littered with plenty of ideas that are interesting and important, but, you know, kind of long before their time. In many ways the story of technology development is you know trying to use new technologies to solve old tricks right like most of our tools are you know for productivity right um in many ways um whether that's the industrial revolution or the computing revolution or the current AI revolution we're trying to kind of do the same stuff and you know and so there you know I think there's a relatively small set of very powerful ideas new technologies give us new opportunities to attack them and there's a set of people and teams that are going to be positioned to be able to do that. They need to have technical innovation and then an intuition about product and business in a way that you know, you know, you kind of in the RPG dice roll of the skills that you get in these three domains. People start at different base levels, right? And you know, you might have an incredibly technical founder who doesn't know how to think commercially or someone who's just natively a very commercial thinker who, you know, it doesn't have very strong product sense, right? Um even though they could sell the crap out of it, right? And so I think these sort of this sort of three broad categories of capabilities you need to kind of bring together in a way that you can allocate capital to in the right times in order to make these ideas possible in a really differentiated way. Like this thing literally wouldn't happen if we didn't get these people together and funded at the right time in the right way. Right? And that's that's really what what motivates me and these are kinds of the things that I've been excited about. you know, backing, you know, longevity companies like Newman, right? BCI companies like Nudge, right? Robotics companies like the bot company, right? Um, you know, these are some of the examples of kind of, you know, things that I think must happen in the world. Um, and therefore should happen and you know, how do we actually find the right people and the right time to actually kind of go on the fellowship of the ring hunt, right? >> Yeah. If not too difficult, I want to ask uh Jorge a question adapted to these uh additional spaces um robotics um sort of BCI and and longevity if appropriate terms of and through questions I believe were what's overhyped what's uh where do you see opportunity or path and what's got hefted already. I think the cool thing about agents um generally is that they do real work, right? Um compared to like SAS companies that came before, agents replace real productivity, right? And I think you know they have a lot of errors today and I would say the computer use agents will probably trail the coding agents by maybe a year, right? But but it's coming and we'll follow the trajectory as these go from doing you know minutes of work without error to hours to days right and I think you know you're going to get a completely different product shape as we march through that across legal BO you know medicine healthcare whatever right and we'll kind of follow that as an industry and that's that's going to be really exciting and I think that's where we're going to see real heft is because most of the economy is services spent it's not software spend and you know the reason why we're all excited about this stuff is that it can attack you know the the the services economy and I would say like you know where where is there hype there's tremendous amount right that's that's that's no doubt the hype is in the model capabilities right and you know it's we we we're working with an architecture that you know dates back to 2017 right and if you look at the history of deep learning it's like kind of every eight years there's something really Right. Um, and we it feels like in 2025 we're really overdue for some net new architecture. And I think there are lots of really interesting research ideas that are bubbling up that could um do that thing. And in many ways there's a set of really interesting academic ideas, especially in the golden age of machine learning research from I don't know like 2009 to 2015, right? There's so many interesting ideas, little archive papers that have like 30 citations or less. And as the marginal cost of compute goes down yearon year, I think you're going to be able to take all of these ideas and actually scale them up, right? Where you don't see the scaling laws when you're training them at 100 million or 650 million parameters like back then. But if you can scale them up to 1B, 7B, 35B, 70B, right? you start to see, you know, whether or not these ideas will pop, right? And I think that's very exciting because, you know, there's just going to be a lot of opportunity for new super intelligence labs to do things um, you know, beyond what the kind of, you know, established foundation model companies are doing today, right? As they kind of, you know, in addition to these research teams, right? You know, these are in many ways becoming applied AI companies, right? they need to build product shape and you know all kinds of different enterprises and do RL for businesses and make money right and I think or or or build coding agents and make API revenue and that's important and I think you know a timely race to survive today but I'm just you know very bullish on the research of say like a sakana AI right which was founded by one of the authors of attention is all you need right Ian Jones and they're doing incredibly interesting stuff on model emerging and how you can have kind of um sort of like evolutionary selection of you know kind of of different um uh kind of you know models ine and I think the the sort of opportunities here um in the long run to move beyond just like RL gyms for example um also to kind of figure out new ways to learn and and find like kind of reward signal is going to be really exciting. >> I think it's a great place to wrap. Gearing towards towards closing, anything uh upcoming for ARC that you'd like us to know of? Anything you want to tease? Anything for people want to learn more? What should they know about? >> So, Alphold was uh in many ways came out of a protein folding competition called CASP, right? Uh critical assessment of the structure of proteins. And um you know, we created our own virtual cell challenge um at virtualellchallenge.org or where we have, you know, $100,000 prizes sponsored by NVIDIA and 10X Genomics and Ultima and others. And it's an open competition that anyone can enter where you can train perturbation prediction models and we can openly and transparently assess these model capabilities both today and in subsequent years follow them to get to that ChachiBT moment. Right? And so I'm extremely excited about this. um you know um we we'd like more people to you know train models and apply both bioml experts and engineers in any other domain and you know I'm you know I I I just I want this thing to exist in the world you know hopefully we're important parts of making that happen but I just be happy that someone does it. >> Yeah, >> that's an inspiring note to to wrap on. Patrick Jorge, thanks so much for the conversation. >> Thanks so much guys. Appreciate it. Thanks >> for having me.